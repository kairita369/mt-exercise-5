2024-05-19 13:05:49,737 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2024-05-19 13:05:49,740 - INFO - joeynmt.helpers -                           cfg.name : bpe_model_4000
2024-05-19 13:05:49,740 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2024-05-19 13:05:49,740 - INFO - joeynmt.helpers -                     cfg.data.train : data2/train
2024-05-19 13:05:49,741 - INFO - joeynmt.helpers -                       cfg.data.dev : data2/dev
2024-05-19 13:05:49,741 - INFO - joeynmt.helpers -                      cfg.data.test : data2/test
2024-05-19 13:05:49,741 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2024-05-19 13:05:49,741 - INFO - joeynmt.helpers -                  cfg.data.src.lang : en
2024-05-19 13:05:49,742 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2024-05-19 13:05:49,742 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2024-05-19 13:05:49,742 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2024-05-19 13:05:49,742 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data2/bpe_vocab4000.en
2024-05-19 13:05:49,742 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2024-05-19 13:05:49,743 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.pretokenizer : moses
2024-05-19 13:05:49,743 - INFO - joeynmt.helpers - cfg.data.src.tokenizer_cfg.num_merges : 4000
2024-05-19 13:05:49,743 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data2/code4000.bpe
2024-05-19 13:05:49,743 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : it
2024-05-19 13:05:49,744 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2024-05-19 13:05:49,744 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2024-05-19 13:05:49,744 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2024-05-19 13:05:49,744 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data2/bpe_vocab4000.it
2024-05-19 13:05:49,744 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2024-05-19 13:05:49,745 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.pretokenizer : moses
2024-05-19 13:05:49,745 - INFO - joeynmt.helpers - cfg.data.trg.tokenizer_cfg.num_merges : 4000
2024-05-19 13:05:49,745 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data2/code4000.bpe
2024-05-19 13:05:49,746 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2024-05-19 13:05:49,746 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2024-05-19 13:05:49,746 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2024-05-19 13:05:49,746 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2024-05-19 13:05:49,747 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2024-05-19 13:05:49,747 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2024-05-19 13:05:49,747 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2024-05-19 13:05:49,747 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2024-05-19 13:05:49,747 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2024-05-19 13:05:49,748 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2024-05-19 13:05:49,748 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2024-05-19 13:05:49,748 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2024-05-19 13:05:49,748 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2024-05-19 13:05:49,748 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2024-05-19 13:05:49,748 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2024-05-19 13:05:49,749 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2024-05-19 13:05:49,749 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2024-05-19 13:05:49,749 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2024-05-19 13:05:49,749 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2024-05-19 13:05:49,749 - INFO - joeynmt.helpers -             cfg.training.model_dir : bpe_model_4000
2024-05-19 13:05:49,750 - INFO - joeynmt.helpers -             cfg.training.overwrite : True
2024-05-19 13:05:49,750 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2024-05-19 13:05:49,750 - INFO - joeynmt.helpers -              cfg.training.use_cuda : True
2024-05-19 13:05:49,750 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2024-05-19 13:05:49,750 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2024-05-19 13:05:49,750 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2024-05-19 13:05:49,751 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2024-05-19 13:05:49,751 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2024-05-19 13:05:49,751 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2024-05-19 13:05:49,751 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2024-05-19 13:05:49,752 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2024-05-19 13:05:49,752 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2024-05-19 13:05:49,752 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2024-05-19 13:05:49,752 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2024-05-19 13:05:49,752 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2024-05-19 13:05:49,752 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2024-05-19 13:05:49,753 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2024-05-19 13:05:49,753 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2024-05-19 13:05:49,753 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2024-05-19 13:05:49,753 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2024-05-19 13:05:49,753 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2024-05-19 13:05:49,754 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2024-05-19 13:05:49,754 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2024-05-19 13:05:49,754 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2024-05-19 13:05:49,754 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2024-05-19 13:05:49,754 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2024-05-19 13:05:49,755 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2024-05-19 13:05:49,755 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2024-05-19 13:05:49,755 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2024-05-19 13:05:49,755 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2024-05-19 13:05:49,755 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2024-05-19 13:05:49,806 - INFO - joeynmt.data - Building tokenizer...
2024-05-19 13:05:50,200 - INFO - joeynmt.tokenizers - en tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-19 13:05:50,201 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=moses, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-19 13:05:50,201 - INFO - joeynmt.data - Loading train set...
2024-05-19 13:06:21,595 - INFO - joeynmt.data - Building vocabulary...
2024-05-19 13:06:21,788 - INFO - joeynmt.data - Loading dev set...
2024-05-19 13:06:22,033 - INFO - joeynmt.data - Loading test set...
2024-05-19 13:06:22,438 - INFO - joeynmt.data - Data loaded.
2024-05-19 13:06:22,438 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=en, trg_lang=it, has_trg=True, random_subset=-1)
2024-05-19 13:06:22,439 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=929, src_lang=en, trg_lang=it, has_trg=True, random_subset=-1)
2024-05-19 13:06:22,439 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1566, src_lang=en, trg_lang=it, has_trg=True, random_subset=-1)
2024-05-19 13:06:22,439 - INFO - joeynmt.data - First training example:
	[SRC] Al G@@ ore : A@@ ver@@ ting the clim@@ ate cri@@ si@@ s
	[TRG] Al G@@ ore : ar@@ rest@@ iamo il ri@@ scal@@ d@@ amento glob@@ ale
2024-05-19 13:06:22,440 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) to (6) of (7) a (8) and (9) in
2024-05-19 13:06:22,440 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) di (5) che (6) e (7) a (8) la (9) un
2024-05-19 13:06:22,440 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 3316
2024-05-19 13:06:22,441 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 3720
2024-05-19 13:06:22,462 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-19 13:06:22,557 - INFO - joeynmt.model - Enc-dec model built.
2024-05-19 13:06:23,743 - DEBUG - tensorflow - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2024-05-19 13:06:23,942 - DEBUG - h5py._conv - Creating converter from 7 to 5
2024-05-19 13:06:23,942 - DEBUG - h5py._conv - Creating converter from 5 to 7
2024-05-19 13:06:23,942 - DEBUG - h5py._conv - Creating converter from 7 to 5
2024-05-19 13:06:23,943 - DEBUG - h5py._conv - Creating converter from 5 to 7
2024-05-19 13:06:24,340 - DEBUG - jax._src.path - etils.epath found. Using etils.epath for file I/O.
2024-05-19 13:06:25,372 - INFO - joeynmt.model - Total params: 4700416
2024-05-19 13:06:25,373 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2024-05-19 13:06:25,375 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=3316),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=3720),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2024-05-19 13:06:26,471 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2024-05-19 13:06:26,471 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2024-05-19 13:06:26,472 - INFO - joeynmt.training - Train stats:
	device: cuda
	n_gpu: 1
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2024-05-19 13:06:26,472 - INFO - joeynmt.training - EPOCH 1
2024-05-19 13:06:31,846 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     4.126712, Batch Acc: 0.054864, Tokens per Sec:    13543, Lr: 0.000300
2024-05-19 13:06:35,590 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.812963, Batch Acc: 0.108659, Tokens per Sec:    19101, Lr: 0.000300
2024-05-19 13:06:39,238 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.717400, Batch Acc: 0.142511, Tokens per Sec:    19796, Lr: 0.000300
2024-05-19 13:06:43,567 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.580589, Batch Acc: 0.157990, Tokens per Sec:    16545, Lr: 0.000300
2024-05-19 13:06:47,490 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.549991, Batch Acc: 0.167429, Tokens per Sec:    18400, Lr: 0.000300
2024-05-19 13:06:47,491 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:06:47,491 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:07:03,658 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.55, ppl:  34.74, acc:   0.16, generation: 15.9744[sec], evaluation: 0.0000[sec]
2024-05-19 13:07:03,659 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:07:03,910 - INFO - joeynmt.training - Example #0
2024-05-19 13:07:03,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:07:03,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:07:03,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che']
2024-05-19 13:07:03,912 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:07:03,912 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:07:03,913 - INFO - joeynmt.training - 	Hypothesis: E che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che che
2024-05-19 13:07:03,913 - INFO - joeynmt.training - Example #1
2024-05-19 13:07:03,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:07:03,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:07:03,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'pos@@', ';', ';', ';', ';', ';', ';', ';', ';', ';', ';', ';', ';', ';', ';', ';', ';', 'è', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che']
2024-05-19 13:07:03,914 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:07:03,914 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:07:03,914 - INFO - joeynmt.training - 	Hypothesis: E che che che che che che che che che che che che che che un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un un pos;;;;;;;;;;;;;;;; è che che che che che che che che che che che che che che che che che che che
2024-05-19 13:07:03,915 - INFO - joeynmt.training - Example #2
2024-05-19 13:07:03,915 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:07:03,915 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:07:03,915 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'che', 'che', 'che', 'che', 'è', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'pos@@', 'e', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'un', 'pos@@', ';', 'è', 'un', 'pos@@', ';', 'è', 'un', 'un', 'un', 'un', 'un', 'pos@@', ';', 'è', 'un', 'un', 'un', 'un', 'un', 'un', 'pos@@', 'ot@@', 'a', '.', '</s>']
2024-05-19 13:07:03,916 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:07:03,916 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:07:03,916 - INFO - joeynmt.training - 	Hypothesis: E è che che che che è un un un un un un un un un pose che che che che che che che che che che che un pos; è un pos; è un un un un un pos; è un un un un un un posota.
2024-05-19 13:07:03,917 - INFO - joeynmt.training - Example #3
2024-05-19 13:07:03,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:07:03,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:07:03,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'che', 'che', 'che', 'che', 'che', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'un', 'pos@@', 'e', '.', '</s>']
2024-05-19 13:07:03,918 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:07:03,918 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:07:03,918 - INFO - joeynmt.training - 	Hypothesis: E che che che che che un un un un un un un un pose.
2024-05-19 13:07:03,918 - INFO - joeynmt.training - Example #4
2024-05-19 13:07:03,919 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:07:03,919 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:07:03,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'è', 'è', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'che', 'un', 'pos@@', ';', ';', ';', ';', 'è', 'un', 'pos@@', ';', 'è', 'un', 'pos@@', ';', 'a', '.', '</s>']
2024-05-19 13:07:03,920 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:07:03,920 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:07:03,920 - INFO - joeynmt.training - 	Hypothesis: E è è che che che che che che che che che che che che che che che che che che che che che che che che che che che che che un pos;;;; è un pos; è un pos; a.
2024-05-19 13:07:07,514 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.439404, Batch Acc: 0.175851, Tokens per Sec:    19085, Lr: 0.000300
2024-05-19 13:07:11,738 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.280715, Batch Acc: 0.180584, Tokens per Sec:    17035, Lr: 0.000300
2024-05-19 13:07:15,897 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.542873, Batch Acc: 0.190123, Tokens per Sec:    17079, Lr: 0.000300
2024-05-19 13:07:19,571 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.162468, Batch Acc: 0.194545, Tokens per Sec:    19746, Lr: 0.000300
2024-05-19 13:07:23,178 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.364753, Batch Acc: 0.200760, Tokens per Sec:    20126, Lr: 0.000300
2024-05-19 13:07:23,179 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:07:23,179 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:07:38,015 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.28, ppl:  26.49, acc:   0.20, generation: 14.6006[sec], evaluation: 0.0000[sec]
2024-05-19 13:07:38,016 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:07:38,309 - INFO - joeynmt.training - Example #0
2024-05-19 13:07:38,310 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:07:38,311 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:07:38,311 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'pos@@', ';', ';', '</s>']
2024-05-19 13:07:38,313 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:07:38,313 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:07:38,313 - INFO - joeynmt.training - 	Hypothesis: La nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro pos;;
2024-05-19 13:07:38,313 - INFO - joeynmt.training - Example #1
2024-05-19 13:07:38,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:07:38,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:07:38,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'è', 'il', 'cosa', 'che', 'il', 'cosa', 'è', 'il', 'cosa', 'che', 'è', 'il', 'nostro', 'nostro', 'nostro', 'mondo', '.', '</s>']
2024-05-19 13:07:38,315 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:07:38,315 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:07:38,315 - INFO - joeynmt.training - 	Hypothesis: Ma è il cosa che il cosa è il cosa che è il nostro nostro nostro mondo.
2024-05-19 13:07:38,315 - INFO - joeynmt.training - Example #2
2024-05-19 13:07:38,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:07:38,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:07:38,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', ',', 'il', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'mondo', '.', '</s>']
2024-05-19 13:07:38,317 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:07:38,317 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:07:38,317 - INFO - joeynmt.training - 	Hypothesis: La cosa, il nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro mondo.
2024-05-19 13:07:38,317 - INFO - joeynmt.training - Example #3
2024-05-19 13:07:38,317 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:07:38,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:07:38,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', '.', '</s>']
2024-05-19 13:07:38,318 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:07:38,318 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:07:38,319 - INFO - joeynmt.training - 	Hypothesis: E sono sono sono sono sono sono sono sono sono sono sono sono sono sono.
2024-05-19 13:07:38,319 - INFO - joeynmt.training - Example #4
2024-05-19 13:07:38,319 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:07:38,319 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:07:38,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'cosa', 'che', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', 'sono', '.', '</s>']
2024-05-19 13:07:38,320 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:07:38,320 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:07:38,320 - INFO - joeynmt.training - 	Hypothesis: La cosa che sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono sono.
2024-05-19 13:07:42,770 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.078425, Batch Acc: 0.210721, Tokens per Sec:    15149, Lr: 0.000300
2024-05-19 13:07:46,409 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.065063, Batch Acc: 0.221790, Tokens per Sec:    19233, Lr: 0.000300
2024-05-19 13:07:50,068 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.113452, Batch Acc: 0.229565, Tokens per Sec:    19762, Lr: 0.000300
2024-05-19 13:07:54,592 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.968015, Batch Acc: 0.244505, Tokens per Sec:    15822, Lr: 0.000300
2024-05-19 13:07:58,553 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.938592, Batch Acc: 0.253513, Tokens per Sec:    18813, Lr: 0.000300
2024-05-19 13:07:58,554 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:07:58,554 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:08:13,458 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.97, ppl:  19.58, acc:   0.25, generation: 14.7702[sec], evaluation: 0.0000[sec]
2024-05-19 13:08:13,459 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:08:13,714 - INFO - joeynmt.training - Example #0
2024-05-19 13:08:13,715 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:08:13,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:08:13,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['D@@', 'unque', ',', 'sono', 'anni', ',', 'sono', 'due', 'anni', ',', 'in', 'cui', 'i', 'nostri', 'anni', ',', 'che', 'il', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio']
2024-05-19 13:08:13,717 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:08:13,718 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:08:13,718 - INFO - joeynmt.training - 	Hypothesis: Dunque, sono anni, sono due anni, in cui i nostri anni, che il mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio
2024-05-19 13:08:13,718 - INFO - joeynmt.training - Example #1
2024-05-19 13:08:13,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:08:13,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:08:13,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'il', 'nostro', 'nostro', 'nostro', 'nostro', 'modo', 'di', 'questo', 'è', 'il', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', 'nostro', '.', '</s>']
2024-05-19 13:08:13,719 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:08:13,720 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:08:13,720 - INFO - joeynmt.training - 	Hypothesis: Ma il nostro nostro nostro nostro modo di questo è il nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro nostro.
2024-05-19 13:08:13,720 - INFO - joeynmt.training - Example #2
2024-05-19 13:08:13,721 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:08:13,721 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:08:13,721 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'nostro', 'nostro', 'sistema', 'di', 'un', 'po', '&@@', 'a@@', 'pos@@', ';', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', 'di', 'un', 'sistema', '.', '</s>']
2024-05-19 13:08:13,722 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:08:13,722 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:08:13,722 - INFO - joeynmt.training - 	Hypothesis: Il nostro nostro sistema di un po 'di un sistema di un sistema di un sistema di un sistema di un sistema.
2024-05-19 13:08:13,722 - INFO - joeynmt.training - Example #3
2024-05-19 13:08:13,722 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:08:13,722 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:08:13,723 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'un', 'po', '&@@', 'a@@', 'pos@@', ';', '.', '</s>']
2024-05-19 13:08:13,723 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:08:13,723 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:08:13,723 - INFO - joeynmt.training - 	Hypothesis: E 'un po'.
2024-05-19 13:08:13,723 - INFO - joeynmt.training - Example #4
2024-05-19 13:08:13,724 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:08:13,724 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:08:13,724 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', 'mio', '.', '</s>']
2024-05-19 13:08:13,724 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:08:13,724 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:08:13,725 - INFO - joeynmt.training - 	Hypothesis: Il mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio mio.
2024-05-19 13:08:17,461 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.054159, Batch Acc: 0.258500, Tokens per Sec:    17574, Lr: 0.000300
2024-05-19 13:08:21,505 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.832160, Batch Acc: 0.271072, Tokens per Sec:    17858, Lr: 0.000300
2024-05-19 13:08:25,756 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.713136, Batch Acc: 0.282744, Tokens per Sec:    16410, Lr: 0.000300
2024-05-19 13:08:29,455 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.731309, Batch Acc: 0.289808, Tokens per Sec:    19363, Lr: 0.000300
2024-05-19 13:08:33,050 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.611792, Batch Acc: 0.295642, Tokens per Sec:    19825, Lr: 0.000300
2024-05-19 13:08:33,050 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:08:33,051 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:08:47,834 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.76, ppl:  15.84, acc:   0.29, generation: 14.6536[sec], evaluation: 0.0000[sec]
2024-05-19 13:08:47,835 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:08:48,096 - INFO - joeynmt.training - Example #0
2024-05-19 13:08:48,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:08:48,097 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:08:48,097 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'primo', 'anno', 'ho', 'fatto', 'un', 'paio', 'di', 'di', 'più', 'di', 's@@', 'ette', 'di', 's@@', 'ette', 'di', 'più', 'più', 'di', 'più', 'di', 'più', 'più', 'di', 'anni', ',', 'che', 'il', '7@@', '0', 'anni', ',', 'che', 'il', '20', 'anni', ',', 'che', 'il', '%', 'di', 'anni', ',', 'che', 'ha', 'avuto', 'il', '%', '%', 'di', 'anni', '.', '</s>']
2024-05-19 13:08:48,098 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:08:48,098 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:08:48,099 - INFO - joeynmt.training - 	Hypothesis: Il primo anno ho fatto un paio di di più di sette di sette di più più di più di più più di anni, che il 70 anni, che il 20 anni, che il% di anni, che ha avuto il%% di anni.
2024-05-19 13:08:48,099 - INFO - joeynmt.training - Example #1
2024-05-19 13:08:48,099 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:08:48,099 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:08:48,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'è', 'il', 'problema', 'di', 'questo', 'è', 'il', 'problema', 'di', 'questo', 'è', 'che', 'non', 'è', 'il', 'problema', '.', '</s>']
2024-05-19 13:08:48,100 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:08:48,100 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:08:48,101 - INFO - joeynmt.training - 	Hypothesis: Ma questo è il problema di questo è il problema di questo è che non è il problema.
2024-05-19 13:08:48,101 - INFO - joeynmt.training - Example #2
2024-05-19 13:08:48,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:08:48,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:08:48,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'sistema', 'di', 's@@', 'ini@@', 'stra', 'è', 'un', 'sistema', 'di', 'di', ',', 'un', 'sistema', 'di', 'di', 'più', 'di', 'più', 'di', 'più', 'di', 'più', 'di', 'più', 'di', '&@@', 'a@@', 'pos@@', ';', 'inter@@', 'o', 'del', 'sistema', '.', '</s>']
2024-05-19 13:08:48,102 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:08:48,102 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:08:48,102 - INFO - joeynmt.training - 	Hypothesis: Il sistema di sinistra è un sistema di di, un sistema di di più di più di più di più di più di 'intero del sistema.
2024-05-19 13:08:48,103 - INFO - joeynmt.training - Example #3
2024-05-19 13:08:48,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:08:48,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:08:48,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'un', 'am@@', 'am@@', 'ici', 'e', 'in', 'un', 'po', '&@@', 'a@@', 'pos@@', ';', '.', '</s>']
2024-05-19 13:08:48,104 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:08:48,104 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:08:48,104 - INFO - joeynmt.training - 	Hypothesis: E 'un amamici e in un po'.
2024-05-19 13:08:48,104 - INFO - joeynmt.training - Example #4
2024-05-19 13:08:48,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:08:48,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:08:48,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'primo', 'primo', 'primo', 'primo', 'primo', 'punto', 'di', 'ciò', 'che', 'è', 'che', 'è', 'che', 'è', 'stata', 'stata', 'la', 'cosa', 'che', 'è', 'stata', 'il', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'primo', 'anni', '.', '</s>']
2024-05-19 13:08:48,106 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:08:48,106 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:08:48,106 - INFO - joeynmt.training - 	Hypothesis: Il primo primo primo primo primo punto di ciò che è che è che è stata stata la cosa che è stata il primo primo primo primo primo primo primo primo primo primo primo primo primo primo primo primo primo primo primo primo primo primo anni.
2024-05-19 13:08:52,723 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.608571, Batch Acc: 0.302585, Tokens per Sec:    14566, Lr: 0.000300
2024-05-19 13:08:56,475 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.574599, Batch Acc: 0.309941, Tokens per Sec:    19116, Lr: 0.000300
2024-05-19 13:09:00,134 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.463192, Batch Acc: 0.318408, Tokens per Sec:    19654, Lr: 0.000300
2024-05-19 13:09:04,039 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.667093, Batch Acc: 0.327042, Tokens per Sec:    18620, Lr: 0.000300
2024-05-19 13:09:08,454 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.717001, Batch Acc: 0.331651, Tokens per Sec:    16024, Lr: 0.000300
2024-05-19 13:09:08,455 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:09:08,455 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:09:23,989 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.59, ppl:  13.31, acc:   0.33, generation: 15.4018[sec], evaluation: 0.0000[sec]
2024-05-19 13:09:23,990 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:09:24,244 - INFO - joeynmt.training - Example #0
2024-05-19 13:09:24,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:09:24,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:09:24,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'anno', 'anno', 'ho', 'fatto', 'che', 'questi', 'due', 'milioni', 'di', 'due', 'milioni', 'di', 'di', 'due', 'milioni', 'che', 'la', 'f@@', 'ica', 'che', 'la', 'più', 'più', 'o', 'di', 'tre', 'milioni', 'di', 'anni', '.', '</s>']
2024-05-19 13:09:24,246 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:09:24,246 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:09:24,247 - INFO - joeynmt.training - 	Hypothesis: Il anno anno ho fatto che questi due milioni di due milioni di di due milioni che la fica che la più più o di tre milioni di anni.
2024-05-19 13:09:24,247 - INFO - joeynmt.training - Example #1
2024-05-19 13:09:24,247 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:09:24,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:09:24,248 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'è', 'il', 'problema', 'di', 'questo', 'problema', 'di', 'questo', 'problema', 'perché', 'non', 'è', 'il', 'problema', 'di', 'questo', 'non', 'è', 'il', 'fatto', 'di', 'una', '.', '</s>']
2024-05-19 13:09:24,248 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:09:24,248 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:09:24,249 - INFO - joeynmt.training - 	Hypothesis: Ma questo è il problema di questo problema di questo problema perché non è il problema di questo non è il fatto di una.
2024-05-19 13:09:24,249 - INFO - joeynmt.training - Example #2
2024-05-19 13:09:24,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:09:24,249 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:09:24,250 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'suo', 'senso', 'di', 'ri@@', 'ri@@', 'to', 'è', 'un', 'senso', ',', 'la', 'persona', ',', 'la', 'f@@', 'ase', 'del', 'sistema', 'del', 'sistema', '.', '</s>']
2024-05-19 13:09:24,250 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:09:24,250 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:09:24,251 - INFO - joeynmt.training - 	Hypothesis: Il suo senso di ririto è un senso, la persona, la fase del sistema del sistema.
2024-05-19 13:09:24,251 - INFO - joeynmt.training - Example #3
2024-05-19 13:09:24,251 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:09:24,251 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:09:24,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'poi', 'si', 's@@', 's@@', 's@@', 's@@', 'ì', 'e', 'in', 'cui', 'si', 's@@', 'ì', '.', '</s>']
2024-05-19 13:09:24,252 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:09:24,252 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:09:24,253 - INFO - joeynmt.training - 	Hypothesis: E poi si ssssì e in cui si sì.
2024-05-19 13:09:24,253 - INFO - joeynmt.training - Example #4
2024-05-19 13:09:24,253 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:09:24,253 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:09:24,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'fatto', 'che', 'vi', 'mostr@@', 'erò', 'un', 'po', '&@@', 'a@@', 'pos@@', ';', 'di', 'ciò', 'che', 'è', 'stato', 'stato', 'stato', 'stato', 'stato', 'stato', 'il', 'fatto', 'di', 'anni', '.', '</s>']
2024-05-19 13:09:24,254 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:09:24,254 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:09:24,255 - INFO - joeynmt.training - 	Hypothesis: Il fatto che vi mostrerò un po 'di ciò che è stato stato stato stato stato stato il fatto di anni.
2024-05-19 13:09:27,913 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.488230, Batch Acc: 0.344898, Tokens per Sec:    18595, Lr: 0.000300
2024-05-19 13:09:31,627 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.586119, Batch Acc: 0.347265, Tokens per Sec:    19047, Lr: 0.000300
2024-05-19 13:09:36,073 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.474863, Batch Acc: 0.349756, Tokens per Sec:    15933, Lr: 0.000300
2024-05-19 13:09:39,737 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.336494, Batch Acc: 0.361191, Tokens per Sec:    19482, Lr: 0.000300
2024-05-19 13:09:43,379 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.353256, Batch Acc: 0.367180, Tokens per Sec:    19753, Lr: 0.000300
2024-05-19 13:09:43,379 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:09:43,380 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:09:56,757 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.44, ppl:  11.48, acc:   0.36, generation: 13.2655[sec], evaluation: 0.0000[sec]
2024-05-19 13:09:56,758 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:09:57,007 - INFO - joeynmt.helpers - delete bpe_model_4000/500.ckpt
2024-05-19 13:09:57,031 - INFO - joeynmt.training - Example #0
2024-05-19 13:09:57,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:09:57,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:09:57,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'ho', 'fatto', 'questi', 'due', 'due', 'volte', 'che', 'il', 'più', 'più', 'for@@', 'te', 'che', 'il', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'più', 'di', 'circa', '20', 'anni', 'ha', 'avuto', 'il', '10', '%', 'di', '4@@', '5', '%', 'di', '1@@', '4', '%', ',', 'ha', 'fatto', 'il', '10', '%', '.', '</s>']
2024-05-19 13:09:57,033 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:09:57,033 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:09:57,033 - INFO - joeynmt.training - 	Hypothesis: L'anno ho fatto questi due due volte che il più più forte che il più più più più più più più più più più più più più di circa 20 anni ha avuto il 10% di 45% di 14%, ha fatto il 10%.
2024-05-19 13:09:57,034 - INFO - joeynmt.training - Example #1
2024-05-19 13:09:57,034 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:09:57,034 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:09:57,034 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', ',', 'questo', 'problema', 'di', 'questo', 'problema', 'è', 'il', 'problema', 'di', 'questo', 'problema', 'perché', 'non', 'è', 'mostr@@', 'ato', 'il', 'problema', 'di', 'questo', 'non', 'è', 'il', 'problema', '.', '</s>']
2024-05-19 13:09:57,035 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:09:57,035 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:09:57,035 - INFO - joeynmt.training - 	Hypothesis: Ma questo, questo problema di questo problema è il problema di questo problema perché non è mostrato il problema di questo non è il problema.
2024-05-19 13:09:57,036 - INFO - joeynmt.training - Example #2
2024-05-19 13:09:57,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:09:57,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:09:57,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'sua', 'sua', 'fi@@', 'fi@@', 'fi@@', 'fi@@', 'a', 'è', ',', 'il', 'suo', 'senso', ',', 'il', 'suo', 'sistema', 'del', 'sistema', '.', '</s>']
2024-05-19 13:09:57,037 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:09:57,037 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:09:57,037 - INFO - joeynmt.training - 	Hypothesis: La sua sua fifififia è, il suo senso, il suo sistema del sistema.
2024-05-19 13:09:57,037 - INFO - joeynmt.training - Example #3
2024-05-19 13:09:57,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:09:57,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:09:57,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'ver@@', 'i', 'in', 'e', 'si', 'si', 'ri@@', 'fer@@', 'i@@', 'bile', '.', '</s>']
2024-05-19 13:09:57,039 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:09:57,039 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:09:57,039 - INFO - joeynmt.training - 	Hypothesis: E 'inververi in e si si riferibile.
2024-05-19 13:09:57,039 - INFO - joeynmt.training - Example #4
2024-05-19 13:09:57,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:09:57,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:09:57,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prossi@@', 'mo', 'mo', 'mo', 'mo', 'mo', 'mo', 'mo', 'mo', 'mo', 'mo', 'mo', 'più', 'più', 'velo@@', 'ce', '.', '</s>']
2024-05-19 13:09:57,040 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:09:57,041 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:09:57,041 - INFO - joeynmt.training - 	Hypothesis: Il prossimo mo mo mo mo mo mo mo mo mo mo più più veloce.
2024-05-19 13:10:01,183 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.391686, Batch Acc: 0.374536, Tokens per Sec:    16188, Lr: 0.000300
2024-05-19 13:10:05,342 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.288908, Batch Acc: 0.378345, Tokens per Sec:    16884, Lr: 0.000300
2024-05-19 13:10:09,011 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.244471, Batch Acc: 0.385249, Tokens per Sec:    19465, Lr: 0.000300
2024-05-19 13:10:12,649 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.243190, Batch Acc: 0.390843, Tokens per Sec:    19956, Lr: 0.000300
2024-05-19 13:10:17,232 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.355599, Batch Acc: 0.398839, Tokens per Sec:    15943, Lr: 0.000300
2024-05-19 13:10:17,233 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:10:17,233 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:10:26,541 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.33, ppl:  10.25, acc:   0.39, generation: 9.2006[sec], evaluation: 0.0000[sec]
2024-05-19 13:10:26,542 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:10:26,786 - INFO - joeynmt.helpers - delete bpe_model_4000/1000.ckpt
2024-05-19 13:10:26,797 - INFO - joeynmt.training - Example #0
2024-05-19 13:10:26,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:10:26,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:10:26,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'pi@@', 'eg@@', 'ico', 'che', 'la', 'pi@@', 'ena', 'di', 'v@@', 'ag@@', 'ina', ',', 'che', 'la', 'più', 'più', 'di', 'più', 'di', 'più', 'di', 'più', 'di', 'circa', 'il', '9@@', '3@@', '8', ',', 'ha', 'avuto', 'la', 'dimen@@', 'sione', 'del', '4@@', '5', '%', '.', '</s>']
2024-05-19 13:10:26,799 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:10:26,800 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:10:26,800 - INFO - joeynmt.training - 	Hypothesis: L'anno ho mostrato queste due piegico che la piena di vagina, che la più più di più di più di più di circa il 938, ha avuto la dimensione del 45%.
2024-05-19 13:10:26,800 - INFO - joeynmt.training - Example #1
2024-05-19 13:10:26,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:10:26,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:10:26,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'è', 'stata', 'la', 'questione', 'di', 'questa', 'problema', 'di', 'questa', 'problema', 'perché', 'non', 'è', 'mostr@@', 'ato', 'la', 'ver@@', 'ità', 'della', 'b@@', 'ast@@', 'ità', '.', '</s>']
2024-05-19 13:10:26,802 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:10:26,802 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:10:26,802 - INFO - joeynmt.training - 	Hypothesis: Ma questo è stata la questione di questa problema di questa problema perché non è mostrato la verità della bastità.
2024-05-19 13:10:26,802 - INFO - joeynmt.training - Example #2
2024-05-19 13:10:26,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:10:26,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:10:26,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'sistema', 'di', 'ghi@@', 'accio', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'sistema', 'di', 'carb@@', 'on@@', 'io', 'glob@@', 'ale', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:10:26,803 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:10:26,804 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:10:26,804 - INFO - joeynmt.training - 	Hypothesis: Il sistema di ghiaccio è, in un senso, il sistema di carbonio globale globale.
2024-05-19 13:10:26,804 - INFO - joeynmt.training - Example #3
2024-05-19 13:10:26,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:10:26,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:10:26,805 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'la', 'pi@@', 'ena', 'di', 's@@', 'post@@', 'e', 'in', 's@@', 'alt@@', 'a', '.', '</s>']
2024-05-19 13:10:26,805 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:10:26,805 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:10:26,806 - INFO - joeynmt.training - 	Hypothesis: E 'la piena di sposte in salta.
2024-05-19 13:10:26,806 - INFO - joeynmt.training - Example #4
2024-05-19 13:10:26,806 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:10:26,806 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:10:26,807 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'a@@', 'b', 'che', 'vi', 'mostr@@', 'erà', 'un', 'posto', 'più', 'difficile', 'da', 'parte', 'di', 'quello', 'che', 'è', 'successo', 'in', 'cui', 'il', '25', 'anni', '.', '</s>']
2024-05-19 13:10:26,807 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:10:26,807 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:10:26,808 - INFO - joeynmt.training - 	Hypothesis: L'ab che vi mostrerà un posto più difficile da parte di quello che è successo in cui il 25 anni.
2024-05-19 13:10:31,312 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.274662, Batch Acc: 0.398310, Tokens per Sec:    14783, Lr: 0.000300
2024-05-19 13:10:34,960 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.157862, Batch Acc: 0.409793, Tokens per Sec:    19429, Lr: 0.000300
2024-05-19 13:10:38,656 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.141015, Batch Acc: 0.407248, Tokens per Sec:    19805, Lr: 0.000300
2024-05-19 13:10:42,597 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.185656, Batch Acc: 0.414920, Tokens per Sec:    17969, Lr: 0.000300
2024-05-19 13:10:46,758 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.379304, Batch Acc: 0.420281, Tokens per Sec:    16859, Lr: 0.000300
2024-05-19 13:10:46,759 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:10:46,759 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:10:57,763 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.33, acc:   0.41, generation: 10.8021[sec], evaluation: 0.0000[sec]
2024-05-19 13:10:57,764 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:10:58,072 - INFO - joeynmt.helpers - delete bpe_model_4000/1500.ckpt
2024-05-19 13:10:58,088 - INFO - joeynmt.training - Example #0
2024-05-19 13:10:58,089 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:10:58,089 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:10:58,089 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'mostr@@', 'i', 'questi', 'due', 'due', 'milioni', 'di', 'due', 'milioni', 'di', 'anni', ',', 'che', 'per', 'la', 'maggior', 'parte', 'delle', 'tre', 'milioni', 'di', 'anni', 'ha', 'la', 'dimen@@', 'sione', 'del', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'la', 'dimen@@', 'sione', 'del', 'sol@@', 'e', ',', 'ha', 'avuto', 'il', 'co@@', 'sto', 'di', '4@@', '8', '%', '.', '</s>']
2024-05-19 13:10:58,090 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:10:58,090 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:10:58,091 - INFO - joeynmt.training - 	Hypothesis: L'anno mostri questi due due milioni di due milioni di anni, che per la maggior parte delle tre milioni di anni ha la dimensione del tre milioni di anni ha avuto la dimensione del sole, ha avuto il costo di 48%.
2024-05-19 13:10:58,091 - INFO - joeynmt.training - Example #1
2024-05-19 13:10:58,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:10:58,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:10:58,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'è', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'problema', 'perché', 'non', 'è', 'mostr@@', 'are', 'la', 'ver@@', 'ità', 'di', 'questo', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'la', 'ver@@', 'ità', 'della', '.', '</s>']
2024-05-19 13:10:58,093 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:10:58,093 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:10:58,093 - INFO - joeynmt.training - 	Hypothesis: Ma questo è capito la serie di questo problema perché non è mostrare la verità di questo problema perché non mostrano la verità della.
2024-05-19 13:10:58,093 - INFO - joeynmt.training - Example #2
2024-05-19 13:10:58,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:10:58,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:10:58,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'suo', 'att@@', 'ico', 'che', 'si', 'es@@', 'plo@@', 'sione', 'è', ',', 'il', 'suo', 'sistema', 'glob@@', 'ale', 'del', 'cli@@', 'mat@@', 'ico', '.', '</s>']
2024-05-19 13:10:58,095 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:10:58,095 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:10:58,095 - INFO - joeynmt.training - 	Hypothesis: Il suo attico che si esplosione è, il suo sistema globale del climatico.
2024-05-19 13:10:58,096 - INFO - joeynmt.training - Example #3
2024-05-19 13:10:58,096 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:10:58,096 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:10:58,096 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'es@@', 'es@@', 'su@@', 'su@@', 'to', 'e', 'si', 'ap@@', 'ap@@', 'i', '.', '</s>']
2024-05-19 13:10:58,097 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:10:58,097 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:10:58,098 - INFO - joeynmt.training - 	Hypothesis: E 'esessusuto e si apapi.
2024-05-19 13:10:58,098 - INFO - joeynmt.training - Example #4
2024-05-19 13:10:58,098 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:10:58,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:10:58,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'mostr@@', 'erò', 'un', 'atti@@', 'mo', 'di', 'quello', 'che', 'è', 'successo', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:10:58,099 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:10:58,100 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:10:58,100 - INFO - joeynmt.training - 	Hypothesis: La prossima mostrerò un attimo di quello che è successo di quello che è successo negli ultimi ultimi 25 anni.
2024-05-19 13:11:02,082 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.192859, Batch Acc: 0.426322, Tokens per Sec:    16709, Lr: 0.000300
2024-05-19 13:11:05,722 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     2.040077, Batch Acc: 0.429064, Tokens per Sec:    19536, Lr: 0.000300
2024-05-19 13:11:09,299 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     2.074519, Batch Acc: 0.432451, Tokens per Sec:    19911, Lr: 0.000300
2024-05-19 13:11:11,468 - INFO - joeynmt.training - Epoch   1: total training loss 12171.13
2024-05-19 13:11:11,468 - INFO - joeynmt.training - EPOCH 2
2024-05-19 13:11:13,877 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     2.175166, Batch Acc: 0.447582, Tokens per Sec:    15458, Lr: 0.000300
2024-05-19 13:11:17,506 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.867823, Batch Acc: 0.451142, Tokens per Sec:    19767, Lr: 0.000300
2024-05-19 13:11:17,506 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:11:17,507 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:11:28,972 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.15, ppl:   8.58, acc:   0.43, generation: 11.3576[sec], evaluation: 0.0000[sec]
2024-05-19 13:11:28,973 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:11:29,225 - INFO - joeynmt.helpers - delete bpe_model_4000/2000.ckpt
2024-05-19 13:11:29,230 - INFO - joeynmt.training - Example #0
2024-05-19 13:11:29,231 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:11:29,231 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:11:29,231 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'due', 'di', 'due', 'di', 'cui', 'ho', 'mostr@@', 'ato', 'che', 'i', 'c@@', '&@@', 'a@@', 'pos@@', ';', 'è', 'la', 'più', 'più', 'di', 'più', 'di', 'più', 'di', 'circa', '4@@', '8', '%', 'di', 'più', 'di', 'circa', '4@@', '8', '%', '.', '</s>']
2024-05-19 13:11:29,233 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:11:29,233 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:11:29,233 - INFO - joeynmt.training - 	Hypothesis: L'anno ho mostrato questi due due di due di cui ho mostrato che i c'è la più più di più di più di circa 48% di più di circa 48%.
2024-05-19 13:11:29,234 - INFO - joeynmt.training - Example #1
2024-05-19 13:11:29,234 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:11:29,234 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:11:29,234 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'problema', 'di', 'questo', 'problema', 'perché', 'non', 'è', 'il', 'problema', 'di', 'questo', 'problema', 'perché', 'non', 'è', 'la', 'ver@@', 'ità', '.', '</s>']
2024-05-19 13:11:29,235 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:11:29,235 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:11:29,236 - INFO - joeynmt.training - 	Hypothesis: Ma questo problema di questo problema perché non è il problema di questo problema perché non è la verità.
2024-05-19 13:11:29,236 - INFO - joeynmt.training - Example #2
2024-05-19 13:11:29,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:11:29,236 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:11:29,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'che', 'si', 'es@@', 'c@@', 'ic@@', 'ic@@', 'ic@@', 'ic@@', 'ato', 'è', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:11:29,237 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:11:29,237 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:11:29,238 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio che si escicicicicato è, il cuore globale.
2024-05-19 13:11:29,238 - INFO - joeynmt.training - Example #3
2024-05-19 13:11:29,238 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:11:29,238 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:11:29,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'es@@', 'es@@', 'c@@', 'ci@@', 'to', 'in', 'in@@', 'in@@', 'ver@@', 'no', 'e', 'in', 'ci@@', 'ma', '.', '</s>']
2024-05-19 13:11:29,239 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:11:29,239 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:11:29,240 - INFO - joeynmt.training - 	Hypothesis: E 'esesccito in ininverno e in cima.
2024-05-19 13:11:29,240 - INFO - joeynmt.training - Example #4
2024-05-19 13:11:29,240 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:11:29,240 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:11:29,241 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'prossi@@', 'ma', 'mostr@@', 'erò', 'un', 'punto', 'di', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:11:29,241 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:11:29,241 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:11:29,242 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima mostrerò un punto di più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:11:32,834 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     2.040756, Batch Acc: 0.455800, Tokens per Sec:    18453, Lr: 0.000300
2024-05-19 13:11:36,462 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.717831, Batch Acc: 0.453683, Tokens per Sec:    20146, Lr: 0.000300
2024-05-19 13:11:40,769 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.919349, Batch Acc: 0.458175, Tokens per Sec:    16659, Lr: 0.000300
2024-05-19 13:11:44,540 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.339601, Batch Acc: 0.458930, Tokens per Sec:    19322, Lr: 0.000300
2024-05-19 13:11:48,139 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.968018, Batch Acc: 0.461826, Tokens per Sec:    19780, Lr: 0.000300
2024-05-19 13:11:48,139 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:11:48,139 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:12:00,136 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.08, ppl:   8.03, acc:   0.45, generation: 11.8915[sec], evaluation: 0.0000[sec]
2024-05-19 13:12:00,137 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:12:00,377 - INFO - joeynmt.helpers - delete bpe_model_4000/2500.ckpt
2024-05-19 13:12:00,383 - INFO - joeynmt.training - Example #0
2024-05-19 13:12:00,384 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:12:00,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:12:00,384 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'due', 'a@@', 'str@@', 'ano', 'che', 'il', 'm@@', 'ese', 'che', 'il', 'c@@', 'acci@@', 'acci@@', 'a', ',', 'che', 'per', 'la', 'maggior', 'parte', 'del', '40', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'del', '40', '%', '.', '</s>']
2024-05-19 13:12:00,385 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:12:00,385 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:12:00,386 - INFO - joeynmt.training - 	Hypothesis: L'anno ho mostrato queste due due astrano che il mese che il cacciaccia, che per la maggior parte del 40 milioni di anni è stata la dimensione del 40%.
2024-05-19 13:12:00,386 - INFO - joeynmt.training - Example #1
2024-05-19 13:12:00,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:12:00,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:12:00,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'problema', 'di', 'questo', 'problema', 'di', 'questo', 'problema', ',', 'perché', 'non', 'è', 'mostr@@', 'ato', 'il', 'più', 'o', '.', '</s>']
2024-05-19 13:12:00,387 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:12:00,387 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:12:00,388 - INFO - joeynmt.training - 	Hypothesis: Ma questo problema di questo problema di questo problema, perché non è mostrato il più o.
2024-05-19 13:12:00,388 - INFO - joeynmt.training - Example #2
2024-05-19 13:12:00,388 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:12:00,388 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:12:00,388 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'sistema', 'c@@', 'att@@', 'ico', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:12:00,389 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:12:00,389 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:12:00,390 - INFO - joeynmt.training - 	Hypothesis: Il sistema cattico è, in un senso, il cuore globale del sistema globale.
2024-05-19 13:12:00,390 - INFO - joeynmt.training - Example #3
2024-05-19 13:12:00,390 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:12:00,391 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:12:00,391 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Le', 'man@@', 'i', 'in', 'v@@', 'est@@', 'ate', 'e', 'si', 'ap@@', 'pren@@', 'de', 'in', 'ci@@', 'ma', '.', '</s>']
2024-05-19 13:12:00,391 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:12:00,391 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:12:00,392 - INFO - joeynmt.training - 	Hypothesis: Le mani in vestate e si apprende in cima.
2024-05-19 13:12:00,392 - INFO - joeynmt.training - Example #4
2024-05-19 13:12:00,392 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:12:00,392 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:12:00,393 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prossi@@', 'mo', 'prossi@@', 'mo', 'mostr@@', 'o', 'un', 'po', '&@@', 'a@@', 'pos@@', ';', 'più', 'veloc@@', 'ità', 'di', 'cosa', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:12:00,393 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:12:00,393 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:12:00,394 - INFO - joeynmt.training - 	Hypothesis: Il prossimo prossimo mostro un po 'più velocità di cosa è successo negli ultimi 25 anni.
2024-05-19 13:12:03,979 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.911353, Batch Acc: 0.464637, Tokens per Sec:    18635, Lr: 0.000300
2024-05-19 13:12:08,118 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.981423, Batch Acc: 0.463141, Tokens per Sec:    16911, Lr: 0.000300
2024-05-19 13:12:12,080 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.957436, Batch Acc: 0.470810, Tokens per Sec:    17648, Lr: 0.000300
2024-05-19 13:12:15,625 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.939512, Batch Acc: 0.472471, Tokens per Sec:    20074, Lr: 0.000300
2024-05-19 13:12:19,271 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     1.899062, Batch Acc: 0.473505, Tokens per Sec:    19502, Lr: 0.000300
2024-05-19 13:12:19,272 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:12:19,272 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:12:29,858 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.03, ppl:   7.59, acc:   0.46, generation: 10.4848[sec], evaluation: 0.0000[sec]
2024-05-19 13:12:29,859 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:12:30,126 - INFO - joeynmt.helpers - delete bpe_model_4000/3000.ckpt
2024-05-19 13:12:30,136 - INFO - joeynmt.training - Example #0
2024-05-19 13:12:30,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:12:30,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:12:30,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'due', 'a@@', 'str@@', 'at@@', 'ti', 'che', 'il', 'c@@', 'ant@@', 'ico', 'che', 'il', 'c@@', 'ant@@', 'ico', ',', 'per', 'la', 'maggior', 'parte', 'di', 'tre', 'milioni', 'di', 'anni', 'è', 'stato', 'la', 'dimen@@', 'sione', 'del', '4@@', '8', '%', '.', '</s>']
2024-05-19 13:12:30,139 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:12:30,139 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:12:30,139 - INFO - joeynmt.training - 	Hypothesis: L'anno ho mostrato questi due due astratti che il cantico che il cantico, per la maggior parte di tre milioni di anni è stato la dimensione del 48%.
2024-05-19 13:12:30,140 - INFO - joeynmt.training - Example #1
2024-05-19 13:12:30,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:12:30,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:12:30,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'problema', 'di', 'questo', 'problema', 'è', 'una', 'serie', 'di', 'questo', 'problema', 'perché', 'non', 'è', 'la', 'ver@@', 'ità', 'della', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:12:30,141 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:12:30,141 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:12:30,141 - INFO - joeynmt.training - 	Hypothesis: Ma questo problema di questo problema è una serie di questo problema perché non è la verità della ghiaccio.
2024-05-19 13:12:30,142 - INFO - joeynmt.training - Example #2
2024-05-19 13:12:30,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:12:30,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:12:30,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'sistema', 'di', 'ghi@@', 'accio', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'sistema', 'di', 'cu@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:12:30,143 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:12:30,143 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:12:30,144 - INFO - joeynmt.training - 	Hypothesis: Il sistema di ghiaccio è, in un senso, il sistema di cuore globale.
2024-05-19 13:12:30,144 - INFO - joeynmt.training - Example #3
2024-05-19 13:12:30,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:12:30,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:12:30,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'es@@', 'p@@', 'into', 'e', 'in', 'ver@@', 'sione', '.', '</s>']
2024-05-19 13:12:30,145 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:12:30,145 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:12:30,145 - INFO - joeynmt.training - 	Hypothesis: E 'espinto e in versione.
2024-05-19 13:12:30,146 - INFO - joeynmt.training - Example #4
2024-05-19 13:12:30,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:12:30,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:12:30,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'che', 'vi', 'mostr@@', 'i', 'un', 'punto', 'di', 'vista', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:12:30,147 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:12:30,147 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:12:30,147 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostri un punto di vista più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:12:33,715 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     1.945480, Batch Acc: 0.484117, Tokens per Sec:    18375, Lr: 0.000300
2024-05-19 13:12:38,220 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     2.021173, Batch Acc: 0.479119, Tokens per Sec:    15710, Lr: 0.000300
2024-05-19 13:12:41,818 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     2.080828, Batch Acc: 0.482005, Tokens per Sec:    20284, Lr: 0.000300
2024-05-19 13:12:45,350 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     1.972912, Batch Acc: 0.484432, Tokens per Sec:    19988, Lr: 0.000300
2024-05-19 13:12:49,210 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.978202, Batch Acc: 0.482702, Tokens per Sec:    18232, Lr: 0.000300
2024-05-19 13:12:49,211 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:12:49,211 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:12:59,858 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.25, acc:   0.47, generation: 10.5419[sec], evaluation: 0.0000[sec]
2024-05-19 13:12:59,858 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:13:00,106 - INFO - joeynmt.helpers - delete bpe_model_4000/3500.ckpt
2024-05-19 13:13:00,118 - INFO - joeynmt.training - Example #0
2024-05-19 13:13:00,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:13:00,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:13:00,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'che', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'ar@@', 'mon@@', 'ico', 'che', 'il', 're@@', 'c@@', 'ed@@', 'ico', ',', 'che', 'per', 'la', 'maggior', 'parte', 'della', 'dimen@@', 'sione', ',', 'che', 'per', 'la', 'maggior', 'parte', 'del', '40', '%', '.', '</s>']
2024-05-19 13:13:00,120 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:13:00,120 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:13:00,120 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso l'anno che l'armonico che il recedico, che per la maggior parte della dimensione, che per la maggior parte del 40%.
2024-05-19 13:13:00,121 - INFO - joeynmt.training - Example #1
2024-05-19 13:13:00,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:13:00,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:13:00,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'è', 'com@@', 'posto', 'che', 'la', 'serie', 'di', 'questo', 'problema', 'perché', 'non', 'è', 'il', 'mo@@', 'tivo', 'perché', 'non', 'mostr@@', 'ano', 'il', 't@@', 'etto', 'della', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:13:00,122 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:13:00,122 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:13:00,122 - INFO - joeynmt.training - 	Hypothesis: Ma questo è composto che la serie di questo problema perché non è il motivo perché non mostrano il tetto della ghiaccio.
2024-05-19 13:13:00,123 - INFO - joeynmt.training - Example #2
2024-05-19 13:13:00,123 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:13:00,123 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:13:00,123 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'sistema', 'di', 'ghi@@', 'accio', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'sistema', 'di', 'ap@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:13:00,124 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:13:00,124 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:13:00,124 - INFO - joeynmt.training - 	Hypothesis: Il sistema di ghiaccio è, in un senso, il sistema di apore globale.
2024-05-19 13:13:00,125 - INFO - joeynmt.training - Example #3
2024-05-19 13:13:00,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:13:00,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:13:00,125 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'es@@', 'p@@', 'into', 'e', 'si', 'est@@', 'ate', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:13:00,126 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:13:00,126 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:13:00,126 - INFO - joeynmt.training - 	Hypothesis: E 'espinto e si estate in estate.
2024-05-19 13:13:00,127 - INFO - joeynmt.training - Example #4
2024-05-19 13:13:00,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:13:00,127 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:13:00,127 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prossi@@', 'mo', 'di@@', 'a@@', 'positi@@', 'vo', 'che', 'vi', 'mostr@@', 'erà', 'una', 'rapi@@', 'd@@', 'amente', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:13:00,128 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:13:00,128 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:13:00,128 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostrerà una rapidamente veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:13:04,215 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.901239, Batch Acc: 0.490474, Tokens per Sec:    16976, Lr: 0.000300
2024-05-19 13:13:08,244 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     2.040254, Batch Acc: 0.486580, Tokens per Sec:    18025, Lr: 0.000300
2024-05-19 13:13:11,853 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.974639, Batch Acc: 0.494816, Tokens per Sec:    19217, Lr: 0.000300
2024-05-19 13:13:15,505 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.830452, Batch Acc: 0.487630, Tokens per Sec:    19520, Lr: 0.000300
2024-05-19 13:13:19,981 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     1.975226, Batch Acc: 0.500000, Tokens per Sec:    16375, Lr: 0.000300
2024-05-19 13:13:19,982 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:13:19,982 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:13:30,459 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.96, acc:   0.48, generation: 10.2827[sec], evaluation: 0.0000[sec]
2024-05-19 13:13:30,460 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:13:30,761 - INFO - joeynmt.helpers - delete bpe_model_4000/4000.ckpt
2024-05-19 13:13:30,766 - INFO - joeynmt.training - Example #0
2024-05-19 13:13:30,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:13:30,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:13:30,767 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'anno', 'scor@@', 'so', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'due', 'di@@', 'a@@', 'str@@', 'ico', ',', 'che', 'la', 'maggior', 'parte', 'dei', 'tre', 'milioni', 'di', 'anni', 'è', 'stato', 'la', 'dimen@@', 'sione', 'del', '40', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '40', '.', '</s>']
2024-05-19 13:13:30,768 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:13:30,769 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:13:30,769 - INFO - joeynmt.training - 	Hypothesis: L'anno anno scorso, ho mostrato queste due due diastrico, che la maggior parte dei tre milioni di anni è stato la dimensione del 40 anni è stata la dimensione di 40.
2024-05-19 13:13:30,769 - INFO - joeynmt.training - Example #1
2024-05-19 13:13:30,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:13:30,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:13:30,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'è', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'problema', 'perché', 'non', 'è', 'mostr@@', 'ato', 'la', 'ver@@', 'ità', 'del', 'gen@@', 'ere', '.', '</s>']
2024-05-19 13:13:30,771 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:13:30,771 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:13:30,771 - INFO - joeynmt.training - 	Hypothesis: Ma questo è capito la serie di questo problema perché non è mostrato la verità del genere.
2024-05-19 13:13:30,771 - INFO - joeynmt.training - Example #2
2024-05-19 13:13:30,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:13:30,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:13:30,772 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'suo', 'ar@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:13:30,773 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:13:30,773 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:13:30,773 - INFO - joeynmt.training - 	Hypothesis: Il suo artico è, in un senso, il cuore del sistema globale.
2024-05-19 13:13:30,773 - INFO - joeynmt.training - Example #3
2024-05-19 13:13:30,773 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:13:30,774 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:13:30,774 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'in', 'effetti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:13:30,774 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:13:30,775 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:13:30,775 - INFO - joeynmt.training - 	Hypothesis: E 'inverno e in effetti in estate.
2024-05-19 13:13:30,775 - INFO - joeynmt.training - Example #4
2024-05-19 13:13:30,775 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:13:30,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:13:30,775 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prossi@@', 'mo', 'mostr@@', 'o', 'un', 'for@@', 'zo', 'rapi@@', 'd@@', 'amente', 'in', 'alto', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:13:30,776 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:13:30,776 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:13:30,776 - INFO - joeynmt.training - 	Hypothesis: Il prossimo mostro un forzo rapidamente in alto di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:13:35,301 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     1.800359, Batch Acc: 0.497877, Tokens per Sec:    14689, Lr: 0.000300
2024-05-19 13:13:38,894 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     2.067923, Batch Acc: 0.499092, Tokens per Sec:    19930, Lr: 0.000300
2024-05-19 13:13:42,441 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.797854, Batch Acc: 0.496782, Tokens per Sec:    19849, Lr: 0.000300
2024-05-19 13:13:46,448 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     1.849340, Batch Acc: 0.503820, Tokens per Sec:    18490, Lr: 0.000300
2024-05-19 13:13:50,467 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     1.897735, Batch Acc: 0.505207, Tokens per Sec:    17515, Lr: 0.000300
2024-05-19 13:13:50,468 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:13:50,468 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:14:01,493 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.78, acc:   0.49, generation: 10.8284[sec], evaluation: 0.0000[sec]
2024-05-19 13:14:01,494 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:14:01,802 - INFO - joeynmt.helpers - delete bpe_model_4000/4500.ckpt
2024-05-19 13:14:01,807 - INFO - joeynmt.training - Example #0
2024-05-19 13:14:01,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:14:01,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:14:01,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', ',', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'a@@', 'positi@@', 'vi', 'che', 'il', 'più', 'più', 'am@@', 'pio', ',', 'che', 'per', 'la', 'maggior', 'parte', 'dei', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'stati', 'il', '4@@', '8', '%', '.', '</s>']
2024-05-19 13:14:01,810 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:14:01,810 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:14:01,811 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso, ho mostrato questi due diapositivi che il più più ampio, che per la maggior parte dei tre milioni di anni sono stati stati il 48%.
2024-05-19 13:14:01,811 - INFO - joeynmt.training - Example #1
2024-05-19 13:14:01,811 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:14:01,811 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:14:01,811 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'to', 'la', 'ser@@', 'ia', 'di', 'questo', 'problema', ',', 'perché', 'non', 'mostr@@', 'ano', 'il', 'più', 'profon@@', 'do', '.', '</s>']
2024-05-19 13:14:01,812 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:14:01,812 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:14:01,813 - INFO - joeynmt.training - 	Hypothesis: Ma questo capito la seria di questo problema, perché non mostrano il più profondo.
2024-05-19 13:14:01,813 - INFO - joeynmt.training - Example #2
2024-05-19 13:14:01,813 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:14:01,813 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:14:01,813 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'sistema', 'di', 'ghi@@', 'accio', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:14:01,814 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:14:01,814 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:14:01,815 - INFO - joeynmt.training - 	Hypothesis: Il sistema di ghiaccio è, in un senso, il cuore del sistema globale.
2024-05-19 13:14:01,815 - INFO - joeynmt.training - Example #3
2024-05-19 13:14:01,815 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:14:01,815 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:14:01,815 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'in@@', 'p@@', 'ing@@', 'ere', 'in', 'est@@', 'ate', 'e', 'si', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:14:01,816 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:14:01,816 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:14:01,817 - INFO - joeynmt.training - 	Hypothesis: Spinpingere in estate e si estate.
2024-05-19 13:14:01,817 - INFO - joeynmt.training - Example #4
2024-05-19 13:14:01,817 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:14:01,817 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:14:01,817 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'i', 'un', 'po', '&@@', 'a@@', 'pos@@', ';', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:14:01,818 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:14:01,818 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:14:01,819 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostri un po 'più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:14:05,677 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     1.874336, Batch Acc: 0.503861, Tokens per Sec:    17433, Lr: 0.000300
2024-05-19 13:14:09,311 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     1.769543, Batch Acc: 0.506981, Tokens per Sec:    19968, Lr: 0.000300
2024-05-19 13:14:13,045 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     1.803407, Batch Acc: 0.502572, Tokens per Sec:    19735, Lr: 0.000300
2024-05-19 13:14:17,453 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     1.913188, Batch Acc: 0.505334, Tokens per Sec:    16100, Lr: 0.000300
2024-05-19 13:14:21,033 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     1.885310, Batch Acc: 0.505417, Tokens per Sec:    20216, Lr: 0.000300
2024-05-19 13:14:21,034 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:14:21,034 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:14:31,588 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.55, acc:   0.50, generation: 10.4458[sec], evaluation: 0.0000[sec]
2024-05-19 13:14:31,589 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:14:31,843 - INFO - joeynmt.helpers - delete bpe_model_4000/5000.ckpt
2024-05-19 13:14:31,854 - INFO - joeynmt.training - Example #0
2024-05-19 13:14:31,855 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:14:31,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:14:31,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'due', 'a@@', 'positi@@', 've', 'che', 'hanno', 'mostr@@', 'ato', 'che', 'il', 'br@@', 'accio', 'c@@', '&@@', 'a@@', 'pos@@', ';', 'è', 'stato', 'stato', 'il', 'c@@', 'ento', 'di', 'circa', '4@@', '8', 'milioni', 'di', 'anni', 'sono', 'stati', 'stati', ',', 'ha', 'fatto', 'che', 'la', 'dimen@@', 'sione', '4@@', '8', '%', '.', '</s>']
2024-05-19 13:14:31,857 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:14:31,857 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:14:31,857 - INFO - joeynmt.training - 	Hypothesis: L'anno ho mostrato questi due due apositive che hanno mostrato che il braccio c'è stato stato il cento di circa 48 milioni di anni sono stati stati, ha fatto che la dimensione 48%.
2024-05-19 13:14:31,858 - INFO - joeynmt.training - Example #1
2024-05-19 13:14:31,858 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:14:31,858 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:14:31,858 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'to', 'che', 'questo', 'problema', ',', 'perché', 'non', 'mostr@@', 'ano', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'altro', ',', 'perché', 'non', 'mostr@@', 'ano', 'il', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:14:31,859 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:14:31,859 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:14:31,859 - INFO - joeynmt.training - 	Hypothesis: Ma questo capito che questo problema, perché non mostrano l'altro, perché non mostrano il ghiaccio.
2024-05-19 13:14:31,860 - INFO - joeynmt.training - Example #2
2024-05-19 13:14:31,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:14:31,860 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:14:31,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'c@@', '&@@', 'a@@', 'pos@@', ';', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:14:31,861 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:14:31,861 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:14:31,862 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio c'è, in un senso, il cuore del sistema globale.
2024-05-19 13:14:31,862 - INFO - joeynmt.training - Example #3
2024-05-19 13:14:31,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:14:31,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:14:31,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'ing@@', 'e', 'in', 'v@@', 'est@@', 'ito', 'e', 'in@@', 'fatti', '.', '</s>']
2024-05-19 13:14:31,863 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:14:31,863 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:14:31,864 - INFO - joeynmt.training - 	Hypothesis: Spinge in vestito e infatti.
2024-05-19 13:14:31,864 - INFO - joeynmt.training - Example #4
2024-05-19 13:14:31,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:14:31,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:14:31,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'i', 'un', 'po', '&@@', 'a@@', 'pos@@', ';', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:14:31,865 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:14:31,866 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:14:31,866 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostri un po 'di quello che è successo negli ultimi 25 anni.
2024-05-19 13:14:35,479 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     1.708200, Batch Acc: 0.512335, Tokens per Sec:    18714, Lr: 0.000300
2024-05-19 13:14:39,052 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     1.668964, Batch Acc: 0.513525, Tokens per Sec:    19931, Lr: 0.000300
2024-05-19 13:14:43,054 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     1.763059, Batch Acc: 0.507989, Tokens per Sec:    17990, Lr: 0.000300
2024-05-19 13:14:47,191 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     1.796872, Batch Acc: 0.509833, Tokens per Sec:    17408, Lr: 0.000300
2024-05-19 13:14:50,767 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     1.669386, Batch Acc: 0.512336, Tokens per Sec:    19386, Lr: 0.000300
2024-05-19 13:14:50,767 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:14:50,768 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:15:02,783 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.39, acc:   0.50, generation: 11.9083[sec], evaluation: 0.0000[sec]
2024-05-19 13:15:02,784 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:15:03,063 - INFO - joeynmt.helpers - delete bpe_model_4000/5500.ckpt
2024-05-19 13:15:03,067 - INFO - joeynmt.training - Example #0
2024-05-19 13:15:03,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:15:03,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:15:03,069 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'a@@', 'positi@@', 've', ',', 'quindi', 'che', 'il', 'br@@', 'accio', 'c@@', '&@@', 'a@@', 'pos@@', ';', 'è', 'stato', 'il', 'c@@', 'uc@@', 'co', 'di', 'circa', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', 'circa', '4@@', '8', '%', '.', '</s>']
2024-05-19 13:15:03,069 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:15:03,070 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:15:03,070 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato questi due apositive, quindi che il braccio c'è stato il cucco di circa tre milioni di anni è stata la dimensione di circa 48%.
2024-05-19 13:15:03,070 - INFO - joeynmt.training - Example #1
2024-05-19 13:15:03,070 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:15:03,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:15:03,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'è', 'capi@@', 'to', 'la', 'ser@@', 'a', 'questo', 'problema', ',', 'perché', 'non', 'si', 'mostr@@', 'ano', 'il', 't@@', 'ab@@', 'br@@', 'accio', '.', '</s>']
2024-05-19 13:15:03,071 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:15:03,072 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:15:03,072 - INFO - joeynmt.training - 	Hypothesis: Ma questo è capito la sera questo problema, perché non si mostrano il tabbraccio.
2024-05-19 13:15:03,072 - INFO - joeynmt.training - Example #2
2024-05-19 13:15:03,072 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:15:03,073 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:15:03,073 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'c@@', '&@@', 'a@@', 'pos@@', ';', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'sistema', 'di', 'att@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:15:03,073 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:15:03,074 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:15:03,074 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio c'è, in un senso, il sistema di attore globale.
2024-05-19 13:15:03,074 - INFO - joeynmt.training - Example #3
2024-05-19 13:15:03,074 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:15:03,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:15:03,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'ing@@', 'ere', 'le', 'man@@', 'i', 'e', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:15:03,075 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:15:03,075 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:15:03,076 - INFO - joeynmt.training - 	Hypothesis: Spingere le mani e in estate.
2024-05-19 13:15:03,076 - INFO - joeynmt.training - Example #4
2024-05-19 13:15:03,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:15:03,076 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:15:03,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'vi', 'mostr@@', 'arvi', 'una', 'rapi@@', 'd@@', 'amente', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:15:03,077 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:15:03,077 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:15:03,078 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva vi mostrarvi una rapidamente veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:15:06,667 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     1.847347, Batch Acc: 0.514606, Tokens per Sec:    18151, Lr: 0.000300
2024-05-19 13:15:10,588 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     1.954621, Batch Acc: 0.519311, Tokens per Sec:    18363, Lr: 0.000300
2024-05-19 13:15:14,983 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     1.688901, Batch Acc: 0.517459, Tokens per Sec:    16476, Lr: 0.000300
2024-05-19 13:15:18,686 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     1.747997, Batch Acc: 0.512197, Tokens per Sec:    19166, Lr: 0.000300
2024-05-19 13:15:22,323 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     1.732646, Batch Acc: 0.511623, Tokens per Sec:    19405, Lr: 0.000300
2024-05-19 13:15:22,323 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:15:22,324 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:15:33,872 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.82, ppl:   6.19, acc:   0.51, generation: 11.4365[sec], evaluation: 0.0000[sec]
2024-05-19 13:15:33,873 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:15:34,150 - INFO - joeynmt.helpers - delete bpe_model_4000/6000.ckpt
2024-05-19 13:15:34,154 - INFO - joeynmt.training - Example #0
2024-05-19 13:15:34,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:15:34,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:15:34,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'a@@', 'positi@@', 've', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'inter@@', 'v@@', 'ento', 'di', 'circa', '4@@', '8', '%', '.', '</s>']
2024-05-19 13:15:34,156 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:15:34,157 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:15:34,157 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso, ho mostrato queste due apositive, che per la maggior parte degli ultimi tre milioni di anni sono stati l'intervento di circa 48%.
2024-05-19 13:15:34,157 - INFO - joeynmt.training - Example #1
2024-05-19 13:15:34,157 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:15:34,158 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:15:34,158 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'ser@@', 'ia', 'di', 'questo', 'particol@@', 'are', 'perché', 'non', 'mostr@@', 'ano', 'il', 'mo@@', 'tivo', '.', '</s>']
2024-05-19 13:15:34,159 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:15:34,159 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:15:34,159 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la seria di questo particolare perché non mostrano il motivo.
2024-05-19 13:15:34,159 - INFO - joeynmt.training - Example #2
2024-05-19 13:15:34,160 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:15:34,160 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:15:34,160 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 't@@', 't@@', 'ico', 'c@@', '&@@', 'a@@', 'pos@@', ';', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:15:34,161 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:15:34,161 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:15:34,161 - INFO - joeynmt.training - 	Hypothesis: Il ttico c'è, in un senso, il cuore del sistema globale.
2024-05-19 13:15:34,161 - INFO - joeynmt.training - Example #3
2024-05-19 13:15:34,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:15:34,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:15:34,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'es@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'si', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:15:34,162 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:15:34,163 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:15:34,163 - INFO - joeynmt.training - 	Hypothesis: E espande in estate e si estate.
2024-05-19 13:15:34,163 - INFO - joeynmt.training - Example #4
2024-05-19 13:15:34,164 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:15:34,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:15:34,164 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'prossi@@', 'ma', 'mostr@@', 'erò', 'una', 'rapi@@', 'd@@', 'amente', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:15:34,164 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:15:34,164 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:15:34,164 - INFO - joeynmt.training - 	Hypothesis: La prossima prossima mostrerò una rapidamente più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:15:37,775 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     1.620945, Batch Acc: 0.515107, Tokens per Sec:    18382, Lr: 0.000300
2024-05-19 13:15:42,261 - INFO - joeynmt.training - Epoch   2: total training loss 8251.46
2024-05-19 13:15:42,262 - INFO - joeynmt.training - EPOCH 3
2024-05-19 13:15:42,349 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     1.765773, Batch Acc: 0.523013, Tokens per Sec:    16627, Lr: 0.000300
2024-05-19 13:15:45,876 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     1.595192, Batch Acc: 0.541725, Tokens per Sec:    19696, Lr: 0.000300
2024-05-19 13:15:49,522 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.622200, Batch Acc: 0.543991, Tokens per Sec:    20094, Lr: 0.000300
2024-05-19 13:15:53,577 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.659899, Batch Acc: 0.544192, Tokens per Sec:    17780, Lr: 0.000300
2024-05-19 13:15:53,577 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:15:53,578 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:16:03,982 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.06, acc:   0.52, generation: 10.3002[sec], evaluation: 0.0000[sec]
2024-05-19 13:16:03,983 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:16:04,246 - INFO - joeynmt.helpers - delete bpe_model_4000/6500.ckpt
2024-05-19 13:16:04,257 - INFO - joeynmt.training - Example #0
2024-05-19 13:16:04,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:16:04,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:16:04,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'a@@', 'positi@@', 've', 'che', 'la', 'di@@', 'mostr@@', 'i', 'che', 'la', 'pol@@', 'izi@@', 'a', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', 'bas@@', 'so', 'di', '4@@', '8', '%', '.', '</s>']
2024-05-19 13:16:04,260 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:16:04,260 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:16:04,260 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due apositive che la dimostri che la polizia, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione di basso di 48%.
2024-05-19 13:16:04,260 - INFO - joeynmt.training - Example #1
2024-05-19 13:16:04,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:16:04,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:16:04,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questa', 'ha', 'capi@@', 'to', 'la', 'ser@@', 'ia', 'di', 'questo', 'particol@@', 'are', 'perché', 'non', 'mostr@@', 'ano', 'il', 'problema', 'non', 'mostr@@', 'ano', 'il', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:16:04,262 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:16:04,262 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:16:04,262 - INFO - joeynmt.training - 	Hypothesis: Ma questa ha capito la seria di questo particolare perché non mostrano il problema non mostrano il ghiaccio.
2024-05-19 13:16:04,263 - INFO - joeynmt.training - Example #2
2024-05-19 13:16:04,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:16:04,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:16:04,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 't@@', 'el@@', 'abor@@', 'ato', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'glob@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:16:04,264 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:16:04,264 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:16:04,264 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio telaborato è, in un senso, il cuore globale del sistema globale.
2024-05-19 13:16:04,264 - INFO - joeynmt.training - Example #3
2024-05-19 13:16:04,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:16:04,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:16:04,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'uc@@', 'c@@', 'ere', 'in', 'v@@', 'int@@', 'a', 'e', 'cont@@', 'ra@@', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:16:04,266 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:16:04,266 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:16:04,266 - INFO - joeynmt.training - 	Hypothesis: Succere in vinta e contrad'estate.
2024-05-19 13:16:04,266 - INFO - joeynmt.training - Example #4
2024-05-19 13:16:04,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:16:04,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:16:04,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'una', 'rapi@@', 'd@@', 'amente', 'più', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:16:04,268 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:16:04,268 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:16:04,268 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò una rapidamente più veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:16:08,472 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.645925, Batch Acc: 0.537414, Tokens per Sec:    16048, Lr: 0.000300
2024-05-19 13:16:12,519 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.737069, Batch Acc: 0.538874, Tokens per Sec:    17384, Lr: 0.000300
2024-05-19 13:16:16,130 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.766244, Batch Acc: 0.539567, Tokens per Sec:    19489, Lr: 0.000300
2024-05-19 13:16:19,686 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     1.638484, Batch Acc: 0.541143, Tokens per Sec:    19925, Lr: 0.000300
2024-05-19 13:16:24,211 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     1.656513, Batch Acc: 0.543070, Tokens per Sec:    15819, Lr: 0.000300
2024-05-19 13:16:24,212 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:16:24,212 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:16:34,601 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.97, acc:   0.52, generation: 10.1958[sec], evaluation: 0.0000[sec]
2024-05-19 13:16:34,604 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:16:34,886 - INFO - joeynmt.helpers - delete bpe_model_4000/7000.ckpt
2024-05-19 13:16:34,902 - INFO - joeynmt.training - Example #0
2024-05-19 13:16:34,903 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:16:34,903 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:16:34,904 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', ',', 'che', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'ar@@', 'c@@', 'ica', 'che', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'ar@@', 'te', 'di', '4@@', '8', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', 'il', '40', '%', '.', '</s>']
2024-05-19 13:16:34,905 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:16:34,905 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:16:34,905 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso scorso ho mostrato queste due diapositive, che l'arcica che l'arte di 48 milioni di anni è stata la dimensione di il 40%.
2024-05-19 13:16:34,906 - INFO - joeynmt.training - Example #1
2024-05-19 13:16:34,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:16:34,906 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:16:34,906 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'il', 'problema', 'perché', 'non', 'mostr@@', 'a', 'il', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:16:34,907 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:16:34,907 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:16:34,908 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo problema perché non mostrano il problema perché non mostra il ghiaccio.
2024-05-19 13:16:34,908 - INFO - joeynmt.training - Example #2
2024-05-19 13:16:34,908 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:16:34,908 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:16:34,909 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'c@@', 'att@@', 'ico', 'è', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'un', 'certo', 'senso', ',', 'il', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:16:34,909 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:16:34,910 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:16:34,910 - INFO - joeynmt.training - 	Hypothesis: Il cattico è un certo senso, il cuore di un certo senso, il sistema globale.
2024-05-19 13:16:34,910 - INFO - joeynmt.training - Example #3
2024-05-19 13:16:34,911 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:16:34,911 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:16:34,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:16:34,912 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:16:34,912 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:16:34,912 - INFO - joeynmt.training - 	Hypothesis: Spande in estate e contratti in estate.
2024-05-19 13:16:34,912 - INFO - joeynmt.training - Example #4
2024-05-19 13:16:34,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:16:34,913 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:16:34,913 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'una', 'rapi@@', 'da', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:16:34,914 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:16:34,914 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:16:34,914 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò una rapida veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:16:39,412 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     1.751972, Batch Acc: 0.542134, Tokens per Sec:    15172, Lr: 0.000300
2024-05-19 13:16:43,077 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     1.673405, Batch Acc: 0.539354, Tokens per Sec:    19245, Lr: 0.000300
2024-05-19 13:16:46,647 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     1.588810, Batch Acc: 0.539136, Tokens per Sec:    20249, Lr: 0.000300
2024-05-19 13:16:50,835 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.730352, Batch Acc: 0.543123, Tokens per Sec:    17380, Lr: 0.000300
2024-05-19 13:16:54,815 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     1.707730, Batch Acc: 0.544570, Tokens per Sec:    17990, Lr: 0.000300
2024-05-19 13:16:54,816 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:16:54,816 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:17:05,449 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.89, acc:   0.52, generation: 10.4403[sec], evaluation: 0.0000[sec]
2024-05-19 13:17:05,450 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:17:05,784 - INFO - joeynmt.helpers - delete bpe_model_4000/7500.ckpt
2024-05-19 13:17:05,800 - INFO - joeynmt.training - Example #0
2024-05-19 13:17:05,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:17:05,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:17:05,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'di@@', 'mo@@', 'stra@@', 'de', 'che', 'la', 'c@@', 'att@@', 'a', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'bas@@', 'so', 'il', '40', '%', '.', '</s>']
2024-05-19 13:17:05,802 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:17:05,803 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:17:05,803 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diapositive che la dimostrade che la catta, che per la maggior parte degli ultimi tre milioni di anni sono stati le dimensioni di basso il 40%.
2024-05-19 13:17:05,803 - INFO - joeynmt.training - Example #1
2024-05-19 13:17:05,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:17:05,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:17:05,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'è', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'il', 't@@', 'ello', 'di', 'ghi@@', 'accio', 'perché', 'non', 'mostr@@', 'ano', 'il', 'ghi@@', 'accio', 'della', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:17:05,804 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:17:05,805 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:17:05,805 - INFO - joeynmt.training - 	Hypothesis: Ma questo è capito la serie di questo problema perché non mostrano il tello di ghiaccio perché non mostrano il ghiaccio della ghiaccio.
2024-05-19 13:17:05,805 - INFO - joeynmt.training - Example #2
2024-05-19 13:17:05,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:17:05,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:17:05,805 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 't@@', 'es@@', 'c@@', 'ic@@', 'ina', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'sistema', 'glob@@', 'ale', 'del', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:17:05,806 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:17:05,806 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:17:05,807 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio tescicina è, in un senso, il sistema globale del climatico globale.
2024-05-19 13:17:05,807 - INFO - joeynmt.training - Example #3
2024-05-19 13:17:05,807 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:17:05,807 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:17:05,807 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:17:05,808 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:17:05,808 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:17:05,808 - INFO - joeynmt.training - 	Hypothesis: Sppande in estate e contratti in estate.
2024-05-19 13:17:05,809 - INFO - joeynmt.training - Example #4
2024-05-19 13:17:05,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:17:05,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:17:05,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prossi@@', 'mo', 'di@@', 'a@@', 'positi@@', 'vo', 'che', 'vi', 'mostr@@', 'i', 'una', 'rapi@@', 'd@@', 'amente', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:17:05,810 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:17:05,810 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:17:05,810 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostri una rapidamente di quello che è successo negli ultimi 25 anni.
2024-05-19 13:17:09,643 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     1.476557, Batch Acc: 0.543599, Tokens per Sec:    16899, Lr: 0.000300
2024-05-19 13:17:13,188 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     1.428284, Batch Acc: 0.544638, Tokens per Sec:    20134, Lr: 0.000300
2024-05-19 13:17:16,869 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.820818, Batch Acc: 0.538949, Tokens per Sec:    19422, Lr: 0.000300
2024-05-19 13:17:21,299 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     1.717146, Batch Acc: 0.544303, Tokens per Sec:    16497, Lr: 0.000300
2024-05-19 13:17:24,902 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.752643, Batch Acc: 0.538725, Tokens per Sec:    19728, Lr: 0.000300
2024-05-19 13:17:24,902 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:17:24,902 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:17:34,985 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.82, acc:   0.52, generation: 9.9644[sec], evaluation: 0.0000[sec]
2024-05-19 13:17:34,986 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:17:35,246 - INFO - joeynmt.helpers - delete bpe_model_4000/8000.ckpt
2024-05-19 13:17:35,251 - INFO - joeynmt.training - Example #0
2024-05-19 13:17:35,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:17:35,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:17:35,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'il', 'ghi@@', 'accio', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'dimen@@', 'sioni', 'di', 'circa', '8', 'st@@', 'av@@', 'i', ',', 'ha', 'di@@', 'vi@@', 'aggi@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:17:35,253 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:17:35,253 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:17:35,254 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive che il ghiaccio, che per la maggior parte degli ultimi tre milioni di anni sono state dimensioni di circa 8 stavi, ha diviaggiato dal 40%.
2024-05-19 13:17:35,254 - INFO - joeynmt.training - Example #1
2024-05-19 13:17:35,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:17:35,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:17:35,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'è', 'capi@@', 'to', 'che', 'il', 'problema', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'il', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:17:35,255 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:17:35,256 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:17:35,256 - INFO - joeynmt.training - 	Hypothesis: Ma questo è capito che il problema di questo particolare problema perché non mostrano il ghiaccio.
2024-05-19 13:17:35,256 - INFO - joeynmt.training - Example #2
2024-05-19 13:17:35,257 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:17:35,257 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:17:35,257 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'c@@', 'att@@', 'ico', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'cu@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:17:35,257 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:17:35,258 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:17:35,258 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio cattico è, in un senso, il cuore del cuore globale.
2024-05-19 13:17:35,258 - INFO - joeynmt.training - Example #3
2024-05-19 13:17:35,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:17:35,259 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:17:35,259 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'v@@', 'est@@', 'ate', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:17:35,259 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:17:35,260 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:17:35,260 - INFO - joeynmt.training - 	Hypothesis: Spande in vestate e contratti in estate.
2024-05-19 13:17:35,260 - INFO - joeynmt.training - Example #4
2024-05-19 13:17:35,260 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:17:35,260 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:17:35,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'prossi@@', 'mo', 'di@@', 'a@@', 'positi@@', 'vo', 'che', 'vi', 'mostr@@', 'i', 'un', 'rapi@@', 'd@@', 'amente', 'più', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:17:35,261 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:17:35,261 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:17:35,262 - INFO - joeynmt.training - 	Hypothesis: Il prossimo diapositivo che vi mostri un rapidamente più veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:17:38,889 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.696197, Batch Acc: 0.547702, Tokens per Sec:    18499, Lr: 0.000300
2024-05-19 13:17:42,632 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     1.597904, Batch Acc: 0.550120, Tokens per Sec:    20009, Lr: 0.000300
2024-05-19 13:17:46,607 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     1.658242, Batch Acc: 0.547053, Tokens per Sec:    17943, Lr: 0.000300
2024-05-19 13:17:50,784 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     1.653733, Batch Acc: 0.545607, Tokens per Sec:    17390, Lr: 0.000300
2024-05-19 13:17:54,376 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     1.635611, Batch Acc: 0.552689, Tokens per Sec:    20224, Lr: 0.000300
2024-05-19 13:17:54,377 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:17:54,377 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:18:04,737 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.71, acc:   0.53, generation: 10.2521[sec], evaluation: 0.0000[sec]
2024-05-19 13:18:04,738 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:18:04,985 - INFO - joeynmt.helpers - delete bpe_model_4000/8500.ckpt
2024-05-19 13:18:04,990 - INFO - joeynmt.training - Example #0
2024-05-19 13:18:04,991 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:18:04,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:18:04,991 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'questi', 'due', 'di@@', 'a@@', 'positi@@', 'vi', 'che', 'il', 'c@@', 'ucci@@', 'olo', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'le', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', 'di', '4@@', '8', 'st@@', 'ates', ',', 'ha', 'ri@@', 'ma@@', 'sto', ',', 'ha', 'ri@@', 'ma@@', 'zione', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:18:04,992 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:18:04,992 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:18:04,992 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato questi due diapositivi che il cucciolo, che per la maggior parte degli ultimi tre milioni di anni sono state le dimensioni di più basso di 48 states, ha rimasto, ha rimazione dal 40%.
2024-05-19 13:18:04,993 - INFO - joeynmt.training - Example #1
2024-05-19 13:18:04,993 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:18:04,993 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:18:04,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'ser@@', 'a', 'di', 'questo', 'particol@@', 'are', 'perché', 'non', 'mostr@@', 'a', 'il', 'ghi@@', 'accio', 'della', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:18:04,994 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:18:04,994 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:18:04,995 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la sera di questo particolare perché non mostra il ghiaccio della ghiaccio.
2024-05-19 13:18:04,995 - INFO - joeynmt.training - Example #2
2024-05-19 13:18:04,995 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:18:04,995 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:18:04,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 't@@', 'es@@', 'o', 'c@@', 'att@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:18:04,996 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:18:04,997 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:18:04,997 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio teso cattico è, in un certo senso, il cuore del sistema globale.
2024-05-19 13:18:04,997 - INFO - joeynmt.training - Example #3
2024-05-19 13:18:04,997 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:18:04,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:18:04,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'ver@@', 'no', ',', 'e', 'si', 'è', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:18:04,998 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:18:04,999 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:18:04,999 - INFO - joeynmt.training - 	Hypothesis: Spande in verno, e si è estate.
2024-05-19 13:18:04,999 - INFO - joeynmt.training - Example #4
2024-05-19 13:18:05,000 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:18:05,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:18:05,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erà', 'una', 'rapi@@', 'da', 'rapi@@', 'd@@', 'amente', ',', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:18:05,001 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:18:05,001 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:18:05,001 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerà una rapida rapidamente, più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:18:08,635 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     1.529803, Batch Acc: 0.542463, Tokens per Sec:    18531, Lr: 0.000300
2024-05-19 13:18:12,321 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.727841, Batch Acc: 0.548453, Tokens per Sec:    19359, Lr: 0.000300
2024-05-19 13:18:16,759 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     1.546851, Batch Acc: 0.547884, Tokens per Sec:    16170, Lr: 0.000300
2024-05-19 13:18:20,566 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     1.606711, Batch Acc: 0.543591, Tokens per Sec:    18946, Lr: 0.000300
2024-05-19 13:18:24,092 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     1.457037, Batch Acc: 0.547540, Tokens per Sec:    20347, Lr: 0.000300
2024-05-19 13:18:24,093 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:18:24,093 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:18:35,076 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.53, generation: 10.8796[sec], evaluation: 0.0000[sec]
2024-05-19 13:18:35,077 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:18:35,332 - INFO - joeynmt.helpers - delete bpe_model_4000/9000.ckpt
2024-05-19 13:18:35,337 - INFO - joeynmt.training - Example #0
2024-05-19 13:18:35,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:18:35,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:18:35,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', 'circa', 'il', '40', '%', '.', '</s>']
2024-05-19 13:18:35,339 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:18:35,340 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:18:35,340 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione di circa il 40%.
2024-05-19 13:18:35,340 - INFO - joeynmt.training - Example #1
2024-05-19 13:18:35,340 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:18:35,341 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:18:35,341 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'ser@@', 'ia', 'di', 'questo', 'problema', ',', 'perché', 'non', 'si', 'mostr@@', 'ano', 'il', 't@@', 'etto', 'della', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:18:35,341 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:18:35,342 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:18:35,342 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la seria di questo problema, perché non si mostrano il tetto della ghiaccio.
2024-05-19 13:18:35,342 - INFO - joeynmt.training - Example #2
2024-05-19 13:18:35,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:18:35,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:18:35,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'della', 'c@@', 'ca@@', 'p', 'è', ',', 'in', 'un', 'certo', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:18:35,343 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:18:35,343 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:18:35,344 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio della ccap è, in un certo, il cuore del sistema globale.
2024-05-19 13:18:35,344 - INFO - joeynmt.training - Example #3
2024-05-19 13:18:35,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:18:35,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:18:35,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'così', 'si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'contr@@', 'atto', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:18:35,345 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:18:35,345 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:18:35,346 - INFO - joeynmt.training - 	Hypothesis: E 'così si espande in contratto in estate.
2024-05-19 13:18:35,346 - INFO - joeynmt.training - Example #4
2024-05-19 13:18:35,346 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:18:35,346 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:18:35,346 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'i', 'un', 'rapi@@', 'd@@', 'amente', 'più', 'rapi@@', 'da', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:18:35,347 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:18:35,347 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:18:35,347 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostri un rapidamente più rapida di quello che è successo negli ultimi 25 anni.
2024-05-19 13:18:39,009 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     1.688461, Batch Acc: 0.546427, Tokens per Sec:    18260, Lr: 0.000300
2024-05-19 13:18:42,891 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     1.678700, Batch Acc: 0.545724, Tokens per Sec:    18764, Lr: 0.000300
2024-05-19 13:18:47,315 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     1.542480, Batch Acc: 0.550313, Tokens per Sec:    16199, Lr: 0.000300
2024-05-19 13:18:50,971 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     1.525287, Batch Acc: 0.548554, Tokens per Sec:    19542, Lr: 0.000300
2024-05-19 13:18:54,635 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     1.695746, Batch Acc: 0.555774, Tokens per Sec:    19065, Lr: 0.000300
2024-05-19 13:18:54,636 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:18:54,636 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:19:05,444 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.61, acc:   0.53, generation: 10.6989[sec], evaluation: 0.0000[sec]
2024-05-19 13:19:05,445 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:19:05,710 - INFO - joeynmt.helpers - delete bpe_model_4000/9500.ckpt
2024-05-19 13:19:05,721 - INFO - joeynmt.training - Example #0
2024-05-19 13:19:05,722 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:19:05,722 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:19:05,722 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'di@@', 'mo@@', 'stra@@', 'zione', 'di', 'c@@', 'ca@@', 'po', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '4@@', '8', 'st@@', 'a@@', 'di@@', 'o', ',', 'ha', 'di@@', 'mostr@@', 'ato', 'da', '40', '%', '.', '</s>']
2024-05-19 13:19:05,723 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:19:05,723 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:19:05,724 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive che la dimostrazione di ccapo, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione di 48 stadio, ha dimostrato da 40%.
2024-05-19 13:19:05,724 - INFO - joeynmt.training - Example #1
2024-05-19 13:19:05,724 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:19:05,724 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:19:05,725 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'il', 't@@', 'el@@', 'em@@', 'ento', '.', '</s>']
2024-05-19 13:19:05,725 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:19:05,726 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:19:05,726 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serietà di questo particolare problema perché non mostrano il telemento.
2024-05-19 13:19:05,726 - INFO - joeynmt.training - Example #2
2024-05-19 13:19:05,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:19:05,727 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:19:05,727 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'c@@', 'att@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:19:05,727 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:19:05,728 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:19:05,728 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio cattico è, in un certo senso, il sistema clima globale.
2024-05-19 13:19:05,728 - INFO - joeynmt.training - Example #3
2024-05-19 13:19:05,728 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:19:05,729 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:19:05,729 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'cont@@', 'est@@', 'ate', 'e', 'cont@@', 'ra@@', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:19:05,729 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:19:05,730 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:19:05,730 - INFO - joeynmt.training - 	Hypothesis: Spande in contestate e contrad'estate.
2024-05-19 13:19:05,730 - INFO - joeynmt.training - Example #4
2024-05-19 13:19:05,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:19:05,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:19:05,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'vi', 'mostr@@', 'i', 'un', 'rapi@@', 'd@@', 'amente', ',', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:19:05,731 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:19:05,731 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:19:05,732 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi vi mostri un rapidamente, di quello che è successo negli ultimi 25 anni.
2024-05-19 13:19:09,412 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     1.878739, Batch Acc: 0.549012, Tokens per Sec:    18453, Lr: 0.000300
2024-05-19 13:19:13,923 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     1.584830, Batch Acc: 0.553323, Tokens per Sec:    15418, Lr: 0.000300
2024-05-19 13:19:17,735 - INFO - joeynmt.training - Epoch   3, Step:    12300, Batch Loss:     1.459241, Batch Acc: 0.550762, Tokens per Sec:    18373, Lr: 0.000300
2024-05-19 13:19:21,383 - INFO - joeynmt.training - Epoch   3, Step:    12400, Batch Loss:     1.858409, Batch Acc: 0.553704, Tokens per Sec:    19626, Lr: 0.000300
2024-05-19 13:19:25,178 - INFO - joeynmt.training - Epoch   3, Step:    12500, Batch Loss:     1.560997, Batch Acc: 0.556317, Tokens per Sec:    19225, Lr: 0.000300
2024-05-19 13:19:25,178 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:19:25,179 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:19:36,219 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.46, acc:   0.54, generation: 10.9370[sec], evaluation: 0.0000[sec]
2024-05-19 13:19:36,220 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:19:36,464 - INFO - joeynmt.helpers - delete bpe_model_4000/10000.ckpt
2024-05-19 13:19:36,474 - INFO - joeynmt.training - Example #0
2024-05-19 13:19:36,475 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:19:36,475 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:19:36,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mostr@@', 'i', 'che', 'il', 'ghi@@', 'accio', 'br@@', 'accio', 'br@@', 'accio', 'br@@', 'accio', 'la', 'c@@', 'ca@@', 'p', ',', 'che', 'per', 'la', 'maggior', 'parte', 'delle', 'tre', 'milioni', 'di', 'anni', 'è', 'stato', 'la', 'dimen@@', 'sione', '4@@', '8', 'st@@', 'i', ',', 'ha', 'di@@', 'b@@', 'at@@', 'tuto', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:19:36,476 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:19:36,477 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:19:36,477 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due slide così che dimostri che il ghiaccio braccio braccio braccio la ccap, che per la maggior parte delle tre milioni di anni è stato la dimensione 48 sti, ha dibattuto dal 40%.
2024-05-19 13:19:36,477 - INFO - joeynmt.training - Example #1
2024-05-19 13:19:36,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:19:36,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:19:36,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'problema', ',', 'perché', 'non', 'è', 'la', 'di@@', 'mo@@', 'sta', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:19:36,478 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:19:36,479 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:19:36,479 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo problema, perché non è la dimosta del ghiaccio.
2024-05-19 13:19:36,479 - INFO - joeynmt.training - Example #2
2024-05-19 13:19:36,479 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:19:36,480 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:19:36,480 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 'c@@', 'att@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:19:36,480 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:19:36,480 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:19:36,481 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio cattico è, in un certo senso, il cuore del sistema globale.
2024-05-19 13:19:36,481 - INFO - joeynmt.training - Example #3
2024-05-19 13:19:36,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:19:36,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:19:36,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'rem@@', 'ità', ',', 'e', 'si', 'est@@', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:19:36,482 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:19:36,482 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:19:36,483 - INFO - joeynmt.training - 	Hypothesis: Spande in estremità, e si estestate.
2024-05-19 13:19:36,483 - INFO - joeynmt.training - Example #4
2024-05-19 13:19:36,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:19:36,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:19:36,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'vi', 'vi', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:19:36,484 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:19:36,484 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:19:36,484 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva vi vi vi mostrerò un rapido veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:19:40,508 - INFO - joeynmt.training - Epoch   3, Step:    12600, Batch Loss:     1.643239, Batch Acc: 0.551367, Tokens per Sec:    16640, Lr: 0.000300
2024-05-19 13:19:45,026 - INFO - joeynmt.training - Epoch   3, Step:    12700, Batch Loss:     1.757604, Batch Acc: 0.553689, Tokens per Sec:    15771, Lr: 0.000300
2024-05-19 13:19:48,602 - INFO - joeynmt.training - Epoch   3, Step:    12800, Batch Loss:     1.565230, Batch Acc: 0.557050, Tokens per Sec:    19780, Lr: 0.000300
2024-05-19 13:19:52,175 - INFO - joeynmt.training - Epoch   3, Step:    12900, Batch Loss:     1.806581, Batch Acc: 0.552644, Tokens per Sec:    20407, Lr: 0.000300
2024-05-19 13:19:56,337 - INFO - joeynmt.training - Epoch   3, Step:    13000, Batch Loss:     1.521494, Batch Acc: 0.554074, Tokens per Sec:    17015, Lr: 0.000300
2024-05-19 13:19:56,337 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:19:56,337 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:20:07,410 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.46, acc:   0.54, generation: 10.9614[sec], evaluation: 0.0000[sec]
2024-05-19 13:20:07,411 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:20:07,672 - INFO - joeynmt.helpers - delete bpe_model_4000/10500.ckpt
2024-05-19 13:20:07,677 - INFO - joeynmt.training - Example #0
2024-05-19 13:20:07,678 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:20:07,678 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:20:07,678 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'sono', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'car@@', 't@@', 'ica', 'car@@', 't@@', 'ico', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', 'circa', '4@@', '8', 'st@@', 'i', ',', 'ha', 'di@@', 'mostr@@', 'ato', 'da', '40', '%', '.', '</s>']
2024-05-19 13:20:07,679 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:20:07,679 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:20:07,680 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso sono mostrato queste due slide così che la cartica cartico, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione di circa 48 sti, ha dimostrato da 40%.
2024-05-19 13:20:07,680 - INFO - joeynmt.training - Example #1
2024-05-19 13:20:07,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:20:07,681 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:20:07,681 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'ser@@', 'ia', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'è', 'mostr@@', 'ato', 'la', 'z@@', 'ona', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:20:07,682 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:20:07,682 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:20:07,682 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la seria di questo particolare problema perché non è mostrato la zona del ghiaccio.
2024-05-19 13:20:07,682 - INFO - joeynmt.training - Example #2
2024-05-19 13:20:07,683 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:20:07,683 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:20:07,683 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 't@@', 'agli@@', 'o', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:20:07,684 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:20:07,684 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:20:07,685 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio taglio è, in un certo senso, il cuore del sistema globale.
2024-05-19 13:20:07,685 - INFO - joeynmt.training - Example #3
2024-05-19 13:20:07,685 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:20:07,685 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:20:07,685 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'ver@@', 'no', 'e', 'si', 'si', 'est@@', 'ate', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:20:07,686 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:20:07,686 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:20:07,687 - INFO - joeynmt.training - 	Hypothesis: Spande in verno e si si estate in estate.
2024-05-19 13:20:07,687 - INFO - joeynmt.training - Example #4
2024-05-19 13:20:07,687 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:20:07,687 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:20:07,688 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'vo', 'che', 'vi', 'mostr@@', 'i', 'sarà', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:20:07,688 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:20:07,688 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:20:07,689 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositivo che vi mostri sarà un rapido rapido di quello che è successo negli ultimi 25 anni.
2024-05-19 13:20:09,720 - INFO - joeynmt.training - Epoch   3: total training loss 7231.89
2024-05-19 13:20:09,721 - INFO - joeynmt.training - EPOCH 4
2024-05-19 13:20:12,342 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     1.557229, Batch Acc: 0.577138, Tokens per Sec:    15496, Lr: 0.000300
2024-05-19 13:20:15,988 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     1.436789, Batch Acc: 0.576819, Tokens per Sec:    19718, Lr: 0.000300
2024-05-19 13:20:19,650 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     1.581540, Batch Acc: 0.574432, Tokens per Sec:    19618, Lr: 0.000300
2024-05-19 13:20:23,590 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     1.658315, Batch Acc: 0.572965, Tokens per Sec:    17988, Lr: 0.000300
2024-05-19 13:20:27,816 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     1.568191, Batch Acc: 0.573307, Tokens per Sec:    17074, Lr: 0.000300
2024-05-19 13:20:27,817 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:20:27,817 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:20:37,876 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.42, acc:   0.54, generation: 9.8650[sec], evaluation: 0.0000[sec]
2024-05-19 13:20:37,877 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:20:38,220 - INFO - joeynmt.helpers - delete bpe_model_4000/11000.ckpt
2024-05-19 13:20:38,236 - INFO - joeynmt.training - Example #0
2024-05-19 13:20:38,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:20:38,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:20:38,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'che', 'di@@', 'mo@@', 'stra@@', 'de', 'che', 'la', 'f@@', 'ase', 'più', 'o', 'meno', 'di', '4@@', '8', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'del', '40', '%', '.', '</s>']
2024-05-19 13:20:38,238 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:20:38,238 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:20:38,238 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso che ho mostrato queste due slide che dimostrade che la fase più o meno di 48 anni è stata la dimensione delle dimensioni del 40%.
2024-05-19 13:20:38,238 - INFO - joeynmt.training - Example #1
2024-05-19 13:20:38,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:20:38,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:20:38,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'ser@@', 'ia', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sua', 't@@', 'el@@', 'ev@@', 'ata', '.', '</s>']
2024-05-19 13:20:38,240 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:20:38,240 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:20:38,240 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la seria di questo particolare problema perché non mostra la sua televata.
2024-05-19 13:20:38,240 - INFO - joeynmt.training - Example #2
2024-05-19 13:20:38,241 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:20:38,241 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:20:38,241 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'c@@', 'att@@', 'ico', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:20:38,241 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:20:38,242 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:20:38,242 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio cattico è, in un senso, il cuore del sistema globale.
2024-05-19 13:20:38,242 - INFO - joeynmt.training - Example #3
2024-05-19 13:20:38,242 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:20:38,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:20:38,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'cont@@', 'est@@', 'ate', 'e', 'si', 'est@@', 'i@@', 'va', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:20:38,244 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:20:38,244 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:20:38,244 - INFO - joeynmt.training - 	Hypothesis: Spande in contestate e si estiva in estate.
2024-05-19 13:20:38,244 - INFO - joeynmt.training - Example #4
2024-05-19 13:20:38,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:20:38,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:20:38,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'erò', 'che', 'sarà', 'un', 'rapi@@', 'd@@', 'amente', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:20:38,245 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:20:38,246 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:20:38,246 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostrerò che sarà un rapidamente veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:20:42,487 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     1.459578, Batch Acc: 0.573294, Tokens per Sec:    15349, Lr: 0.000300
2024-05-19 13:20:46,202 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     1.453622, Batch Acc: 0.573852, Tokens per Sec:    19550, Lr: 0.000300
2024-05-19 13:20:49,740 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     1.567713, Batch Acc: 0.578544, Tokens per Sec:    19853, Lr: 0.000300
2024-05-19 13:20:54,061 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.351347, Batch Acc: 0.577281, Tokens per Sec:    16298, Lr: 0.000300
2024-05-19 13:20:57,845 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.705577, Batch Acc: 0.572570, Tokens per Sec:    19081, Lr: 0.000300
2024-05-19 13:20:57,846 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:20:57,846 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:21:09,054 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.38, acc:   0.55, generation: 11.0897[sec], evaluation: 0.0000[sec]
2024-05-19 13:21:09,055 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:21:09,308 - INFO - joeynmt.helpers - delete bpe_model_4000/11500.ckpt
2024-05-19 13:21:09,320 - INFO - joeynmt.training - Example #0
2024-05-19 13:21:09,321 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:21:09,321 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:21:09,322 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'car@@', 'ica', 'car@@', 'ta', 'di', 'car@@', 'ic@@', 'chi@@', 'a', ',', 'che', 'per', 'la', 'maggior', 'parte', 'delle', 'ul@@', 'time', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '4@@', '8', 'st@@', 'elle', ',', 'ha', 'ri@@', 'ma@@', 'zione', 'di', '40', '%', '.', '</s>']
2024-05-19 13:21:09,323 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:21:09,323 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:21:09,323 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive che la carica carta di caricchia, che per la maggior parte delle ultime tre milioni di anni è stata la dimensione di 48 stelle, ha rimazione di 40%.
2024-05-19 13:21:09,324 - INFO - joeynmt.training - Example #1
2024-05-19 13:21:09,324 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:21:09,324 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:21:09,324 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questa', 'è', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'parte', 'parte', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:21:09,325 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:21:09,325 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:21:09,326 - INFO - joeynmt.training - 	Hypothesis: Ma questa è la serie di questo particolare problema perché non mostra la parte parte del ghiaccio.
2024-05-19 13:21:09,326 - INFO - joeynmt.training - Example #2
2024-05-19 13:21:09,326 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:21:09,326 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:21:09,327 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'c@@', 'att@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:21:09,327 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:21:09,327 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:21:09,328 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio cattico è, in un certo senso, il cuore del sistema globale.
2024-05-19 13:21:09,328 - INFO - joeynmt.training - Example #3
2024-05-19 13:21:09,328 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:21:09,328 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:21:09,329 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'ex@@', 'er', '.', '</s>']
2024-05-19 13:21:09,329 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:21:09,329 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:21:09,330 - INFO - joeynmt.training - 	Hypothesis: Sexexexexexexexexexexexexexer.
2024-05-19 13:21:09,330 - INFO - joeynmt.training - Example #4
2024-05-19 13:21:09,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:21:09,330 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:21:09,331 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'una', 'rapi@@', 'da', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:21:09,331 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:21:09,331 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:21:09,332 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò una rapida veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:21:12,895 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.350722, Batch Acc: 0.568562, Tokens per Sec:    18836, Lr: 0.000300
2024-05-19 13:21:16,539 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.533604, Batch Acc: 0.570522, Tokens per Sec:    19675, Lr: 0.000300
2024-05-19 13:21:20,608 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     1.598658, Batch Acc: 0.572261, Tokens per Sec:    17934, Lr: 0.000300
2024-05-19 13:21:24,756 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     1.618846, Batch Acc: 0.573471, Tokens per Sec:    16951, Lr: 0.000300
2024-05-19 13:21:28,424 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     1.530851, Batch Acc: 0.577498, Tokens per Sec:    19886, Lr: 0.000300
2024-05-19 13:21:28,425 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:21:28,426 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:21:39,424 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.33, acc:   0.55, generation: 10.8899[sec], evaluation: 0.0000[sec]
2024-05-19 13:21:39,425 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:21:39,692 - INFO - joeynmt.helpers - delete bpe_model_4000/12000.ckpt
2024-05-19 13:21:39,703 - INFO - joeynmt.training - Example #0
2024-05-19 13:21:39,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:21:39,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:21:39,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'le', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'maggior', 'parte', 'della', 'car@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'bas@@', 'so', ',', 'ha', 'ri@@', 'ma@@', 'sta', ',', 'ha', 'di@@', 'mostr@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:21:39,705 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:21:39,705 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:21:39,705 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso le due diapositive così che la maggior parte della cartica, che per la maggior parte degli ultimi tre milioni di anni sono stati le dimensioni di basso, ha rimasta, ha dimostrato dal 40%.
2024-05-19 13:21:39,706 - INFO - joeynmt.training - Example #1
2024-05-19 13:21:39,706 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:21:39,706 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:21:39,706 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'ser@@', 'ia', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'cosa', 'è', 'la', 'sp@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:21:39,707 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:21:39,707 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:21:39,708 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la seria di questo particolare problema perché non mostra la cosa è la spità del ghiaccio.
2024-05-19 13:21:39,708 - INFO - joeynmt.training - Example #2
2024-05-19 13:21:39,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:21:39,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:21:39,709 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 'della', 'car@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:21:39,709 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:21:39,709 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:21:39,710 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio della cartica è, in un senso, il cuore del sistema globale.
2024-05-19 13:21:39,710 - INFO - joeynmt.training - Example #3
2024-05-19 13:21:39,710 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:21:39,710 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:21:39,711 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'si', 'cont@@', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:21:39,711 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:21:39,711 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:21:39,712 - INFO - joeynmt.training - 	Hypothesis: Spande in estate e si contestate.
2024-05-19 13:21:39,712 - INFO - joeynmt.training - Example #4
2024-05-19 13:21:39,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:21:39,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:21:39,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'vi', 'vi', 'vi', 'mostr@@', 'o', 'un', 'rapi@@', 'd@@', 'amente', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:21:39,713 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:21:39,714 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:21:39,714 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva vi vi vi mostro un rapidamente di quello che è successo negli ultimi 25 anni.
2024-05-19 13:21:43,473 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.630927, Batch Acc: 0.571061, Tokens per Sec:    17741, Lr: 0.000300
2024-05-19 13:21:47,071 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.515965, Batch Acc: 0.577597, Tokens per Sec:    19920, Lr: 0.000300
2024-05-19 13:21:51,630 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.471377, Batch Acc: 0.575430, Tokens per Sec:    15774, Lr: 0.000300
2024-05-19 13:21:55,160 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     1.640160, Batch Acc: 0.570946, Tokens per Sec:    19888, Lr: 0.000300
2024-05-19 13:21:58,765 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.605906, Batch Acc: 0.575079, Tokens per Sec:    20340, Lr: 0.000300
2024-05-19 13:21:58,766 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:21:58,766 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:22:08,773 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.55, generation: 9.8995[sec], evaluation: 0.0000[sec]
2024-05-19 13:22:08,774 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:22:09,039 - INFO - joeynmt.helpers - delete bpe_model_4000/12500.ckpt
2024-05-19 13:22:09,067 - INFO - joeynmt.training - Example #0
2024-05-19 13:22:09,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:22:09,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:22:09,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stato', 'la', 'dimen@@', 'sione', 'del', '4@@', '8', 'st@@', 'amp@@', 'a', ',', 'ha', 'ri@@', 'ma@@', 'sto', 'per', 'c@@', 'ento', '.', '</s>']
2024-05-19 13:22:09,069 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:22:09,070 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:22:09,070 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive, che per la maggior parte degli ultimi tre milioni di anni è stato la dimensione del 48 stampa, ha rimasto per cento.
2024-05-19 13:22:09,070 - INFO - joeynmt.training - Example #1
2024-05-19 13:22:09,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:22:09,071 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:22:09,071 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'problema', 'della', 'serie', 'di', 'questo', 'problema', ',', 'perché', 'non', 'è', 'la', 'di@@', 'mo@@', 'stra@@', 'zione', 'di', 'questo', 'problema', 'perché', 'non', 'è', 'la', 'di@@', 'spon@@', 'i@@', 'bile', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:22:09,072 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:22:09,072 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:22:09,072 - INFO - joeynmt.training - 	Hypothesis: Ma questo problema della serie di questo problema, perché non è la dimostrazione di questo problema perché non è la disponibile del ghiaccio.
2024-05-19 13:22:09,073 - INFO - joeynmt.training - Example #2
2024-05-19 13:22:09,073 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:22:09,073 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:22:09,073 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'c@@', 'att@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'be@@', 'l', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:22:09,074 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:22:09,074 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:22:09,074 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio cattico è, in un certo senso, il bel sistema globale.
2024-05-19 13:22:09,075 - INFO - joeynmt.training - Example #3
2024-05-19 13:22:09,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:22:09,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:22:09,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'es@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:22:09,076 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:22:09,076 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:22:09,076 - INFO - joeynmt.training - 	Hypothesis: E espande in estate.
2024-05-19 13:22:09,076 - INFO - joeynmt.training - Example #4
2024-05-19 13:22:09,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:22:09,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:22:09,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erà', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:22:09,078 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:22:09,078 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:22:09,078 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerà un rapido rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:22:12,716 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.573373, Batch Acc: 0.575256, Tokens per Sec:    18181, Lr: 0.000300
2024-05-19 13:22:16,465 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     1.539791, Batch Acc: 0.571315, Tokens per Sec:    18754, Lr: 0.000300
2024-05-19 13:22:20,923 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.504338, Batch Acc: 0.573326, Tokens per Sec:    16404, Lr: 0.000300
2024-05-19 13:22:24,514 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.549976, Batch Acc: 0.573800, Tokens per Sec:    20236, Lr: 0.000300
2024-05-19 13:22:28,178 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.438465, Batch Acc: 0.572054, Tokens per Sec:    20017, Lr: 0.000300
2024-05-19 13:22:28,179 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:22:28,179 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:22:38,864 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.55, generation: 10.5705[sec], evaluation: 0.0000[sec]
2024-05-19 13:22:38,865 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:22:39,124 - INFO - joeynmt.helpers - delete bpe_model_4000/13000.ckpt
2024-05-19 13:22:39,140 - INFO - joeynmt.training - Example #0
2024-05-19 13:22:39,142 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:22:39,142 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:22:39,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', ',', 'che', 'per', 'la', 'maggior', 'parte', 'delle', 'scor@@', 'te', 'di', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'circa', 'il', '40', '%', '.', '</s>']
2024-05-19 13:22:39,143 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:22:39,144 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:22:39,145 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive, che per la maggior parte delle scorte di tre milioni di anni sono stati le dimensioni di circa il 40%.
2024-05-19 13:22:39,145 - INFO - joeynmt.training - Example #1
2024-05-19 13:22:39,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:22:39,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:22:39,146 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'ser@@', 'ia', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'il', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:22:39,147 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:22:39,147 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:22:39,147 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la seria di questo particolare problema perché non mostrano il ghiaccio.
2024-05-19 13:22:39,148 - INFO - joeynmt.training - Example #2
2024-05-19 13:22:39,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:22:39,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:22:39,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'c@@', '&@@', 'a@@', 'pos@@', ';', 'è', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:22:39,149 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:22:39,150 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:22:39,150 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio c'è un certo senso, il cuore di cuore del sistema globale.
2024-05-19 13:22:39,150 - INFO - joeynmt.training - Example #3
2024-05-19 13:22:39,151 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:22:39,151 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:22:39,151 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'si', 'cont@@', 'ra@@', 'i', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:22:39,152 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:22:39,152 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:22:39,152 - INFO - joeynmt.training - 	Hypothesis: Spande in estate e si contrai in estate.
2024-05-19 13:22:39,152 - INFO - joeynmt.training - Example #4
2024-05-19 13:22:39,153 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:22:39,153 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:22:39,153 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erà', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:22:39,154 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:22:39,154 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:22:39,154 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerà un rapido rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:22:42,827 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.682292, Batch Acc: 0.576345, Tokens per Sec:    18499, Lr: 0.000300
2024-05-19 13:22:47,125 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     1.678115, Batch Acc: 0.574673, Tokens per Sec:    16918, Lr: 0.000300
2024-05-19 13:22:51,089 - INFO - joeynmt.training - Epoch   4, Step:    15800, Batch Loss:     1.543066, Batch Acc: 0.578570, Tokens per Sec:    18094, Lr: 0.000300
2024-05-19 13:22:54,688 - INFO - joeynmt.training - Epoch   4, Step:    15900, Batch Loss:     1.479709, Batch Acc: 0.577313, Tokens per Sec:    19821, Lr: 0.000300
2024-05-19 13:22:58,396 - INFO - joeynmt.training - Epoch   4, Step:    16000, Batch Loss:     1.549127, Batch Acc: 0.574159, Tokens per Sec:    19543, Lr: 0.000300
2024-05-19 13:22:58,397 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:22:58,397 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:23:08,751 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.17, acc:   0.55, generation: 10.2384[sec], evaluation: 0.0000[sec]
2024-05-19 13:23:08,752 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:23:09,017 - INFO - joeynmt.helpers - delete bpe_model_4000/13500.ckpt
2024-05-19 13:23:09,022 - INFO - joeynmt.training - Example #0
2024-05-19 13:23:09,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:23:09,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:23:09,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'ulti@@', 'ma', ',', 'che', 'per', 'la', 'maggior', 'parte', 'dei', '4@@', '8', 'st@@', 'iti', ',', 'ha', 's@@', 'alt@@', 'ato', 'da', '40', '%', '.', '</s>']
2024-05-19 13:23:09,024 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:23:09,024 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:23:09,025 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso, ho mostrato queste due diapositive, che per la maggior parte degli ultimi tre milioni di anni sono stati l'ultima, che per la maggior parte dei 48 stiti, ha saltato da 40%.
2024-05-19 13:23:09,025 - INFO - joeynmt.training - Example #1
2024-05-19 13:23:09,025 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:23:09,025 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:23:09,025 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'i', 'il', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:23:09,026 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:23:09,026 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:23:09,027 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serie di questo particolare problema perché non mostri il ghiaccio.
2024-05-19 13:23:09,027 - INFO - joeynmt.training - Example #2
2024-05-19 13:23:09,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:23:09,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:23:09,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'c@@', 'att@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', '.', '</s>']
2024-05-19 13:23:09,028 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:23:09,028 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:23:09,029 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio cattico è, in un certo senso, il cuore del sistema clima.
2024-05-19 13:23:09,029 - INFO - joeynmt.training - Example #3
2024-05-19 13:23:09,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:23:09,029 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:23:09,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ex@@', 'ex@@', 'p@@', 'in@@', 'ver@@', 'no', 'e', 'si', 'cont@@', 'a', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:23:09,030 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:23:09,030 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:23:09,030 - INFO - joeynmt.training - 	Hypothesis: Sexexpinverno e si conta in estate.
2024-05-19 13:23:09,031 - INFO - joeynmt.training - Example #4
2024-05-19 13:23:09,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:23:09,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:23:09,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'i', 'che', 'si', 'tratta', 'di', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:23:09,032 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:23:09,032 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:23:09,032 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostri che si tratta di più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:23:12,738 - INFO - joeynmt.training - Epoch   4, Step:    16100, Batch Loss:     1.356689, Batch Acc: 0.576990, Tokens per Sec:    18217, Lr: 0.000300
2024-05-19 13:23:17,273 - INFO - joeynmt.training - Epoch   4, Step:    16200, Batch Loss:     1.556612, Batch Acc: 0.575086, Tokens per Sec:    15498, Lr: 0.000300
2024-05-19 13:23:20,852 - INFO - joeynmt.training - Epoch   4, Step:    16300, Batch Loss:     1.570156, Batch Acc: 0.568257, Tokens per Sec:    19134, Lr: 0.000300
2024-05-19 13:23:24,436 - INFO - joeynmt.training - Epoch   4, Step:    16400, Batch Loss:     1.411901, Batch Acc: 0.577752, Tokens per Sec:    19827, Lr: 0.000300
2024-05-19 13:23:28,362 - INFO - joeynmt.training - Epoch   4, Step:    16500, Batch Loss:     1.602131, Batch Acc: 0.575394, Tokens per Sec:    17812, Lr: 0.000300
2024-05-19 13:23:28,362 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:23:28,363 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:23:38,342 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.55, generation: 9.8632[sec], evaluation: 0.0000[sec]
2024-05-19 13:23:38,343 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:23:38,590 - INFO - joeynmt.helpers - delete bpe_model_4000/14000.ckpt
2024-05-19 13:23:38,601 - INFO - joeynmt.training - Example #0
2024-05-19 13:23:38,603 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:23:38,604 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:23:38,604 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'ca@@', 'dut@@', 'a', 'di', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:23:38,605 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:23:38,605 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:23:38,605 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive che la caduta di ghiaccio.
2024-05-19 13:23:38,605 - INFO - joeynmt.training - Example #1
2024-05-19 13:23:38,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:23:38,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:23:38,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'z@@', 'ona', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:23:38,607 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:23:38,607 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:23:38,607 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serietà di questo particolare problema perché non ha mostrato la zona del ghiaccio.
2024-05-19 13:23:38,607 - INFO - joeynmt.training - Example #2
2024-05-19 13:23:38,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:23:38,608 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:23:38,608 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'macchina', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'b@@', 'at@@', 'ro', 'del', 'sistema', 'cli@@', 'ma', '.', '</s>']
2024-05-19 13:23:38,609 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:23:38,609 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:23:38,609 - INFO - joeynmt.training - 	Hypothesis: La macchina artica è, in un senso, il batro del sistema clima.
2024-05-19 13:23:38,610 - INFO - joeynmt.training - Example #3
2024-05-19 13:23:38,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:23:38,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:23:38,610 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'contr@@', 'at@@', 'te', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:23:38,611 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:23:38,611 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:23:38,611 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e si è contratte in estate.
2024-05-19 13:23:38,611 - INFO - joeynmt.training - Example #4
2024-05-19 13:23:38,612 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:23:38,612 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:23:38,612 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'i', 'av@@', 'ver@@', 'ò', 'una', 'rapi@@', 'da', 'più', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'acca@@', 'du@@', 'to', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:23:38,613 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:23:38,613 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:23:38,613 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostri avverò una rapida più veloce di quello che è accaduto negli ultimi 25 anni.
2024-05-19 13:23:42,581 - INFO - joeynmt.training - Epoch   4, Step:    16600, Batch Loss:     1.644635, Batch Acc: 0.577731, Tokens per Sec:    16791, Lr: 0.000300
2024-05-19 13:23:46,790 - INFO - joeynmt.training - Epoch   4, Step:    16700, Batch Loss:     1.441112, Batch Acc: 0.574420, Tokens per Sec:    16877, Lr: 0.000300
2024-05-19 13:23:50,402 - INFO - joeynmt.training - Epoch   4, Step:    16800, Batch Loss:     1.439790, Batch Acc: 0.581077, Tokens per Sec:    19892, Lr: 0.000300
2024-05-19 13:23:54,033 - INFO - joeynmt.training - Epoch   4, Step:    16900, Batch Loss:     1.326078, Batch Acc: 0.575169, Tokens per Sec:    19825, Lr: 0.000300
2024-05-19 13:23:58,351 - INFO - joeynmt.training - Epoch   4, Step:    17000, Batch Loss:     1.602594, Batch Acc: 0.579695, Tokens per Sec:    17067, Lr: 0.000300
2024-05-19 13:23:58,352 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:23:58,352 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:24:09,566 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.10, acc:   0.56, generation: 11.0444[sec], evaluation: 0.0000[sec]
2024-05-19 13:24:09,567 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:24:09,898 - INFO - joeynmt.helpers - delete bpe_model_4000/14500.ckpt
2024-05-19 13:24:09,913 - INFO - joeynmt.training - Example #0
2024-05-19 13:24:09,914 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:24:09,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:24:09,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'ca@@', 'p', 'ar@@', 'c@@', 'ica', 'di', 'ghi@@', 'accio', 'ar@@', 't@@', 'ico', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', 'di', '4@@', '8', 'anni', '.', '</s>']
2024-05-19 13:24:09,915 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:24:09,916 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:24:09,916 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che la cap arcica di ghiaccio artico, che per la maggior parte degli ultimi tre milioni di anni sono state dimensioni di più basso di 48 anni.
2024-05-19 13:24:09,916 - INFO - joeynmt.training - Example #1
2024-05-19 13:24:09,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:24:09,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:24:09,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questa', 'com@@', 'pre@@', 'se', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 't@@', 'ick@@', 'zza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:24:09,917 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:24:09,918 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:24:09,918 - INFO - joeynmt.training - 	Hypothesis: Ma questa comprese la serietà di questo particolare problema perché non ha mostrato la tickzza del ghiaccio.
2024-05-19 13:24:09,918 - INFO - joeynmt.training - Example #2
2024-05-19 13:24:09,918 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:24:09,918 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:24:09,919 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 't@@', 'agli@@', 'o', 'di', 'ghi@@', 'accio', '.', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:24:09,919 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:24:09,919 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:24:09,920 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio taglio di ghiaccio. è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:24:09,920 - INFO - joeynmt.training - Example #3
2024-05-19 13:24:09,920 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:24:09,920 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:24:09,920 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'es@@', 'p@@', 'and@@', 'e', 'in', 'cont@@', 'est@@', 'ate', 'e', 'cont@@', 'ra@@', 'd@@', 'di@@', 'o', '.', '</s>']
2024-05-19 13:24:09,921 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:24:09,921 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:24:09,921 - INFO - joeynmt.training - 	Hypothesis: E espande in contestate e contraddio.
2024-05-19 13:24:09,921 - INFO - joeynmt.training - Example #4
2024-05-19 13:24:09,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:24:09,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:24:09,922 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'che', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'o', 'un', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:24:09,923 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:24:09,923 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:24:09,923 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostro che vi mostro un rapido di quello che è successo negli ultimi 25 anni.
2024-05-19 13:24:14,411 - INFO - joeynmt.training - Epoch   4, Step:    17100, Batch Loss:     1.550618, Batch Acc: 0.579649, Tokens per Sec:    15131, Lr: 0.000300
2024-05-19 13:24:18,023 - INFO - joeynmt.training - Epoch   4, Step:    17200, Batch Loss:     1.375611, Batch Acc: 0.579547, Tokens per Sec:    19701, Lr: 0.000300
2024-05-19 13:24:21,587 - INFO - joeynmt.training - Epoch   4, Step:    17300, Batch Loss:     1.505658, Batch Acc: 0.579089, Tokens per Sec:    19672, Lr: 0.000300
2024-05-19 13:24:25,234 - INFO - joeynmt.training - Epoch   4: total training loss 6704.96
2024-05-19 13:24:25,235 - INFO - joeynmt.training - EPOCH 5
2024-05-19 13:24:25,681 - INFO - joeynmt.training - Epoch   5, Step:    17400, Batch Loss:     1.481519, Batch Acc: 0.588185, Tokens per Sec:    15683, Lr: 0.000300
2024-05-19 13:24:29,820 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     1.330364, Batch Acc: 0.603338, Tokens per Sec:    17101, Lr: 0.000300
2024-05-19 13:24:29,820 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:24:29,821 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:24:39,846 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.07, acc:   0.56, generation: 9.8232[sec], evaluation: 0.0000[sec]
2024-05-19 13:24:39,847 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:24:40,178 - INFO - joeynmt.helpers - delete bpe_model_4000/15000.ckpt
2024-05-19 13:24:40,183 - INFO - joeynmt.training - Example #0
2024-05-19 13:24:40,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:24:40,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:24:40,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'macchina', 'ar@@', 'c@@', 'ica', 'car@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'le', 'dimen@@', 'sioni', 'del', '40', '%', ',', 'ha', 'ri@@', 'ma@@', 'is', 'da', '40', '%', '.', '</s>']
2024-05-19 13:24:40,185 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:24:40,185 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:24:40,185 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che la macchina arcica cartica, che per la maggior parte degli ultimi tre milioni di anni sono state le dimensioni del 40%, ha rimais da 40%.
2024-05-19 13:24:40,186 - INFO - joeynmt.training - Example #1
2024-05-19 13:24:40,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:24:40,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:24:40,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'ser@@', 'a', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'sp@@', 'av@@', 'ent@@', 'a', '.', '</s>']
2024-05-19 13:24:40,187 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:24:40,187 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:24:40,188 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la sera di questo particolare problema perché non ha mostrato la spaventa.
2024-05-19 13:24:40,188 - INFO - joeynmt.training - Example #2
2024-05-19 13:24:40,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:24:40,188 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:24:40,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'macchina', 'car@@', 'ic@@', 'ata', 'car@@', 'di@@', 'ac@@', 'a', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'suo', 'cu@@', 'ore', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:24:40,189 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:24:40,189 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:24:40,189 - INFO - joeynmt.training - 	Hypothesis: La macchina caricata cardiaca è, in un certo senso, il suo cuore climatico globale.
2024-05-19 13:24:40,190 - INFO - joeynmt.training - Example #3
2024-05-19 13:24:40,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:24:40,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:24:40,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'contr@@', 'atto', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:24:40,191 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:24:40,191 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:24:40,191 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e si è contratto in estate.
2024-05-19 13:24:40,191 - INFO - joeynmt.training - Example #4
2024-05-19 13:24:40,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:24:40,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:24:40,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'vi', 'vi', 'mostr@@', 'o', 'un', 'rapi@@', 'do', 'rapi@@', 'd@@', 'amente', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:24:40,193 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:24:40,193 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:24:40,193 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva vi vi mostro un rapido rapidamente di quello che è successo negli ultimi 25 anni.
2024-05-19 13:24:44,337 - INFO - joeynmt.training - Epoch   5, Step:    17600, Batch Loss:     1.322230, Batch Acc: 0.602774, Tokens per Sec:    16007, Lr: 0.000300
2024-05-19 13:24:47,956 - INFO - joeynmt.training - Epoch   5, Step:    17700, Batch Loss:     1.486132, Batch Acc: 0.602212, Tokens per Sec:    19447, Lr: 0.000300
2024-05-19 13:24:51,539 - INFO - joeynmt.training - Epoch   5, Step:    17800, Batch Loss:     1.294002, Batch Acc: 0.603457, Tokens per Sec:    19882, Lr: 0.000300
2024-05-19 13:24:56,149 - INFO - joeynmt.training - Epoch   5, Step:    17900, Batch Loss:     1.200561, Batch Acc: 0.600624, Tokens per Sec:    15586, Lr: 0.000300
2024-05-19 13:24:59,791 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     1.417079, Batch Acc: 0.594952, Tokens per Sec:    19934, Lr: 0.000300
2024-05-19 13:24:59,792 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:24:59,792 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:25:10,088 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.62, ppl:   5.06, acc:   0.56, generation: 10.0949[sec], evaluation: 0.0000[sec]
2024-05-19 13:25:10,089 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:25:10,415 - INFO - joeynmt.helpers - delete bpe_model_4000/15500.ckpt
2024-05-19 13:25:10,420 - INFO - joeynmt.training - Example #0
2024-05-19 13:25:10,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:25:10,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:25:10,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', ',', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'macchina', 'att@@', 'ica', 'ca@@', 'po@@', 'vol@@', 'a', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'ha', 'sp@@', 'into', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:25:10,422 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:25:10,423 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:25:10,423 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso, due diapositive così che la macchina attica capovola, che per la maggior parte degli ultimi tre milioni di anni sono stati le dimensioni di più basso 48 stati, ha spinto dal 40%.
2024-05-19 13:25:10,423 - INFO - joeynmt.training - Example #1
2024-05-19 13:25:10,424 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:25:10,424 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:25:10,424 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questa', 'com@@', 'pre@@', 'se', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 't@@', 'el@@', 'ev@@', 'ata', 'della', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:25:10,424 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:25:10,425 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:25:10,425 - INFO - joeynmt.training - 	Hypothesis: Ma questa comprese la serietà di questo particolare problema perché non ha mostrato la televata della ghiaccio.
2024-05-19 13:25:10,425 - INFO - joeynmt.training - Example #2
2024-05-19 13:25:10,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:25:10,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:25:10,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 't@@', 'ico', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:25:10,426 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:25:10,427 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:25:10,427 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio tico è, in un senso, il cuore di cuore del sistema globale.
2024-05-19 13:25:10,427 - INFO - joeynmt.training - Example #3
2024-05-19 13:25:10,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:25:10,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:25:10,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'cont@@', 'ra@@', 'd@@', 'ine', '.', '</s>']
2024-05-19 13:25:10,428 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:25:10,429 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:25:10,429 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e si contradine.
2024-05-19 13:25:10,429 - INFO - joeynmt.training - Example #4
2024-05-19 13:25:10,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:25:10,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:25:10,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'sarà', 'un', 'rapi@@', 'd@@', 'amente', 'più', 'veloc@@', 'emente', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:25:10,431 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:25:10,431 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:25:10,431 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro sarà un rapidamente più velocemente di quello che è successo negli ultimi 25 anni.
2024-05-19 13:25:14,163 - INFO - joeynmt.training - Epoch   5, Step:    18100, Batch Loss:     1.372061, Batch Acc: 0.596584, Tokens per Sec:    17443, Lr: 0.000300
2024-05-19 13:25:17,804 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.354455, Batch Acc: 0.598316, Tokens per Sec:    19580, Lr: 0.000300
2024-05-19 13:25:21,660 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.599392, Batch Acc: 0.599251, Tokens per Sec:    18419, Lr: 0.000300
2024-05-19 13:25:25,947 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.586892, Batch Acc: 0.591427, Tokens per Sec:    16296, Lr: 0.000300
2024-05-19 13:25:29,604 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.502073, Batch Acc: 0.594698, Tokens per Sec:    19694, Lr: 0.000300
2024-05-19 13:25:29,605 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:25:29,605 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:25:41,023 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.97, acc:   0.57, generation: 11.2942[sec], evaluation: 0.0000[sec]
2024-05-19 13:25:41,024 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:25:41,292 - INFO - joeynmt.helpers - delete bpe_model_4000/16000.ckpt
2024-05-19 13:25:41,308 - INFO - joeynmt.training - Example #0
2024-05-19 13:25:41,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:25:41,309 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:25:41,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'car@@', 't@@', 'ica', 'di', 'più', 'di', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', 'di', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'ma@@', 'sto', ',', 'ha', 's@@', 'alt@@', 'ato', 'dal', '40', 'anni', '.', '</s>']
2024-05-19 13:25:41,311 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:25:41,311 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:25:41,311 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive che la cartica di più di tre milioni di anni sono stati le dimensioni di più basso di 48 stati, ha rimasto, ha saltato dal 40 anni.
2024-05-19 13:25:41,311 - INFO - joeynmt.training - Example #1
2024-05-19 13:25:41,312 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:25:41,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:25:41,312 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'ghi@@', 'accio', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:25:41,313 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:25:41,313 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:25:41,313 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo particolare problema perché non mostra la ghiaccio del ghiaccio.
2024-05-19 13:25:41,314 - INFO - joeynmt.training - Example #2
2024-05-19 13:25:41,314 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:25:41,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:25:41,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 'arti@@', 'fici@@', 'ale', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:25:41,315 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:25:41,315 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:25:41,315 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio artificiale è, in un certo senso, il cuore del sistema globale.
2024-05-19 13:25:41,316 - INFO - joeynmt.training - Example #3
2024-05-19 13:25:41,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:25:41,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:25:41,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ex@@', 'p@@', 'essi@@', 'mo', 'in', 'in@@', 'ver@@', 'no', 'e', 'cont@@', 'ra@@', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:25:41,317 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:25:41,317 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:25:41,317 - INFO - joeynmt.training - 	Hypothesis: Sexpessimo in inverno e contrad'estate.
2024-05-19 13:25:41,317 - INFO - joeynmt.training - Example #4
2024-05-19 13:25:41,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:25:41,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:25:41,318 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:25:41,319 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:25:41,319 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:25:41,319 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi vi mostrerò un rapido rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:25:45,138 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.418142, Batch Acc: 0.592717, Tokens per Sec:    17229, Lr: 0.000300
2024-05-19 13:25:48,706 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.578698, Batch Acc: 0.594556, Tokens per Sec:    20165, Lr: 0.000300
2024-05-19 13:25:53,230 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.439914, Batch Acc: 0.593714, Tokens per Sec:    15831, Lr: 0.000300
2024-05-19 13:25:56,789 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.388602, Batch Acc: 0.588333, Tokens per Sec:    19691, Lr: 0.000300
2024-05-19 13:26:00,434 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.291125, Batch Acc: 0.590960, Tokens per Sec:    19961, Lr: 0.000300
2024-05-19 13:26:00,435 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:26:00,435 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:26:11,309 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.01, acc:   0.56, generation: 10.7554[sec], evaluation: 0.0000[sec]
2024-05-19 13:26:11,560 - INFO - joeynmt.helpers - delete bpe_model_4000/16500.ckpt
2024-05-19 13:26:11,572 - INFO - joeynmt.training - Example #0
2024-05-19 13:26:11,573 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:26:11,573 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:26:11,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'ca@@', 'p@@', 'elle', 'di', 'ghi@@', 'accio', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'ma@@', 'sta', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:26:11,574 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:26:11,575 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:26:11,575 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che la capelle di ghiaccio tica, che per la maggior parte degli ultimi tre anni è stata la dimensione di 48 stati, ha rimasta dal 40%.
2024-05-19 13:26:11,575 - INFO - joeynmt.training - Example #1
2024-05-19 13:26:11,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:26:11,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:26:11,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', ',', 'perché', 'non', 'mostr@@', 'a', 'la', 'parte', 'parte', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:26:11,577 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:26:11,577 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:26:11,577 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo particolare problema, perché non mostra la parte parte del ghiaccio.
2024-05-19 13:26:11,578 - INFO - joeynmt.training - Example #2
2024-05-19 13:26:11,578 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:26:11,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:26:11,579 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 't@@', 'ica', 'c@@', '&@@', 'a@@', 'pos@@', ';', 'è', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'cu@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:26:11,579 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:26:11,580 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:26:11,580 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio tica c'è in un certo senso, il cuore di cuore globale.
2024-05-19 13:26:11,580 - INFO - joeynmt.training - Example #3
2024-05-19 13:26:11,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:26:11,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:26:11,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'si', 'cont@@', 'ra@@', 'ff@@', 'i', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:26:11,582 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:26:11,582 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:26:11,582 - INFO - joeynmt.training - 	Hypothesis: Sppande in estate e si contraffi in estate.
2024-05-19 13:26:11,582 - INFO - joeynmt.training - Example #4
2024-05-19 13:26:11,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:26:11,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:26:11,583 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'o', 'sarà', 'un', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:26:11,584 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:26:11,584 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:26:11,584 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostro sarà un rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:26:15,187 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.556769, Batch Acc: 0.595851, Tokens per Sec:    18800, Lr: 0.000300
2024-05-19 13:26:19,346 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.459087, Batch Acc: 0.596457, Tokens per Sec:    17594, Lr: 0.000300
2024-05-19 13:26:23,439 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.359983, Batch Acc: 0.597054, Tokens per Sec:    17820, Lr: 0.000300
2024-05-19 13:26:27,073 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.379084, Batch Acc: 0.593566, Tokens per Sec:    19615, Lr: 0.000300
2024-05-19 13:26:30,686 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.440235, Batch Acc: 0.599153, Tokens per Sec:    20146, Lr: 0.000300
2024-05-19 13:26:30,686 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:26:30,687 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:26:41,306 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.95, acc:   0.56, generation: 10.5181[sec], evaluation: 0.0000[sec]
2024-05-19 13:26:41,307 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:26:41,568 - INFO - joeynmt.helpers - delete bpe_model_4000/17000.ckpt
2024-05-19 13:26:41,580 - INFO - joeynmt.training - Example #0
2024-05-19 13:26:41,581 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:26:41,581 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:26:41,581 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', ',', 'che', 'per', 'la', 'maggior', 'parte', 'delle', 'ul@@', 'time', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'le', 'dimen@@', 'sioni', 'della', 'dimen@@', 'sione', 'dell@@', '&@@', 'a@@', 'pos@@', ';', 'ultimo', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'bas@@', 'se', 'di', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:26:41,582 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:26:41,582 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:26:41,582 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive, che per la maggior parte delle ultime tre milioni di anni sono state le dimensioni della dimensione dell'ultimo tre milioni di anni sono stati le dimensioni di basse di 48 stati, si è rimasta dal 40%.
2024-05-19 13:26:41,583 - INFO - joeynmt.training - Example #1
2024-05-19 13:26:41,583 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:26:41,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:26:41,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'il', 't@@', 'ick@@', 'zza', 'della', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:26:41,584 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:26:41,584 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:26:41,585 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo particolare problema perché non mostrano il tickzza della ghiaccio.
2024-05-19 13:26:41,585 - INFO - joeynmt.training - Example #2
2024-05-19 13:26:41,585 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:26:41,585 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:26:41,586 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 'della', 'c@@', 'att@@', 'ina', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'cu@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:26:41,586 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:26:41,586 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:26:41,587 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio della cattina è, in un senso, il cuore di cuore globale.
2024-05-19 13:26:41,587 - INFO - joeynmt.training - Example #3
2024-05-19 13:26:41,587 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:26:41,587 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:26:41,588 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'per@@', 'man@@', 'i', 'in', 'est@@', 'i@@', 'era', 'e', 'si', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'i@@', 'era', '.', '</s>']
2024-05-19 13:26:41,588 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:26:41,588 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:26:41,589 - INFO - joeynmt.training - 	Hypothesis: Spermani in estiera e si contratti in estiera.
2024-05-19 13:26:41,589 - INFO - joeynmt.training - Example #4
2024-05-19 13:26:41,589 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:26:41,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:26:41,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'di', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:26:41,590 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:26:41,591 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:26:41,591 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un rapido di di quello che è successo negli ultimi 25 anni.
2024-05-19 13:26:45,337 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.452830, Batch Acc: 0.596951, Tokens per Sec:    18002, Lr: 0.000300
2024-05-19 13:26:50,057 - INFO - joeynmt.training - Epoch   5, Step:    19700, Batch Loss:     1.442788, Batch Acc: 0.586056, Tokens per Sec:    15100, Lr: 0.000300
2024-05-19 13:26:53,620 - INFO - joeynmt.training - Epoch   5, Step:    19800, Batch Loss:     1.561224, Batch Acc: 0.592049, Tokens per Sec:    19583, Lr: 0.000300
2024-05-19 13:26:57,200 - INFO - joeynmt.training - Epoch   5, Step:    19900, Batch Loss:     1.535316, Batch Acc: 0.601075, Tokens per Sec:    20216, Lr: 0.000300
2024-05-19 13:27:01,136 - INFO - joeynmt.training - Epoch   5, Step:    20000, Batch Loss:     1.454677, Batch Acc: 0.598023, Tokens per Sec:    18150, Lr: 0.000300
2024-05-19 13:27:01,136 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:27:01,137 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:27:12,727 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.93, acc:   0.57, generation: 11.4833[sec], evaluation: 0.0000[sec]
2024-05-19 13:27:12,728 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:27:12,985 - INFO - joeynmt.helpers - delete bpe_model_4000/17500.ckpt
2024-05-19 13:27:12,990 - INFO - joeynmt.training - Example #0
2024-05-19 13:27:12,991 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:27:12,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:27:12,992 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'ca@@', 'p@@', 'elle', 'ar@@', 'c@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', 'di', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'gli@@', 'a', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:27:12,993 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:27:12,993 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:27:12,993 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive che la capelle arcica, che per la maggior parte degli ultimi tre milioni di anni sono stati le dimensioni di più basso di 48 stati, si è rimaglia dal 40%.
2024-05-19 13:27:12,994 - INFO - joeynmt.training - Example #1
2024-05-19 13:27:12,994 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:27:12,994 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:27:12,994 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'si', 'mostr@@', 'ano', 'la', 't@@', 'ick@@', 'zza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:27:12,995 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:27:12,995 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:27:12,996 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo particolare problema perché non si mostrano la tickzza del ghiaccio.
2024-05-19 13:27:12,996 - INFO - joeynmt.training - Example #2
2024-05-19 13:27:12,996 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:27:12,996 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:27:12,996 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 'arti@@', 'fici@@', 'ale', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'b@@', 'ello', 'di', 'cu@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:27:12,997 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:27:12,997 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:27:12,998 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio artificiale è, in un certo senso, il bello di cuore globale.
2024-05-19 13:27:12,998 - INFO - joeynmt.training - Example #3
2024-05-19 13:27:12,998 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:27:12,998 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:27:12,998 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'pe@@', 'pe@@', 'gg@@', 'i', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:27:12,999 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:27:12,999 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:27:12,999 - INFO - joeynmt.training - 	Hypothesis: Spepeggi in inverno e si è contratti in estate.
2024-05-19 13:27:13,000 - INFO - joeynmt.training - Example #4
2024-05-19 13:27:13,000 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:27:13,000 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:27:13,000 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'vi', 'vi', 'mostr@@', 'o', 'che', 'sarà', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:27:13,001 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:27:13,001 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:27:13,001 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva vi vi mostro che sarà un rapido rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:27:17,470 - INFO - joeynmt.training - Epoch   5, Step:    20100, Batch Loss:     1.392119, Batch Acc: 0.594157, Tokens per Sec:    15340, Lr: 0.000300
2024-05-19 13:27:21,169 - INFO - joeynmt.training - Epoch   5, Step:    20200, Batch Loss:     1.364523, Batch Acc: 0.598099, Tokens per Sec:    19261, Lr: 0.000300
2024-05-19 13:27:24,730 - INFO - joeynmt.training - Epoch   5, Step:    20300, Batch Loss:     1.521656, Batch Acc: 0.587079, Tokens per Sec:    19522, Lr: 0.000300
2024-05-19 13:27:28,536 - INFO - joeynmt.training - Epoch   5, Step:    20400, Batch Loss:     1.458912, Batch Acc: 0.590338, Tokens per Sec:    19095, Lr: 0.000300
2024-05-19 13:27:33,073 - INFO - joeynmt.training - Epoch   5, Step:    20500, Batch Loss:     1.312677, Batch Acc: 0.592987, Tokens per Sec:    16020, Lr: 0.000300
2024-05-19 13:27:33,073 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:27:33,074 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:27:43,484 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.88, acc:   0.57, generation: 10.2200[sec], evaluation: 0.0000[sec]
2024-05-19 13:27:43,485 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:27:43,846 - INFO - joeynmt.helpers - delete bpe_model_4000/18000.ckpt
2024-05-19 13:27:43,862 - INFO - joeynmt.training - Example #0
2024-05-19 13:27:43,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:27:43,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:27:43,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'sono', 'state', 'mostr@@', 'ate', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'f@@', 'ase', 'di', 'ghi@@', 'accio', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'il', '40', '%', '.', '</s>']
2024-05-19 13:27:43,864 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:27:43,864 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:27:43,864 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso sono state mostrate queste due slide così che la fase di ghiaccio, che per la maggior parte degli ultimi tre milioni di anni sono stati le dimensioni di basso 48 stati, il 40%.
2024-05-19 13:27:43,864 - INFO - joeynmt.training - Example #1
2024-05-19 13:27:43,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:27:43,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:27:43,865 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'è', 'la', 'sp@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:27:43,866 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:27:43,866 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:27:43,866 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serietà di questo particolare problema perché non è la spità del ghiaccio.
2024-05-19 13:27:43,866 - INFO - joeynmt.training - Example #2
2024-05-19 13:27:43,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:27:43,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:27:43,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 'della', 'c@@', 'ca@@', 'ot@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:27:43,868 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:27:43,868 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:27:43,868 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio della ccaotica è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:27:43,868 - INFO - joeynmt.training - Example #3
2024-05-19 13:27:43,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:27:43,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:27:43,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'pe@@', 'vol@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:27:43,869 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:27:43,870 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:27:43,870 - INFO - joeynmt.training - 	Hypothesis: Spevole in inverno e si è contratti in estate.
2024-05-19 13:27:43,870 - INFO - joeynmt.training - Example #4
2024-05-19 13:27:43,870 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:27:43,871 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:27:43,871 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'sarà', 'un', 'rapi@@', 'do', 'di', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:27:43,871 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:27:43,872 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:27:43,872 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro sarà un rapido di più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:27:48,294 - INFO - joeynmt.training - Epoch   5, Step:    20600, Batch Loss:     1.502687, Batch Acc: 0.593731, Tokens per Sec:    14782, Lr: 0.000300
2024-05-19 13:27:51,931 - INFO - joeynmt.training - Epoch   5, Step:    20700, Batch Loss:     1.468140, Batch Acc: 0.593848, Tokens per Sec:    19740, Lr: 0.000300
2024-05-19 13:27:55,552 - INFO - joeynmt.training - Epoch   5, Step:    20800, Batch Loss:     1.470459, Batch Acc: 0.592976, Tokens per Sec:    19918, Lr: 0.000300
2024-05-19 13:28:00,064 - INFO - joeynmt.training - Epoch   5, Step:    20900, Batch Loss:     1.459210, Batch Acc: 0.594669, Tokens per Sec:    15385, Lr: 0.000300
2024-05-19 13:28:03,715 - INFO - joeynmt.training - Epoch   5, Step:    21000, Batch Loss:     1.507513, Batch Acc: 0.591943, Tokens per Sec:    19996, Lr: 0.000300
2024-05-19 13:28:03,715 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:28:03,716 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:28:15,099 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.88, acc:   0.57, generation: 11.2629[sec], evaluation: 0.0000[sec]
2024-05-19 13:28:15,100 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:28:15,415 - INFO - joeynmt.helpers - delete bpe_model_4000/19000.ckpt
2024-05-19 13:28:15,426 - INFO - joeynmt.training - Example #0
2024-05-19 13:28:15,427 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:28:15,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:28:15,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'ul@@', 'time', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '4@@', '8', 'stati', ',', 'ha', 'sp@@', 'azz@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:28:15,429 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:28:15,429 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:28:15,429 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso che ho mostrato queste due diapositive, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle ultime tre milioni di anni è stata la dimensione di 48 stati, ha spazzato dal 40%.
2024-05-19 13:28:15,430 - INFO - joeynmt.training - Example #1
2024-05-19 13:28:15,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:28:15,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:28:15,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'ess@@', 'enza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:28:15,431 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:28:15,431 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:28:15,431 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo particolare problema perché non mostra la spessenza del ghiaccio.
2024-05-19 13:28:15,432 - INFO - joeynmt.training - Example #2
2024-05-19 13:28:15,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:28:15,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:28:15,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'car@@', 'di@@', 'ac@@', 'a', 'car@@', 'di@@', 'ac@@', 'a', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:28:15,433 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:28:15,433 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:28:15,434 - INFO - joeynmt.training - 	Hypothesis: La cardiaca cardiaca è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:28:15,434 - INFO - joeynmt.training - Example #3
2024-05-19 13:28:15,434 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:28:15,434 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:28:15,434 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'si', 'è', 'in', 'est@@', 'i@@', 've', '.', '</s>']
2024-05-19 13:28:15,435 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:28:15,435 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:28:15,436 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e si si è in estive.
2024-05-19 13:28:15,436 - INFO - joeynmt.training - Example #4
2024-05-19 13:28:15,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:28:15,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:28:15,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'una', 'rapi@@', 'da', 'più', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:28:15,437 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:28:15,438 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:28:15,438 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò una rapida più veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:28:19,100 - INFO - joeynmt.training - Epoch   5, Step:    21100, Batch Loss:     1.288941, Batch Acc: 0.593806, Tokens per Sec:    18195, Lr: 0.000300
2024-05-19 13:28:22,659 - INFO - joeynmt.training - Epoch   5, Step:    21200, Batch Loss:     1.425225, Batch Acc: 0.599373, Tokens per Sec:    19906, Lr: 0.000300
2024-05-19 13:28:26,688 - INFO - joeynmt.training - Epoch   5, Step:    21300, Batch Loss:     1.419674, Batch Acc: 0.589388, Tokens per Sec:    17544, Lr: 0.000300
2024-05-19 13:28:30,743 - INFO - joeynmt.training - Epoch   5, Step:    21400, Batch Loss:     1.327712, Batch Acc: 0.588980, Tokens per Sec:    17564, Lr: 0.000300
2024-05-19 13:28:34,377 - INFO - joeynmt.training - Epoch   5, Step:    21500, Batch Loss:     1.381309, Batch Acc: 0.593593, Tokens per Sec:    19990, Lr: 0.000300
2024-05-19 13:28:34,378 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:28:34,378 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:28:45,675 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.87, acc:   0.57, generation: 11.1574[sec], evaluation: 0.0000[sec]
2024-05-19 13:28:45,676 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:28:46,011 - INFO - joeynmt.helpers - delete bpe_model_4000/18500.ckpt
2024-05-19 13:28:46,022 - INFO - joeynmt.training - Example #0
2024-05-19 13:28:46,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:28:46,023 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:28:46,023 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'car@@', 't@@', 'ica', 'di', 'f@@', 'ame', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '4@@', '8', 'stati', ',', 'si', 'è', 'di@@', 'min@@', 'acci@@', 'a', 'da', '40', '%', '.', '</s>']
2024-05-19 13:28:46,024 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:28:46,024 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:28:46,025 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso che ho mostrato queste due diapositive che la cartica di fame, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione di 48 stati, si è diminaccia da 40%.
2024-05-19 13:28:46,025 - INFO - joeynmt.training - Example #1
2024-05-19 13:28:46,025 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:28:46,025 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:28:46,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'è', 'mostr@@', 'ata', 'la', 'sp@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:28:46,026 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:28:46,026 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:28:46,027 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serietà di questo particolare problema perché non è mostrata la spità del ghiaccio.
2024-05-19 13:28:46,027 - INFO - joeynmt.training - Example #2
2024-05-19 13:28:46,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:28:46,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:28:46,028 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'car@@', 'ta', 'di', 'car@@', 'di@@', 'ac@@', 'o', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:28:46,028 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:28:46,029 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:28:46,029 - INFO - joeynmt.training - 	Hypothesis: La carta di cardiaco è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:28:46,029 - INFO - joeynmt.training - Example #3
2024-05-19 13:28:46,030 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:28:46,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:28:46,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:28:46,031 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:28:46,031 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:28:46,031 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e si è contratti in estate.
2024-05-19 13:28:46,031 - INFO - joeynmt.training - Example #4
2024-05-19 13:28:46,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:28:46,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:28:46,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'un', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:28:46,033 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:28:46,033 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:28:46,033 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro un rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:28:49,666 - INFO - joeynmt.training - Epoch   5, Step:    21600, Batch Loss:     1.468641, Batch Acc: 0.590852, Tokens per Sec:    18124, Lr: 0.000300
2024-05-19 13:28:53,483 - INFO - joeynmt.training - Epoch   5, Step:    21700, Batch Loss:     1.414349, Batch Acc: 0.595209, Tokens per Sec:    18784, Lr: 0.000300
2024-05-19 13:28:55,364 - INFO - joeynmt.training - Epoch   5: total training loss 6362.08
2024-05-19 13:28:55,364 - INFO - joeynmt.training - EPOCH 6
2024-05-19 13:28:57,957 - INFO - joeynmt.training - Epoch   6, Step:    21800, Batch Loss:     1.192356, Batch Acc: 0.612633, Tokens per Sec:    16235, Lr: 0.000300
2024-05-19 13:29:01,650 - INFO - joeynmt.training - Epoch   6, Step:    21900, Batch Loss:     1.324556, Batch Acc: 0.621670, Tokens per Sec:    19440, Lr: 0.000300
2024-05-19 13:29:05,308 - INFO - joeynmt.training - Epoch   6, Step:    22000, Batch Loss:     1.335397, Batch Acc: 0.621721, Tokens per Sec:    20250, Lr: 0.000300
2024-05-19 13:29:05,309 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:29:05,309 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:29:16,743 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.85, acc:   0.57, generation: 11.3246[sec], evaluation: 0.0000[sec]
2024-05-19 13:29:16,744 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:29:17,004 - INFO - joeynmt.helpers - delete bpe_model_4000/19500.ckpt
2024-05-19 13:29:17,014 - INFO - joeynmt.training - Example #0
2024-05-19 13:29:17,015 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:29:17,015 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:29:17,016 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'macchina', '.', '</s>']
2024-05-19 13:29:17,016 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:29:17,017 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:29:17,017 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso che ho mostrato queste due slide così che la macchina.
2024-05-19 13:29:17,017 - INFO - joeynmt.training - Example #1
2024-05-19 13:29:17,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:29:17,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:29:17,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'sp@@', 'av@@', 'ent@@', 'a', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:29:17,018 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:29:17,019 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:29:17,019 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serie di questo particolare problema perché non ha mostrato la spaventa del ghiaccio.
2024-05-19 13:29:17,019 - INFO - joeynmt.training - Example #2
2024-05-19 13:29:17,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:29:17,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:29:17,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'car@@', 'ta', 'arti@@', 'fici@@', 'ale', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:29:17,020 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:29:17,021 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:29:17,021 - INFO - joeynmt.training - 	Hypothesis: La carta artificiale è, in un certo senso, il cuore del sistema globale.
2024-05-19 13:29:17,021 - INFO - joeynmt.training - Example #3
2024-05-19 13:29:17,021 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:29:17,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:29:17,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'man@@', 'i', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:29:17,022 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:29:17,023 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:29:17,023 - INFO - joeynmt.training - 	Hypothesis: Sta mani in inverno e si contratti in estate.
2024-05-19 13:29:17,023 - INFO - joeynmt.training - Example #4
2024-05-19 13:29:17,023 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:29:17,024 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:29:17,024 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'o', 'che', 'sarà', 'un', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:29:17,024 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:29:17,025 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:29:17,025 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostro che sarà un rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:29:20,674 - INFO - joeynmt.training - Epoch   6, Step:    22100, Batch Loss:     1.305632, Batch Acc: 0.620596, Tokens per Sec:    18619, Lr: 0.000300
2024-05-19 13:29:25,272 - INFO - joeynmt.training - Epoch   6, Step:    22200, Batch Loss:     1.254077, Batch Acc: 0.617034, Tokens per Sec:    15765, Lr: 0.000300
2024-05-19 13:29:28,904 - INFO - joeynmt.training - Epoch   6, Step:    22300, Batch Loss:     1.302014, Batch Acc: 0.619784, Tokens per Sec:    19443, Lr: 0.000300
2024-05-19 13:29:32,522 - INFO - joeynmt.training - Epoch   6, Step:    22400, Batch Loss:     1.454287, Batch Acc: 0.613823, Tokens per Sec:    19109, Lr: 0.000300
2024-05-19 13:29:36,384 - INFO - joeynmt.training - Epoch   6, Step:    22500, Batch Loss:     1.383023, Batch Acc: 0.607567, Tokens per Sec:    18837, Lr: 0.000300
2024-05-19 13:29:36,384 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:29:36,385 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:29:47,529 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.84, acc:   0.57, generation: 11.0401[sec], evaluation: 0.0000[sec]
2024-05-19 13:29:47,530 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:29:47,784 - INFO - joeynmt.helpers - delete bpe_model_4000/20000.ckpt
2024-05-19 13:29:47,795 - INFO - joeynmt.training - Example #0
2024-05-19 13:29:47,796 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:29:47,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:29:47,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'car@@', 't@@', 'ica', 'di', 'ghi@@', 'accio', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'a', 'più', 'bas@@', 'so', 'di', '4@@', '8', '%', '.', '</s>']
2024-05-19 13:29:47,797 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:29:47,797 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:29:47,798 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che la cartica di ghiaccio artica, che per la maggior parte degli ultimi tre milioni di anni sono stati le dimensioni di 48 stati, si è rimasta a più basso di 48%.
2024-05-19 13:29:47,798 - INFO - joeynmt.training - Example #1
2024-05-19 13:29:47,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:29:47,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:29:47,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'la', 'sp@@', 'av@@', 'ent@@', 'ità', 'della', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:29:47,799 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:29:47,799 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:29:47,800 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serietà di questo particolare problema perché non mostrano la spaventità della ghiaccio.
2024-05-19 13:29:47,800 - INFO - joeynmt.training - Example #2
2024-05-19 13:29:47,800 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:29:47,800 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:29:47,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'cu@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:29:47,801 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:29:47,801 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:29:47,802 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio artica è, in un certo senso, il cuore di cuore globale.
2024-05-19 13:29:47,802 - INFO - joeynmt.training - Example #3
2024-05-19 13:29:47,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:29:47,802 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:29:47,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:29:47,803 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:29:47,803 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:29:47,804 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e contratti in estate.
2024-05-19 13:29:47,804 - INFO - joeynmt.training - Example #4
2024-05-19 13:29:47,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:29:47,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:29:47,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'o', 'che', 'si', 'sarà', 'un', 'rapi@@', 'do', 'di', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:29:47,805 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:29:47,805 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:29:47,805 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostro che si sarà un rapido di più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:29:51,917 - INFO - joeynmt.training - Epoch   6, Step:    22600, Batch Loss:     1.280261, Batch Acc: 0.610192, Tokens per Sec:    16130, Lr: 0.000300
2024-05-19 13:29:56,036 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.465871, Batch Acc: 0.611502, Tokens per Sec:    17327, Lr: 0.000300
2024-05-19 13:29:59,710 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.605020, Batch Acc: 0.604825, Tokens per Sec:    19752, Lr: 0.000300
2024-05-19 13:30:03,371 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.440788, Batch Acc: 0.614258, Tokens per Sec:    19778, Lr: 0.000300
2024-05-19 13:30:07,945 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.342812, Batch Acc: 0.610053, Tokens per Sec:    15703, Lr: 0.000300
2024-05-19 13:30:07,945 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:30:07,946 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:30:18,442 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.85, acc:   0.57, generation: 10.2925[sec], evaluation: 0.0000[sec]
2024-05-19 13:30:18,731 - INFO - joeynmt.helpers - delete bpe_model_4000/20500.ckpt
2024-05-19 13:30:18,747 - INFO - joeynmt.training - Example #0
2024-05-19 13:30:18,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:30:18,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:30:18,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'ca@@', 'po', 'di', 'di', 'di@@', 'mostr@@', 'are', 'che', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'ar@@', 't@@', 'ico', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', 'di', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'di@@', 'co@@', 'sta', 'dal', '40', 'perc@@', 'ento', '.', '</s>']
2024-05-19 13:30:18,748 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:30:18,749 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:30:18,749 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che la capo di di dimostrare che l'artico, che per la maggior parte degli ultimi tre milioni di anni sono stati le dimensioni di più basso di 48 stati, si è rimadicosta dal 40 percento.
2024-05-19 13:30:18,749 - INFO - joeynmt.training - Example #1
2024-05-19 13:30:18,749 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:30:18,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:30:18,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'problema', ',', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'inter@@', 'esse', 'di', 'questo', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'la', 'sp@@', 'alla', 'alla', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:30:18,750 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:30:18,751 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:30:18,751 - INFO - joeynmt.training - 	Hypothesis: Ma questo problema, l'interesse di questo problema perché non mostrano la spalla alla ghiaccio.
2024-05-19 13:30:18,751 - INFO - joeynmt.training - Example #2
2024-05-19 13:30:18,751 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:30:18,751 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:30:18,752 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'della', 'c@@', 'att@@', 'ica', 'è', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:30:18,752 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:30:18,752 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:30:18,753 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio della cattica è in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:30:18,753 - INFO - joeynmt.training - Example #3
2024-05-19 13:30:18,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:30:18,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:30:18,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ex@@', 'p@@', 'and@@', 'e', 'in', 'contr@@', 'atto', 'in', 'est@@', 'ate', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:30:18,754 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:30:18,754 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:30:18,754 - INFO - joeynmt.training - 	Hypothesis: Sexpande in contratto in estate e contratti in estate.
2024-05-19 13:30:18,754 - INFO - joeynmt.training - Example #4
2024-05-19 13:30:18,755 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:30:18,755 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:30:18,755 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'erò', 'sarà', 'una', 'rapi@@', 'da', 'di', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:30:18,756 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:30:18,756 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:30:18,756 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostrerò sarà una rapida di più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:30:23,118 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.407888, Batch Acc: 0.615950, Tokens per Sec:    15801, Lr: 0.000300
2024-05-19 13:30:26,751 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     1.275008, Batch Acc: 0.609100, Tokens per Sec:    19752, Lr: 0.000300
2024-05-19 13:30:30,412 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.295366, Batch Acc: 0.605352, Tokens per Sec:    19116, Lr: 0.000300
2024-05-19 13:30:34,554 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.607453, Batch Acc: 0.606038, Tokens per Sec:    17308, Lr: 0.000300
2024-05-19 13:30:38,633 - INFO - joeynmt.training - Epoch   6, Step:    23500, Batch Loss:     1.495510, Batch Acc: 0.604621, Tokens per Sec:    17808, Lr: 0.000300
2024-05-19 13:30:38,633 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:30:38,634 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:30:48,899 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.77, acc:   0.57, generation: 10.0741[sec], evaluation: 0.0000[sec]
2024-05-19 13:30:48,901 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:30:49,210 - INFO - joeynmt.helpers - delete bpe_model_4000/21000.ckpt
2024-05-19 13:30:49,227 - INFO - joeynmt.training - Example #0
2024-05-19 13:30:49,229 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:30:49,229 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:30:49,229 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mo@@', 'stra@@', 'de', 'che', 'la', 'più', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '4@@', '8', 'stati', 'le', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'e', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:30:49,230 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:30:49,231 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:30:49,231 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso anno ho mostrato queste due slide così che dimostrade che la più artica, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione di 48 stati le dimensioni di 48 stati, e si è rimasta dal 40%.
2024-05-19 13:30:49,231 - INFO - joeynmt.training - Example #1
2024-05-19 13:30:49,232 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:30:49,232 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:30:49,232 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'la', 'sp@@', 'ess@@', 'enza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:30:49,233 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:30:49,233 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:30:49,233 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serietà di questo particolare problema perché non mostrano la spessenza del ghiaccio.
2024-05-19 13:30:49,234 - INFO - joeynmt.training - Example #2
2024-05-19 13:30:49,234 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:30:49,234 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:30:49,234 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'ar@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:30:49,235 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:30:49,236 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:30:49,236 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio artico è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:30:49,236 - INFO - joeynmt.training - Example #3
2024-05-19 13:30:49,236 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:30:49,237 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:30:49,237 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:30:49,237 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:30:49,238 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:30:49,238 - INFO - joeynmt.training - 	Hypothesis: Si espande in estate e contratti in estate.
2024-05-19 13:30:49,238 - INFO - joeynmt.training - Example #4
2024-05-19 13:30:49,239 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:30:49,239 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:30:49,239 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'erò', 'sarà', 'un', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:30:49,240 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:30:49,240 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:30:49,240 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostrerò sarà un rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:30:53,284 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.439561, Batch Acc: 0.608472, Tokens per Sec:    16884, Lr: 0.000300
2024-05-19 13:30:57,009 - INFO - joeynmt.training - Epoch   6, Step:    23700, Batch Loss:     1.487929, Batch Acc: 0.610791, Tokens per Sec:    18944, Lr: 0.000300
2024-05-19 13:31:01,001 - INFO - joeynmt.training - Epoch   6, Step:    23800, Batch Loss:     1.366154, Batch Acc: 0.608358, Tokens per Sec:    17963, Lr: 0.000300
2024-05-19 13:31:06,099 - INFO - joeynmt.training - Epoch   6, Step:    23900, Batch Loss:     1.508088, Batch Acc: 0.607621, Tokens per Sec:    13845, Lr: 0.000300
2024-05-19 13:31:10,002 - INFO - joeynmt.training - Epoch   6, Step:    24000, Batch Loss:     1.335523, Batch Acc: 0.607487, Tokens per Sec:    18284, Lr: 0.000300
2024-05-19 13:31:10,002 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:31:10,003 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:31:22,133 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.81, acc:   0.57, generation: 12.0133[sec], evaluation: 0.0000[sec]
2024-05-19 13:31:22,393 - INFO - joeynmt.helpers - delete bpe_model_4000/21500.ckpt
2024-05-19 13:31:22,417 - INFO - joeynmt.training - Example #0
2024-05-19 13:31:22,418 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:31:22,418 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:31:22,419 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'ca@@', 'p@@', 'a', 'di', 'ghi@@', 'accio', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '4@@', '8', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'bas@@', 'so', ',', 'si', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'per', 'c@@', 'ento', '.', '</s>']
2024-05-19 13:31:22,419 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:31:22,420 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:31:22,420 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diapositive così che la capa di ghiaccio che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione di 48 stati le dimensioni di basso, si si è rimasta per cento.
2024-05-19 13:31:22,420 - INFO - joeynmt.training - Example #1
2024-05-19 13:31:22,421 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:31:22,421 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:31:22,421 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'la', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 'sua', 't@@', 'es@@', 'su@@', 'to', '.', '</s>']
2024-05-19 13:31:22,422 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:31:22,422 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:31:22,422 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serietà di questo particolare problema perché non ha la sua sua sua sua sua sua sua tessuto.
2024-05-19 13:31:22,423 - INFO - joeynmt.training - Example #2
2024-05-19 13:31:22,423 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:31:22,423 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:31:22,423 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'car@@', 't@@', 'ica', 'car@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'suo', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:31:22,424 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:31:22,424 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:31:22,425 - INFO - joeynmt.training - 	Hypothesis: La cartica cartico è, in un certo senso, il suo cuore del sistema globale.
2024-05-19 13:31:22,425 - INFO - joeynmt.training - Example #3
2024-05-19 13:31:22,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:31:22,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:31:22,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:31:22,426 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:31:22,427 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:31:22,427 - INFO - joeynmt.training - 	Hypothesis: Spande in estate e contratti in estate.
2024-05-19 13:31:22,427 - INFO - joeynmt.training - Example #4
2024-05-19 13:31:22,427 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:31:22,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:31:22,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'successi@@', 'va', 'successi@@', 'va', 'vi', 'vi', 'mostr@@', 'erò', 'una', 'rapi@@', 'da', 'su', 'cosa', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:31:22,428 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:31:22,429 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:31:22,429 - INFO - joeynmt.training - 	Hypothesis: La successiva successiva vi vi mostrerò una rapida su cosa è successo negli ultimi 25 anni.
2024-05-19 13:31:26,180 - INFO - joeynmt.training - Epoch   6, Step:    24100, Batch Loss:     1.585991, Batch Acc: 0.609616, Tokens per Sec:    17737, Lr: 0.000300
2024-05-19 13:31:29,949 - INFO - joeynmt.training - Epoch   6, Step:    24200, Batch Loss:     1.382577, Batch Acc: 0.603952, Tokens per Sec:    19351, Lr: 0.000300
2024-05-19 13:31:34,659 - INFO - joeynmt.training - Epoch   6, Step:    24300, Batch Loss:     1.570652, Batch Acc: 0.601992, Tokens per Sec:    15114, Lr: 0.000300
2024-05-19 13:31:38,257 - INFO - joeynmt.training - Epoch   6, Step:    24400, Batch Loss:     1.442087, Batch Acc: 0.608417, Tokens per Sec:    19968, Lr: 0.000300
2024-05-19 13:31:41,856 - INFO - joeynmt.training - Epoch   6, Step:    24500, Batch Loss:     1.568626, Batch Acc: 0.610213, Tokens per Sec:    19550, Lr: 0.000300
2024-05-19 13:31:41,857 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:31:41,857 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:31:53,295 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.75, acc:   0.57, generation: 11.3328[sec], evaluation: 0.0000[sec]
2024-05-19 13:31:53,296 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:31:53,561 - INFO - joeynmt.helpers - delete bpe_model_4000/22000.ckpt
2024-05-19 13:31:53,575 - INFO - joeynmt.training - Example #0
2024-05-19 13:31:53,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:31:53,577 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:31:53,577 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'che', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mostr@@', 'ai', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', 'di', '4@@', '8', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', 'di', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'da', '40', '%', '.', '</s>']
2024-05-19 13:31:53,579 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:31:53,579 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:31:53,579 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso che ho mostrato queste due slide così che dimostrai che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di più basso di 48 stati le dimensioni di più basso di 48 stati, si è rimasta da 40%.
2024-05-19 13:31:53,579 - INFO - joeynmt.training - Example #1
2024-05-19 13:31:53,580 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:31:53,580 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:31:53,580 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'è', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:31:53,581 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:31:53,581 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:31:53,581 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serietà di questo particolare problema perché non è la spessità del ghiaccio.
2024-05-19 13:31:53,582 - INFO - joeynmt.training - Example #2
2024-05-19 13:31:53,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:31:53,582 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:31:53,582 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p', 'ar@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'un', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:31:53,583 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:31:53,583 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:31:53,584 - INFO - joeynmt.training - 	Hypothesis: La cap artico è, in un certo senso, il cuore di un sistema globale.
2024-05-19 13:31:53,584 - INFO - joeynmt.training - Example #3
2024-05-19 13:31:53,584 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:31:53,584 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:31:53,585 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'si', 'è', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:31:53,585 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:31:53,585 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:31:53,586 - INFO - joeynmt.training - 	Hypothesis: Si espande in estate e si è in estate.
2024-05-19 13:31:53,586 - INFO - joeynmt.training - Example #4
2024-05-19 13:31:53,586 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:31:53,586 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:31:53,587 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'o', 'è', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:31:53,587 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:31:53,588 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:31:53,588 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostro che vi mostro è un rapido rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:31:57,256 - INFO - joeynmt.training - Epoch   6, Step:    24600, Batch Loss:     1.314781, Batch Acc: 0.608914, Tokens per Sec:    18082, Lr: 0.000300
2024-05-19 13:32:01,496 - INFO - joeynmt.training - Epoch   6, Step:    24700, Batch Loss:     1.499369, Batch Acc: 0.601919, Tokens per Sec:    17090, Lr: 0.000300
2024-05-19 13:32:05,510 - INFO - joeynmt.training - Epoch   6, Step:    24800, Batch Loss:     1.572253, Batch Acc: 0.611094, Tokens per Sec:    17832, Lr: 0.000300
2024-05-19 13:32:09,192 - INFO - joeynmt.training - Epoch   6, Step:    24900, Batch Loss:     1.402712, Batch Acc: 0.608127, Tokens per Sec:    19704, Lr: 0.000300
2024-05-19 13:32:12,754 - INFO - joeynmt.training - Epoch   6, Step:    25000, Batch Loss:     1.237710, Batch Acc: 0.610972, Tokens per Sec:    19789, Lr: 0.000300
2024-05-19 13:32:12,755 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:32:12,758 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:32:23,466 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.75, acc:   0.58, generation: 10.6063[sec], evaluation: 0.0000[sec]
2024-05-19 13:32:23,467 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:32:23,722 - INFO - joeynmt.helpers - delete bpe_model_4000/23000.ckpt
2024-05-19 13:32:23,732 - INFO - joeynmt.training - Example #0
2024-05-19 13:32:23,733 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:32:23,734 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:32:23,734 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'che', 'la', 'ca@@', 'p@@', 'elle', 'ar@@', 'te', 'di', 'più', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'delle', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'il', '40', 'stati', ',', 'si', 'sta', 'di@@', 'etro', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:32:23,735 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:32:23,735 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:32:23,735 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che dimostrò che la capelle arte di più basso 48 stati, la dimensione delle dimensioni delle dimensioni di più basso 48 stati, il 40 stati, si sta dietro dal 40%.
2024-05-19 13:32:23,736 - INFO - joeynmt.training - Example #1
2024-05-19 13:32:23,736 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:32:23,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:32:23,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questa', 'com@@', 'pre@@', 'se', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostra', 'la', 'sp@@', 'ess@@', 'enza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:32:23,737 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:32:23,738 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:32:23,738 - INFO - joeynmt.training - 	Hypothesis: Ma questa comprese la serietà di questo particolare problema perché non mostra la spessenza del ghiaccio.
2024-05-19 13:32:23,738 - INFO - joeynmt.training - Example #2
2024-05-19 13:32:23,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:32:23,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:32:23,739 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:32:23,739 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:32:23,740 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:32:23,740 - INFO - joeynmt.training - 	Hypothesis: La cap artica è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:32:23,740 - INFO - joeynmt.training - Example #3
2024-05-19 13:32:23,740 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:32:23,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:32:23,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:32:23,741 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:32:23,742 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:32:23,742 - INFO - joeynmt.training - 	Hypothesis: Si espande in inverno e si è in estate.
2024-05-19 13:32:23,742 - INFO - joeynmt.training - Example #4
2024-05-19 13:32:23,742 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:32:23,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:32:23,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'rapi@@', 'da', 'su', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:32:23,743 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:32:23,744 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:32:23,744 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro rapida su quello che è successo negli ultimi 25 anni.
2024-05-19 13:32:27,478 - INFO - joeynmt.training - Epoch   6, Step:    25100, Batch Loss:     1.351949, Batch Acc: 0.610559, Tokens per Sec:    18360, Lr: 0.000300
2024-05-19 13:32:31,968 - INFO - joeynmt.training - Epoch   6, Step:    25200, Batch Loss:     1.361433, Batch Acc: 0.608140, Tokens per Sec:    15952, Lr: 0.000300
2024-05-19 13:32:35,531 - INFO - joeynmt.training - Epoch   6, Step:    25300, Batch Loss:     1.523845, Batch Acc: 0.614011, Tokens per Sec:    20385, Lr: 0.000300
2024-05-19 13:32:39,122 - INFO - joeynmt.training - Epoch   6, Step:    25400, Batch Loss:     1.342569, Batch Acc: 0.612045, Tokens per Sec:    19798, Lr: 0.000300
2024-05-19 13:32:43,248 - INFO - joeynmt.training - Epoch   6, Step:    25500, Batch Loss:     1.491876, Batch Acc: 0.603284, Tokens per Sec:    16973, Lr: 0.000300
2024-05-19 13:32:43,249 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:32:43,249 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:32:53,293 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.70, acc:   0.58, generation: 9.9329[sec], evaluation: 0.0000[sec]
2024-05-19 13:32:53,294 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:32:53,546 - INFO - joeynmt.helpers - delete bpe_model_4000/22500.ckpt
2024-05-19 13:32:53,556 - INFO - joeynmt.training - Example #0
2024-05-19 13:32:53,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:32:53,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:32:53,558 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'str@@', 'ate', 'che', 'di@@', 'mostr@@', 'ò', 'la', 'ca@@', 'p@@', 'a', 'di', 'ghi@@', 'accio', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'si', 'sta', 'più', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'il', '40', '%', '.', '</s>']
2024-05-19 13:32:53,559 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:32:53,559 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:32:53,559 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diastrate che dimostrò la capa di ghiaccio che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di 48 stati, si sta più basso 48 stati, il 40%.
2024-05-19 13:32:53,560 - INFO - joeynmt.training - Example #1
2024-05-19 13:32:53,560 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:32:53,560 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:32:53,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'com@@', 'preso', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'la', 't@@', 'el@@', 'ezza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:32:53,561 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:32:53,562 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:32:53,562 - INFO - joeynmt.training - 	Hypothesis: Ma questo compreso la serie di questo particolare problema perché non mostrano la telezza del ghiaccio.
2024-05-19 13:32:53,562 - INFO - joeynmt.training - Example #2
2024-05-19 13:32:53,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:32:53,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:32:53,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'ar@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:32:53,563 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:32:53,564 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:32:53,564 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio artico è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:32:53,564 - INFO - joeynmt.training - Example #3
2024-05-19 13:32:53,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:32:53,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:32:53,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'man@@', 'i', 'in', 'est@@', 'ate', 'e', 'si', 'con@@', 'net@@', 'te', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:32:53,565 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:32:53,566 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:32:53,566 - INFO - joeynmt.training - 	Hypothesis: Sta mani in estate e si connette in estate.
2024-05-19 13:32:53,566 - INFO - joeynmt.training - Example #4
2024-05-19 13:32:53,566 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:32:53,566 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:32:53,567 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'sarà', 'un', 'rapi@@', 'do', 'rapi@@', 'd@@', 'amente', 'su', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:32:53,567 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:32:53,567 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:32:53,568 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro sarà un rapido rapidamente su ciò che è successo negli ultimi 25 anni.
2024-05-19 13:32:57,730 - INFO - joeynmt.training - Epoch   6, Step:    25600, Batch Loss:     1.447250, Batch Acc: 0.606548, Tokens per Sec:    16579, Lr: 0.000300
2024-05-19 13:33:01,706 - INFO - joeynmt.training - Epoch   6, Step:    25700, Batch Loss:     1.555531, Batch Acc: 0.615490, Tokens per Sec:    17677, Lr: 0.000300
2024-05-19 13:33:05,462 - INFO - joeynmt.training - Epoch   6, Step:    25800, Batch Loss:     1.292322, Batch Acc: 0.612657, Tokens per Sec:    19856, Lr: 0.000300
2024-05-19 13:33:09,069 - INFO - joeynmt.training - Epoch   6, Step:    25900, Batch Loss:     1.423198, Batch Acc: 0.604346, Tokens per Sec:    19674, Lr: 0.000300
2024-05-19 13:33:13,593 - INFO - joeynmt.training - Epoch   6, Step:    26000, Batch Loss:     1.426454, Batch Acc: 0.610021, Tokens per Sec:    15519, Lr: 0.000300
2024-05-19 13:33:13,593 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:33:13,594 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:33:24,382 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.73, acc:   0.57, generation: 10.5891[sec], evaluation: 0.0000[sec]
2024-05-19 13:33:24,695 - INFO - joeynmt.helpers - delete bpe_model_4000/24000.ckpt
2024-05-19 13:33:24,712 - INFO - joeynmt.training - Example #0
2024-05-19 13:33:24,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:33:24,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:33:24,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'str@@', 'ate', 'che', 'la', 'ca@@', 'po', 'di', 'car@@', 'tell@@', 'a', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'dei', 'più', 'bas@@', 'si', 'del', '40', 'stati', ',', 'ha', 'di@@', 'mostr@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:33:24,715 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:33:24,716 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:33:24,716 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diastrate che la capo di cartella, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione dei più bassi del 40 stati, ha dimostrato dal 40%.
2024-05-19 13:33:24,716 - INFO - joeynmt.training - Example #1
2024-05-19 13:33:24,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:33:24,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:33:24,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questa', 'capi@@', 'sce', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'tr@@', 'acci@@', 'a', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:33:24,718 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:33:24,718 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:33:24,718 - INFO - joeynmt.training - 	Hypothesis: Ma questa capisce la serie di questo particolare problema perché non mostra la traccia del ghiaccio.
2024-05-19 13:33:24,719 - INFO - joeynmt.training - Example #2
2024-05-19 13:33:24,719 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:33:24,719 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:33:24,719 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'po', 'di', 'un', 'ca@@', 'po', 'e', '&@@', 'a@@', 'pos@@', ';', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:33:24,720 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:33:24,723 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:33:24,723 - INFO - joeynmt.training - 	Hypothesis: La capo di un capo e ', in un certo senso, il cuore del sistema globale.
2024-05-19 13:33:24,723 - INFO - joeynmt.training - Example #3
2024-05-19 13:33:24,723 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:33:24,724 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:33:24,724 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ex@@', 'ex@@', 'ing', 'e', 'cont@@', 'est@@', 'ate', 'in', 'est@@', 'i@@', 'vo', 'e', 'cont@@', 'est@@', 'i@@', 'vo', '.', '</s>']
2024-05-19 13:33:24,724 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:33:24,725 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:33:24,725 - INFO - joeynmt.training - 	Hypothesis: Sexexing e contestate in estivo e contestivo.
2024-05-19 13:33:24,725 - INFO - joeynmt.training - Example #4
2024-05-19 13:33:24,726 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:33:24,726 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:33:24,726 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'rapi@@', 'da', 'più', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'acca@@', 'du@@', 'to', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:33:24,727 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:33:24,727 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:33:24,727 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro rapida più veloce di quello che è accaduto negli ultimi 25 anni.
2024-05-19 13:33:28,381 - INFO - joeynmt.training - Epoch   6: total training loss 6077.28
2024-05-19 13:33:28,381 - INFO - joeynmt.training - EPOCH 7
2024-05-19 13:33:29,098 - INFO - joeynmt.training - Epoch   7, Step:    26100, Batch Loss:     1.247450, Batch Acc: 0.629561, Tokens per Sec:    20300, Lr: 0.000300
2024-05-19 13:33:32,748 - INFO - joeynmt.training - Epoch   7, Step:    26200, Batch Loss:     1.349564, Batch Acc: 0.636248, Tokens per Sec:    19571, Lr: 0.000300
2024-05-19 13:33:36,411 - INFO - joeynmt.training - Epoch   7, Step:    26300, Batch Loss:     1.361818, Batch Acc: 0.630801, Tokens per Sec:    20193, Lr: 0.000300
2024-05-19 13:33:40,607 - INFO - joeynmt.training - Epoch   7, Step:    26400, Batch Loss:     1.149022, Batch Acc: 0.629926, Tokens per Sec:    17263, Lr: 0.000300
2024-05-19 13:33:44,419 - INFO - joeynmt.training - Epoch   7, Step:    26500, Batch Loss:     1.466010, Batch Acc: 0.635657, Tokens per Sec:    18596, Lr: 0.000300
2024-05-19 13:33:44,420 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:33:44,420 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:33:54,939 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.71, acc:   0.58, generation: 10.3248[sec], evaluation: 0.0000[sec]
2024-05-19 13:33:55,255 - INFO - joeynmt.helpers - delete bpe_model_4000/23500.ckpt
2024-05-19 13:33:55,260 - INFO - joeynmt.training - Example #0
2024-05-19 13:33:55,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:33:55,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:33:55,262 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'ca@@', 'po', 'di', 'ghi@@', 'accio', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'dei', '4@@', '8', 'stati', ',', 'che', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:33:55,263 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:33:55,265 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:33:55,266 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che la capo di ghiaccio artica, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione dei 48 stati, che si è rimasta dal 40%.
2024-05-19 13:33:55,266 - INFO - joeynmt.training - Example #1
2024-05-19 13:33:55,266 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:33:55,266 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:33:55,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questa', 'compren@@', 'sione', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'ess@@', 'enza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:33:55,267 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:33:55,268 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:33:55,268 - INFO - joeynmt.training - 	Hypothesis: Ma questa comprensione la serie di questo particolare problema perché non mostra la spessenza del ghiaccio.
2024-05-19 13:33:55,268 - INFO - joeynmt.training - Example #2
2024-05-19 13:33:55,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:33:55,269 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:33:55,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'a', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'ap@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:33:55,270 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:33:55,270 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:33:55,270 - INFO - joeynmt.training - 	Hypothesis: La capa artica è, in un certo senso, il cuore apore del sistema clima globale.
2024-05-19 13:33:55,270 - INFO - joeynmt.training - Example #3
2024-05-19 13:33:55,270 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:33:55,271 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:33:55,271 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ex@@', 'ex@@', 'man@@', 'i', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'si', 'cont@@', 'ra@@', 'd@@', 'ine', '.', '</s>']
2024-05-19 13:33:55,271 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:33:55,272 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:33:55,272 - INFO - joeynmt.training - 	Hypothesis: Sexexmani in inverno e si si contradine.
2024-05-19 13:33:55,272 - INFO - joeynmt.training - Example #4
2024-05-19 13:33:55,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:33:55,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:33:55,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'un', 'rapi@@', 'do', 'rapi@@', 'da', 'di', 'di', 'cosa', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:33:55,274 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:33:55,274 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:33:55,274 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro un rapido rapida di di cosa è successo negli ultimi 25 anni.
2024-05-19 13:33:58,882 - INFO - joeynmt.training - Epoch   7, Step:    26600, Batch Loss:     1.339955, Batch Acc: 0.626702, Tokens per Sec:    17737, Lr: 0.000300
2024-05-19 13:34:02,509 - INFO - joeynmt.training - Epoch   7, Step:    26700, Batch Loss:     1.308506, Batch Acc: 0.624792, Tokens per Sec:    20191, Lr: 0.000300
2024-05-19 13:34:06,325 - INFO - joeynmt.training - Epoch   7, Step:    26800, Batch Loss:     1.226838, Batch Acc: 0.627582, Tokens per Sec:    18298, Lr: 0.000300
2024-05-19 13:34:10,623 - INFO - joeynmt.training - Epoch   7, Step:    26900, Batch Loss:     1.235004, Batch Acc: 0.623937, Tokens per Sec:    16552, Lr: 0.000300
2024-05-19 13:34:14,307 - INFO - joeynmt.training - Epoch   7, Step:    27000, Batch Loss:     1.320629, Batch Acc: 0.618780, Tokens per Sec:    19690, Lr: 0.000300
2024-05-19 13:34:14,308 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:34:14,308 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:34:25,392 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.70, acc:   0.58, generation: 10.9770[sec], evaluation: 0.0000[sec]
2024-05-19 13:34:25,393 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:34:25,651 - INFO - joeynmt.helpers - delete bpe_model_4000/24500.ckpt
2024-05-19 13:34:25,661 - INFO - joeynmt.training - Example #0
2024-05-19 13:34:25,662 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:34:25,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:34:25,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'che', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'si', 'sta', 'ri@@', 'fer@@', 'i@@', 'sce', 'da', '40', '%', '.', '</s>']
2024-05-19 13:34:25,664 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:34:25,664 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:34:25,664 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che dimostrò che la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di più basso 48 stati, si sta riferisce da 40%.
2024-05-19 13:34:25,664 - INFO - joeynmt.training - Example #1
2024-05-19 13:34:25,665 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:34:25,665 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:34:25,665 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'di@@', 'mostr@@', 'ato', 'la', 'sp@@', 'int@@', 'a', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:34:25,666 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:34:25,666 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:34:25,666 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo particolare problema perché non ha dimostrato la spinta del ghiaccio.
2024-05-19 13:34:25,666 - INFO - joeynmt.training - Example #2
2024-05-19 13:34:25,667 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:34:25,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:34:25,667 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'a', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:34:25,668 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:34:25,668 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:34:25,668 - INFO - joeynmt.training - 	Hypothesis: La capa artica è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:34:25,669 - INFO - joeynmt.training - Example #3
2024-05-19 13:34:25,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:34:25,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:34:25,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ign@@', 'ore', 'in', 'in@@', 'ver@@', 'no', 'e', 'cont@@', 'ra@@', 'i', 'in', 'est@@', 'ate', 'e', 'cont@@', 'ra@@', 'i', '.', '</s>']
2024-05-19 13:34:25,670 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:34:25,670 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:34:25,670 - INFO - joeynmt.training - 	Hypothesis: Signore in inverno e contrai in estate e contrai.
2024-05-19 13:34:25,671 - INFO - joeynmt.training - Example #4
2024-05-19 13:34:25,671 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:34:25,671 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:34:25,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'vi', 'vi', 'mostr@@', 'erò', 'una', 'rapi@@', 'da', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:34:25,672 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:34:25,672 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:34:25,672 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva vi vi mostrerò una rapida più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:34:29,234 - INFO - joeynmt.training - Epoch   7, Step:    27100, Batch Loss:     1.156021, Batch Acc: 0.624014, Tokens per Sec:    18607, Lr: 0.000300
2024-05-19 13:34:32,831 - INFO - joeynmt.training - Epoch   7, Step:    27200, Batch Loss:     1.392707, Batch Acc: 0.621123, Tokens per Sec:    19755, Lr: 0.000300
2024-05-19 13:34:37,430 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     1.224245, Batch Acc: 0.619343, Tokens per Sec:    15838, Lr: 0.000300
2024-05-19 13:34:41,253 - INFO - joeynmt.training - Epoch   7, Step:    27400, Batch Loss:     1.194896, Batch Acc: 0.628425, Tokens per Sec:    18694, Lr: 0.000300
2024-05-19 13:34:44,855 - INFO - joeynmt.training - Epoch   7, Step:    27500, Batch Loss:     1.488525, Batch Acc: 0.630656, Tokens per Sec:    19458, Lr: 0.000300
2024-05-19 13:34:44,856 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:34:44,856 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:34:55,131 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.71, acc:   0.58, generation: 10.1714[sec], evaluation: 0.0000[sec]
2024-05-19 13:34:55,381 - INFO - joeynmt.helpers - delete bpe_model_4000/25000.ckpt
2024-05-19 13:34:55,392 - INFO - joeynmt.training - Example #0
2024-05-19 13:34:55,393 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:34:55,394 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:34:55,394 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Lo', 'scor@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mostr@@', 'o', 'la', 'ca@@', 'p@@', 'elle', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'dei', '4@@', '8', 'stati', ',', 'si', 'è', 'al@@', 'z@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:34:55,395 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:34:55,395 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:34:55,396 - INFO - joeynmt.training - 	Hypothesis: Lo scorso anno ho mostrato queste due slide così che dimostro la capelle artica, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione dei 48 stati, si è alzato dal 40%.
2024-05-19 13:34:55,396 - INFO - joeynmt.training - Example #1
2024-05-19 13:34:55,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:34:55,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:34:55,397 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'ess@@', 'enza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:34:55,397 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:34:55,398 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:34:55,398 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serietà di questo particolare problema perché non mostra la spessenza del ghiaccio.
2024-05-19 13:34:55,398 - INFO - joeynmt.training - Example #2
2024-05-19 13:34:55,398 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:34:55,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:34:55,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'a', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:34:55,399 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:34:55,400 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:34:55,400 - INFO - joeynmt.training - 	Hypothesis: La capa artica è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:34:55,400 - INFO - joeynmt.training - Example #3
2024-05-19 13:34:55,401 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:34:55,401 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:34:55,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'si', 'è', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:34:55,401 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:34:55,402 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:34:55,402 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e si si è estate.
2024-05-19 13:34:55,402 - INFO - joeynmt.training - Example #4
2024-05-19 13:34:55,403 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:34:55,403 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:34:55,403 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'che', 'vi', 'mostr@@', 'erò', 'sarà', 'una', 'rapi@@', 'da', 'di', 'più', 'velo@@', 'ci', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:34:55,404 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:34:55,404 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:34:55,404 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò sarà una rapida di più veloci di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:34:59,007 - INFO - joeynmt.training - Epoch   7, Step:    27600, Batch Loss:     1.516326, Batch Acc: 0.627455, Tokens per Sec:    18605, Lr: 0.000300
2024-05-19 13:35:02,869 - INFO - joeynmt.training - Epoch   7, Step:    27700, Batch Loss:     1.583187, Batch Acc: 0.624324, Tokens per Sec:    18572, Lr: 0.000300
2024-05-19 13:35:07,249 - INFO - joeynmt.training - Epoch   7, Step:    27800, Batch Loss:     1.292795, Batch Acc: 0.619157, Tokens per Sec:    16147, Lr: 0.000300
2024-05-19 13:35:10,777 - INFO - joeynmt.training - Epoch   7, Step:    27900, Batch Loss:     1.468551, Batch Acc: 0.625151, Tokens per Sec:    20382, Lr: 0.000300
2024-05-19 13:35:14,375 - INFO - joeynmt.training - Epoch   7, Step:    28000, Batch Loss:     1.254360, Batch Acc: 0.624414, Tokens per Sec:    19445, Lr: 0.000300
2024-05-19 13:35:14,376 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:35:14,376 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:35:25,109 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.71, acc:   0.58, generation: 10.6266[sec], evaluation: 0.0000[sec]
2024-05-19 13:35:25,357 - INFO - joeynmt.helpers - delete bpe_model_4000/26000.ckpt
2024-05-19 13:35:25,370 - INFO - joeynmt.training - Example #0
2024-05-19 13:35:25,371 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:35:25,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:35:25,372 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'ghi@@', 'accio', 'della', 'ghi@@', 'accio', 'della', 'vita', 'della', 'dimen@@', 'sione', 'dell@@', '&@@', 'a@@', 'pos@@', ';', 'ultimo', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'dei', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'ma@@', 'sto', 'per', 'c@@', 'ento', '.', '</s>']
2024-05-19 13:35:25,377 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:35:25,377 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:35:25,377 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che la ghiaccio della ghiaccio della vita della dimensione dell'ultimo tre milioni di anni è stata la dimensione dei 48 stati, ha rimasto per cento.
2024-05-19 13:35:25,377 - INFO - joeynmt.training - Example #1
2024-05-19 13:35:25,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:35:25,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:35:25,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'è', 'mostr@@', 'are', 'la', 'sp@@', 'ess@@', 'enza', 'della', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:35:25,378 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:35:25,378 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:35:25,378 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serie di questo particolare problema perché non è mostrare la spessenza della ghiaccio.
2024-05-19 13:35:25,379 - INFO - joeynmt.training - Example #2
2024-05-19 13:35:25,379 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:35:25,379 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:35:25,379 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'a', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:35:25,379 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:35:25,380 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:35:25,380 - INFO - joeynmt.training - 	Hypothesis: La capa artica è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:35:25,380 - INFO - joeynmt.training - Example #3
2024-05-19 13:35:25,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:35:25,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:35:25,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:35:25,381 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:35:25,381 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:35:25,381 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e contratti in estate.
2024-05-19 13:35:25,381 - INFO - joeynmt.training - Example #4
2024-05-19 13:35:25,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:35:25,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:35:25,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'o', 'sarà', 'un', 'rapi@@', 'do', 'rapi@@', 'da', 'di', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:35:25,382 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:35:25,382 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:35:25,382 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostro sarà un rapido rapida di di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:35:29,075 - INFO - joeynmt.training - Epoch   7, Step:    28100, Batch Loss:     1.476850, Batch Acc: 0.618841, Tokens per Sec:    18816, Lr: 0.000300
2024-05-19 13:35:33,329 - INFO - joeynmt.training - Epoch   7, Step:    28200, Batch Loss:     1.364356, Batch Acc: 0.613725, Tokens per Sec:    16716, Lr: 0.000300
2024-05-19 13:35:37,326 - INFO - joeynmt.training - Epoch   7, Step:    28300, Batch Loss:     1.386460, Batch Acc: 0.619217, Tokens per Sec:    17331, Lr: 0.000300
2024-05-19 13:35:40,957 - INFO - joeynmt.training - Epoch   7, Step:    28400, Batch Loss:     1.343953, Batch Acc: 0.620073, Tokens per Sec:    19799, Lr: 0.000300
2024-05-19 13:35:44,537 - INFO - joeynmt.training - Epoch   7, Step:    28500, Batch Loss:     1.370417, Batch Acc: 0.617707, Tokens per Sec:    19873, Lr: 0.000300
2024-05-19 13:35:44,538 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:35:44,538 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:35:56,212 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.54, ppl:   4.67, acc:   0.58, generation: 11.5693[sec], evaluation: 0.0000[sec]
2024-05-19 13:35:56,213 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:35:56,496 - INFO - joeynmt.helpers - delete bpe_model_4000/28000.ckpt
2024-05-19 13:35:56,507 - INFO - joeynmt.training - Example #0
2024-05-19 13:35:56,507 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:35:56,508 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:35:56,508 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', ',', 'che', 'di@@', 'mostr@@', 'ai', 'che', 'la', 'ghi@@', 'acci@@', 'a', 'della', 'ghi@@', 'acci@@', 'a', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'i', 'bas@@', 'si', 'di', '4@@', '8', 'stati', ',', 'il', '40', '%', ',', 'si', 'è', 's@@', 'ca@@', 'ff@@', 'a', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:35:56,509 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:35:56,509 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:35:56,509 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diapositive, che dimostrai che la ghiaccia della ghiaccia, che per la maggior parte degli ultimi tre milioni di anni sono stati i bassi di 48 stati, il 40%, si è scaffa dal 40%.
2024-05-19 13:35:56,510 - INFO - joeynmt.training - Example #1
2024-05-19 13:35:56,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:35:56,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:35:56,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'è', 'mostr@@', 'are', 'la', 'sp@@', 'int@@', 'a', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:35:56,511 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:35:56,511 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:35:56,511 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serietà di questo particolare problema perché non è mostrare la spinta del ghiaccio.
2024-05-19 13:35:56,512 - INFO - joeynmt.training - Example #2
2024-05-19 13:35:56,512 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:35:56,512 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:35:56,512 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p', 'arti@@', 'fici@@', 'ale', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'un', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:35:56,513 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:35:56,513 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:35:56,513 - INFO - joeynmt.training - 	Hypothesis: La cap artificiale è, in un certo senso, il cuore di un sistema globale.
2024-05-19 13:35:56,514 - INFO - joeynmt.training - Example #3
2024-05-19 13:35:56,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:35:56,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:35:56,514 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'es@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'contr@@', 'atto', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:35:56,515 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:35:56,515 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:35:56,515 - INFO - joeynmt.training - 	Hypothesis: E espande in inverno e si è contratto in estate.
2024-05-19 13:35:56,515 - INFO - joeynmt.training - Example #4
2024-05-19 13:35:56,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:35:56,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:35:56,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'un', 'rapi@@', 'do', 'rapi@@', 'd@@', 'amente', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:35:56,516 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:35:56,517 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:35:56,517 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro un rapido rapidamente di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:36:00,379 - INFO - joeynmt.training - Epoch   7, Step:    28600, Batch Loss:     1.342859, Batch Acc: 0.619567, Tokens per Sec:    17063, Lr: 0.000300
2024-05-19 13:36:04,658 - INFO - joeynmt.training - Epoch   7, Step:    28700, Batch Loss:     1.267060, Batch Acc: 0.618593, Tokens per Sec:    16810, Lr: 0.000300
2024-05-19 13:36:08,301 - INFO - joeynmt.training - Epoch   7, Step:    28800, Batch Loss:     1.468589, Batch Acc: 0.621276, Tokens per Sec:    19925, Lr: 0.000300
2024-05-19 13:36:11,874 - INFO - joeynmt.training - Epoch   7, Step:    28900, Batch Loss:     1.482475, Batch Acc: 0.618617, Tokens per Sec:    19624, Lr: 0.000300
2024-05-19 13:36:16,063 - INFO - joeynmt.training - Epoch   7, Step:    29000, Batch Loss:     1.332871, Batch Acc: 0.618192, Tokens per Sec:    17145, Lr: 0.000300
2024-05-19 13:36:16,065 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:36:16,065 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:36:26,556 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.54, ppl:   4.65, acc:   0.58, generation: 10.3811[sec], evaluation: 0.0000[sec]
2024-05-19 13:36:26,557 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:36:26,816 - INFO - joeynmt.helpers - delete bpe_model_4000/26500.ckpt
2024-05-19 13:36:26,821 - INFO - joeynmt.training - Example #0
2024-05-19 13:36:26,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:36:26,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:36:26,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'ghi@@', 'acci@@', 'a', 'della', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'lev@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:36:26,824 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:36:26,824 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:36:26,825 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che la ghiaccia della maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di 48 stati, ha rilevato dal 40%.
2024-05-19 13:36:26,825 - INFO - joeynmt.training - Example #1
2024-05-19 13:36:26,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:36:26,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:36:26,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'problema', 'in', 'particol@@', 'are', 'la', 'serie', 'di', 'questo', 'problema', 'particol@@', 'are', 'perché', 'non', 'è', 'mostr@@', 'are', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:36:26,827 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:36:26,827 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:36:26,827 - INFO - joeynmt.training - 	Hypothesis: Ma questo problema in particolare la serie di questo problema particolare perché non è mostrare la spessità del ghiaccio.
2024-05-19 13:36:26,827 - INFO - joeynmt.training - Example #2
2024-05-19 13:36:26,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:36:26,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:36:26,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ca@@', 'po', 'di', 'ar@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'ap@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:36:26,828 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:36:26,829 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:36:26,829 - INFO - joeynmt.training - 	Hypothesis: Il capo di artico è, in un certo senso, il cuore di apore globale.
2024-05-19 13:36:26,829 - INFO - joeynmt.training - Example #3
2024-05-19 13:36:26,829 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:36:26,830 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:36:26,830 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'cont@@', 'at@@', 'ti', 'in', 'est@@', 'i@@', 'vo', '.', '</s>']
2024-05-19 13:36:26,830 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:36:26,831 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:36:26,831 - INFO - joeynmt.training - 	Hypothesis: Si espande in inverno e si contatti in estivo.
2024-05-19 13:36:26,831 - INFO - joeynmt.training - Example #4
2024-05-19 13:36:26,831 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:36:26,831 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:36:26,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'acca@@', 'du@@', 'to', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:36:26,832 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:36:26,833 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:36:26,833 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un rapido rapido di quello che è accaduto negli ultimi 25 anni.
2024-05-19 13:36:31,451 - INFO - joeynmt.training - Epoch   7, Step:    29100, Batch Loss:     1.393957, Batch Acc: 0.618292, Tokens per Sec:    14863, Lr: 0.000300
2024-05-19 13:36:35,122 - INFO - joeynmt.training - Epoch   7, Step:    29200, Batch Loss:     1.414023, Batch Acc: 0.616312, Tokens per Sec:    19273, Lr: 0.000300
2024-05-19 13:36:38,712 - INFO - joeynmt.training - Epoch   7, Step:    29300, Batch Loss:     1.250300, Batch Acc: 0.617652, Tokens per Sec:    19532, Lr: 0.000300
2024-05-19 13:36:42,502 - INFO - joeynmt.training - Epoch   7, Step:    29400, Batch Loss:     1.394551, Batch Acc: 0.620538, Tokens per Sec:    19233, Lr: 0.000300
2024-05-19 13:36:46,879 - INFO - joeynmt.training - Epoch   7, Step:    29500, Batch Loss:     1.367197, Batch Acc: 0.618289, Tokens per Sec:    16770, Lr: 0.000300
2024-05-19 13:36:46,880 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:36:46,880 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:36:57,380 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.62, acc:   0.58, generation: 10.2981[sec], evaluation: 0.0000[sec]
2024-05-19 13:36:57,382 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:36:57,716 - INFO - joeynmt.helpers - delete bpe_model_4000/27500.ckpt
2024-05-19 13:36:57,735 - INFO - joeynmt.training - Example #0
2024-05-19 13:36:57,735 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:36:57,736 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:36:57,736 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'ca@@', 'p@@', 'a', 'di', 'più', 'de@@', 'mon@@', 'te', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'dell@@', '&@@', 'a@@', 'pos@@', ';', 'inter@@', 'a', '4@@', '8', 'stati', ',', 'è', 'ri@@', 'ma@@', 'sto', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:36:57,737 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:36:57,737 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:36:57,737 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diapositive così che la capa di più demonte, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni dell'intera 48 stati, è rimasto dal 40%.
2024-05-19 13:36:57,737 - INFO - joeynmt.training - Example #1
2024-05-19 13:36:57,738 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:36:57,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:36:57,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'problema', 'in', 'particol@@', 'are', ',', 'perché', 'non', 'mostr@@', 'ano', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:36:57,739 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:36:57,739 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:36:57,739 - INFO - joeynmt.training - 	Hypothesis: Ma questo problema in particolare, perché non mostrano la serie di questo particolare problema perché non mostra la spessità del ghiaccio.
2024-05-19 13:36:57,739 - INFO - joeynmt.training - Example #2
2024-05-19 13:36:57,739 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:36:57,739 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:36:57,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 'arti@@', 'fici@@', 'ale', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'ap@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:36:57,740 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:36:57,741 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:36:57,741 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio artificiale è, in un senso, il cuore apore del sistema clima globale.
2024-05-19 13:36:57,741 - INFO - joeynmt.training - Example #3
2024-05-19 13:36:57,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:36:57,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:36:57,741 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'es@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'si', 'è', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:36:57,742 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:36:57,742 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:36:57,743 - INFO - joeynmt.training - 	Hypothesis: E 'espande in estate e si è contratti in estate.
2024-05-19 13:36:57,743 - INFO - joeynmt.training - Example #4
2024-05-19 13:36:57,743 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:36:57,743 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:36:57,743 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'mostr@@', 'erò', 'sarà', 'un', 'rapi@@', 'do', 'in', 'avanti', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:36:57,744 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:36:57,744 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:36:57,744 - INFO - joeynmt.training - 	Hypothesis: La prossima slide mostrerò sarà un rapido in avanti di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:37:02,042 - INFO - joeynmt.training - Epoch   7, Step:    29600, Batch Loss:     1.280491, Batch Acc: 0.620364, Tokens per Sec:    15649, Lr: 0.000300
2024-05-19 13:37:05,675 - INFO - joeynmt.training - Epoch   7, Step:    29700, Batch Loss:     1.352606, Batch Acc: 0.616203, Tokens per Sec:    19158, Lr: 0.000300
2024-05-19 13:37:09,267 - INFO - joeynmt.training - Epoch   7, Step:    29800, Batch Loss:     1.462674, Batch Acc: 0.617768, Tokens per Sec:    19992, Lr: 0.000300
2024-05-19 13:37:13,668 - INFO - joeynmt.training - Epoch   7, Step:    29900, Batch Loss:     1.407653, Batch Acc: 0.618122, Tokens per Sec:    16634, Lr: 0.000300
2024-05-19 13:37:17,557 - INFO - joeynmt.training - Epoch   7, Step:    30000, Batch Loss:     1.407298, Batch Acc: 0.612177, Tokens per Sec:    18292, Lr: 0.000300
2024-05-19 13:37:17,557 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:37:17,558 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:37:29,530 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.61, acc:   0.58, generation: 11.8529[sec], evaluation: 0.0000[sec]
2024-05-19 13:37:29,531 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:37:29,789 - INFO - joeynmt.helpers - delete bpe_model_4000/25500.ckpt
2024-05-19 13:37:29,800 - INFO - joeynmt.training - Example #0
2024-05-19 13:37:29,801 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:37:29,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:37:29,802 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', ',', 'che', 'la', 'ca@@', 'ff@@', 'a', 'di', 'più', 'di', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'le', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'se', '4@@', '8', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'bas@@', 'so', 'di', '4@@', '8', 'stati', ',', 'ha', 's@@', 'ca@@', 'str@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:37:29,802 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:37:29,803 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:37:29,803 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diapositive, che la caffa di più di tre milioni di anni sono state le dimensioni di più basse 48 stati le dimensioni di basso di 48 stati, ha scastrato dal 40%.
2024-05-19 13:37:29,803 - INFO - joeynmt.training - Example #1
2024-05-19 13:37:29,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:37:29,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:37:29,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:37:29,804 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:37:29,805 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:37:29,805 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serietà di questo particolare problema perché non ha mostrato la spessità del ghiaccio.
2024-05-19 13:37:29,805 - INFO - joeynmt.training - Example #2
2024-05-19 13:37:29,806 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:37:29,806 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:37:29,806 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'macchina', 'sc@@', 'att@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'cu@@', 'ore', 'del', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:37:29,806 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:37:29,807 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:37:29,807 - INFO - joeynmt.training - 	Hypothesis: La macchina scattica è, in un certo senso, il cuore di cuore del clima globale.
2024-05-19 13:37:29,807 - INFO - joeynmt.training - Example #3
2024-05-19 13:37:29,807 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:37:29,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:37:29,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'ta', 'man@@', 'i', 'in', 'in@@', 'ver@@', 'no', 'e', 'contr@@', 'i', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:37:29,808 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:37:29,808 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:37:29,809 - INFO - joeynmt.training - 	Hypothesis: Sta mani in inverno e contri in estate.
2024-05-19 13:37:29,809 - INFO - joeynmt.training - Example #4
2024-05-19 13:37:29,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:37:29,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:37:29,810 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sci@@', 'vol@@', 'o', 'vi', 'mostr@@', 'o', 'che', 'sarà', 'rapi@@', 'da', 'più', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:37:29,810 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:37:29,810 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:37:29,811 - INFO - joeynmt.training - 	Hypothesis: La prossima scivolo vi mostro che sarà rapida più veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:37:33,493 - INFO - joeynmt.training - Epoch   7, Step:    30100, Batch Loss:     1.437455, Batch Acc: 0.615130, Tokens per Sec:    18088, Lr: 0.000300
2024-05-19 13:37:37,099 - INFO - joeynmt.training - Epoch   7, Step:    30200, Batch Loss:     1.360745, Batch Acc: 0.609837, Tokens per Sec:    19644, Lr: 0.000300
2024-05-19 13:37:41,384 - INFO - joeynmt.training - Epoch   7, Step:    30300, Batch Loss:     1.431873, Batch Acc: 0.624087, Tokens per Sec:    17005, Lr: 0.000300
2024-05-19 13:37:45,377 - INFO - joeynmt.training - Epoch   7, Step:    30400, Batch Loss:     1.359836, Batch Acc: 0.625739, Tokens per Sec:    18566, Lr: 0.000300
2024-05-19 13:37:46,301 - INFO - joeynmt.training - Epoch   7: total training loss 5886.99
2024-05-19 13:37:46,301 - INFO - joeynmt.training - EPOCH 8
2024-05-19 13:37:49,092 - INFO - joeynmt.training - Epoch   8, Step:    30500, Batch Loss:     1.176186, Batch Acc: 0.639867, Tokens per Sec:    19308, Lr: 0.000300
2024-05-19 13:37:49,093 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:37:49,093 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:38:00,192 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.61, acc:   0.58, generation: 10.9877[sec], evaluation: 0.0000[sec]
2024-05-19 13:38:00,442 - INFO - joeynmt.helpers - delete bpe_model_4000/27000.ckpt
2024-05-19 13:38:00,458 - INFO - joeynmt.training - Example #0
2024-05-19 13:38:00,459 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:38:00,459 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:38:00,459 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'che', 'la', 'ca@@', 'po', 'della', 'br@@', 'accio', 'ar@@', 'c@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'dei', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:38:00,460 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:38:00,460 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:38:00,460 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diapositive così che dimostrò che la capo della braccio arcica, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione dei 48 stati, si è rimasta dal 40%.
2024-05-19 13:38:00,461 - INFO - joeynmt.training - Example #1
2024-05-19 13:38:00,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:38:00,461 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:38:00,461 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'com@@', 'preso', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'sp@@', 'int@@', 'a', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:38:00,462 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:38:00,462 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:38:00,463 - INFO - joeynmt.training - 	Hypothesis: Ma questo compreso la serie di questo particolare problema perché non ha mostrato la spinta del ghiaccio.
2024-05-19 13:38:00,463 - INFO - joeynmt.training - Example #2
2024-05-19 13:38:00,463 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:38:00,463 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:38:00,464 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Il', 'ghi@@', 'accio', 'ar@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:38:00,464 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:38:00,465 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:38:00,465 - INFO - joeynmt.training - 	Hypothesis: Il ghiaccio artico è, in un certo senso, il cuore del sistema globale.
2024-05-19 13:38:00,465 - INFO - joeynmt.training - Example #3
2024-05-19 13:38:00,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:38:00,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:38:00,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'cont@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:38:00,466 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:38:00,467 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:38:00,467 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e contatti in estate.
2024-05-19 13:38:00,467 - INFO - joeynmt.training - Example #4
2024-05-19 13:38:00,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:38:00,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:38:00,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'vi', 'vi', 'vi', 'mostr@@', 'erò', 'una', 'rapi@@', 'da', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:38:00,468 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:38:00,468 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:38:00,469 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva vi vi vi mostrerò una rapida veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:38:04,121 - INFO - joeynmt.training - Epoch   8, Step:    30600, Batch Loss:     1.187603, Batch Acc: 0.638368, Tokens per Sec:    18293, Lr: 0.000300
2024-05-19 13:38:08,094 - INFO - joeynmt.training - Epoch   8, Step:    30700, Batch Loss:     1.251131, Batch Acc: 0.638839, Tokens per Sec:    18264, Lr: 0.000300
2024-05-19 13:38:12,512 - INFO - joeynmt.training - Epoch   8, Step:    30800, Batch Loss:     1.387073, Batch Acc: 0.637768, Tokens per Sec:    16849, Lr: 0.000300
2024-05-19 13:38:16,172 - INFO - joeynmt.training - Epoch   8, Step:    30900, Batch Loss:     1.436933, Batch Acc: 0.640302, Tokens per Sec:    19663, Lr: 0.000300
2024-05-19 13:38:19,818 - INFO - joeynmt.training - Epoch   8, Step:    31000, Batch Loss:     1.228359, Batch Acc: 0.641010, Tokens per Sec:    19694, Lr: 0.000300
2024-05-19 13:38:19,819 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:38:19,819 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:38:31,100 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.62, acc:   0.58, generation: 11.1731[sec], evaluation: 0.0000[sec]
2024-05-19 13:38:31,342 - INFO - joeynmt.helpers - delete bpe_model_4000/28500.ckpt
2024-05-19 13:38:31,353 - INFO - joeynmt.training - Example #0
2024-05-19 13:38:31,354 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:38:31,354 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:38:31,354 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'ca@@', 'p@@', 'elle', 'ar@@', 't@@', 'ica', 'della', 'c@@', 'att@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'delle', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'chi@@', 'u@@', 'de', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:38:31,355 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:38:31,356 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:38:31,356 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che la capelle artica della cattica, che per la maggior parte degli ultimi tre milioni di anni sono stati le dimensioni delle 48 stati, si è richiude dal 40%.
2024-05-19 13:38:31,356 - INFO - joeynmt.training - Example #1
2024-05-19 13:38:31,356 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:38:31,357 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:38:31,357 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'serie', 'di', 'questo', 'problema', 'particol@@', 'are', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'il', 'ghi@@', 'accio', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:38:31,358 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:38:31,358 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:38:31,358 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serie di questo problema particolare perché non ha mostrato il ghiaccio del ghiaccio.
2024-05-19 13:38:31,358 - INFO - joeynmt.training - Example #2
2024-05-19 13:38:31,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:38:31,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:38:31,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ghi@@', 'accio', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'un', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:38:31,360 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:38:31,360 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:38:31,360 - INFO - joeynmt.training - 	Hypothesis: La ghiaccio artica è, in un certo senso, il cuore di un sistema globale.
2024-05-19 13:38:31,360 - INFO - joeynmt.training - Example #3
2024-05-19 13:38:31,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:38:31,361 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:38:31,361 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'in@@', 'ver@@', 'no', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:38:31,361 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:38:31,362 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:38:31,362 - INFO - joeynmt.training - 	Hypothesis: Spande in estate inverno e contratti in estate.
2024-05-19 13:38:31,362 - INFO - joeynmt.training - Example #4
2024-05-19 13:38:31,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:38:31,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:38:31,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'rapi@@', 'da', 'più', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:38:31,363 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:38:31,364 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:38:31,364 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro rapida più veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:38:35,067 - INFO - joeynmt.training - Epoch   8, Step:    31100, Batch Loss:     1.111243, Batch Acc: 0.636154, Tokens per Sec:    18408, Lr: 0.000300
2024-05-19 13:38:39,657 - INFO - joeynmt.training - Epoch   8, Step:    31200, Batch Loss:     1.153304, Batch Acc: 0.640588, Tokens per Sec:    15841, Lr: 0.000300
2024-05-19 13:38:43,284 - INFO - joeynmt.training - Epoch   8, Step:    31300, Batch Loss:     1.309002, Batch Acc: 0.634271, Tokens per Sec:    19308, Lr: 0.000300
2024-05-19 13:38:46,916 - INFO - joeynmt.training - Epoch   8, Step:    31400, Batch Loss:     1.165679, Batch Acc: 0.640699, Tokens per Sec:    19727, Lr: 0.000300
2024-05-19 13:38:50,858 - INFO - joeynmt.training - Epoch   8, Step:    31500, Batch Loss:     1.365952, Batch Acc: 0.634187, Tokens per Sec:    18331, Lr: 0.000300
2024-05-19 13:38:50,859 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:38:50,859 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:39:01,181 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.54, ppl:   4.65, acc:   0.58, generation: 10.2195[sec], evaluation: 0.0000[sec]
2024-05-19 13:39:01,186 - INFO - joeynmt.training - Example #0
2024-05-19 13:39:01,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:39:01,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:39:01,188 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'ca@@', 'p@@', 'elle', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'dell@@', '&@@', 'a@@', 'pos@@', ';', 'inter@@', 'a', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'so', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:39:01,189 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:39:01,189 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:39:01,189 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive che la capelle artica, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione dell'intera 48 stati, ha riso dal 40%.
2024-05-19 13:39:01,189 - INFO - joeynmt.training - Example #1
2024-05-19 13:39:01,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:39:01,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:39:01,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'com@@', 'preso', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'ick@@', 's@@', '&@@', 'a@@', 'pos@@', ';', 'è', 'la', 'sp@@', 'ess@@', 'enza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:39:01,191 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:39:01,191 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:39:01,191 - INFO - joeynmt.training - 	Hypothesis: Ma questo compreso la serie di questo particolare problema perché non mostrano l'icks'è la spessenza del ghiaccio.
2024-05-19 13:39:01,192 - INFO - joeynmt.training - Example #2
2024-05-19 13:39:01,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:39:01,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:39:01,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p', 'arti@@', 'fici@@', 'ale', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:39:01,193 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:39:01,193 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:39:01,193 - INFO - joeynmt.training - 	Hypothesis: La cap artificiale è, in un senso, il cuore di cuore del sistema globale.
2024-05-19 13:39:01,194 - INFO - joeynmt.training - Example #3
2024-05-19 13:39:01,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:39:01,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:39:01,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'cont@@', 'ano', 'in', 'est@@', 'i@@', 'era', '.', '</s>']
2024-05-19 13:39:01,195 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:39:01,195 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:39:01,195 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e si contano in estiera.
2024-05-19 13:39:01,195 - INFO - joeynmt.training - Example #4
2024-05-19 13:39:01,196 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:39:01,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:39:01,196 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'mostr@@', 'erò', 'sarà', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:39:01,197 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:39:01,197 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:39:01,197 - INFO - joeynmt.training - 	Hypothesis: La prossima slide mostrerò sarà rapido di quello che è successo negli ultimi 25 anni.
2024-05-19 13:39:05,013 - INFO - joeynmt.training - Epoch   8, Step:    31600, Batch Loss:     1.542203, Batch Acc: 0.629603, Tokens per Sec:    18603, Lr: 0.000300
2024-05-19 13:39:09,295 - INFO - joeynmt.training - Epoch   8, Step:    31700, Batch Loss:     1.297906, Batch Acc: 0.630648, Tokens per Sec:    17396, Lr: 0.000300
2024-05-19 13:39:12,918 - INFO - joeynmt.training - Epoch   8, Step:    31800, Batch Loss:     1.219286, Batch Acc: 0.639551, Tokens per Sec:    19879, Lr: 0.000300
2024-05-19 13:39:16,465 - INFO - joeynmt.training - Epoch   8, Step:    31900, Batch Loss:     1.267979, Batch Acc: 0.629631, Tokens per Sec:    19358, Lr: 0.000300
2024-05-19 13:39:20,614 - INFO - joeynmt.training - Epoch   8, Step:    32000, Batch Loss:     1.292961, Batch Acc: 0.631322, Tokens per Sec:    17598, Lr: 0.000300
2024-05-19 13:39:20,614 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:39:20,615 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:39:30,532 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.62, acc:   0.58, generation: 9.8007[sec], evaluation: 0.0000[sec]
2024-05-19 13:39:30,786 - INFO - joeynmt.helpers - delete bpe_model_4000/29000.ckpt
2024-05-19 13:39:30,797 - INFO - joeynmt.training - Example #0
2024-05-19 13:39:30,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:39:30,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:39:30,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'di@@', 'mostr@@', 'ò', 'che', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', 'del', '40', '%', ',', 'è', 'stata', 'la', 'dimen@@', 'sione', 'del', '40', '%', 'di', 'un', 'ri@@', 'b@@', 'ass@@', 'a', '.', '</s>']
2024-05-19 13:39:30,799 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:39:30,800 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:39:30,800 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive che dimostrò che la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di più basso del 40%, è stata la dimensione del 40% di un ribassa.
2024-05-19 13:39:30,800 - INFO - joeynmt.training - Example #1
2024-05-19 13:39:30,800 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:39:30,801 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:39:30,801 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'problema', ',', 'perché', 'non', 'è', 'mostr@@', 'are', 'la', 'sp@@', 'int@@', 'a', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:39:30,801 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:39:30,802 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:39:30,802 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo problema, perché non è mostrare la spinta del ghiaccio.
2024-05-19 13:39:30,802 - INFO - joeynmt.training - Example #2
2024-05-19 13:39:30,802 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:39:30,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:39:30,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'a', 'ar@@', 'c@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'cu@@', 'ore', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:39:30,803 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:39:30,804 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:39:30,804 - INFO - joeynmt.training - 	Hypothesis: La capa arcico è, in un certo senso, il cuore di cuore globale.
2024-05-19 13:39:30,804 - INFO - joeynmt.training - Example #3
2024-05-19 13:39:30,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:39:30,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:39:30,805 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'si', 'è', 'est@@', 'i@@', 'va', 'in', 'est@@', 'i@@', 'va', '.', '</s>']
2024-05-19 13:39:30,805 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:39:30,805 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:39:30,806 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e si si è estiva in estiva.
2024-05-19 13:39:30,806 - INFO - joeynmt.training - Example #4
2024-05-19 13:39:30,807 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:39:30,807 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:39:30,807 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'i', 'una', 'rapi@@', 'da', 'avanti', 'in', 'avanti', ',', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:39:30,808 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:39:30,809 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:39:30,809 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostri una rapida avanti in avanti, di quello che è successo negli ultimi 25 anni.
2024-05-19 13:39:35,074 - INFO - joeynmt.training - Epoch   8, Step:    32100, Batch Loss:     1.434882, Batch Acc: 0.632957, Tokens per Sec:    15725, Lr: 0.000300
2024-05-19 13:39:39,211 - INFO - joeynmt.training - Epoch   8, Step:    32200, Batch Loss:     1.206403, Batch Acc: 0.631485, Tokens per Sec:    17692, Lr: 0.000300
2024-05-19 13:39:42,799 - INFO - joeynmt.training - Epoch   8, Step:    32300, Batch Loss:     1.281055, Batch Acc: 0.635666, Tokens per Sec:    19887, Lr: 0.000300
2024-05-19 13:39:46,357 - INFO - joeynmt.training - Epoch   8, Step:    32400, Batch Loss:     1.342255, Batch Acc: 0.625656, Tokens per Sec:    19664, Lr: 0.000300
2024-05-19 13:39:50,998 - INFO - joeynmt.training - Epoch   8, Step:    32500, Batch Loss:     1.162898, Batch Acc: 0.627930, Tokens per Sec:    15474, Lr: 0.000300
2024-05-19 13:39:50,998 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:39:50,999 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:40:00,851 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.54, ppl:   4.64, acc:   0.58, generation: 9.7476[sec], evaluation: 0.0000[sec]
2024-05-19 13:40:00,856 - INFO - joeynmt.training - Example #0
2024-05-19 13:40:00,856 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:40:00,857 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:40:00,857 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'ca@@', 'po', 'di', 'sc@@', 'ambi@@', 'o', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'le', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'st@@', 'i', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:40:00,858 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:40:00,858 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:40:00,859 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che la capo di scambio, che per la maggior parte degli ultimi tre milioni di anni sono state le dimensioni di 48 stati, sono stati le dimensioni di 48 stati, si è rimasti dal 40%.
2024-05-19 13:40:00,859 - INFO - joeynmt.training - Example #1
2024-05-19 13:40:00,859 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:40:00,859 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:40:00,860 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questa', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:40:00,860 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:40:00,861 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:40:00,861 - INFO - joeynmt.training - 	Hypothesis: Ma questa ha capito la serietà di questo particolare problema perché non mostra la spessità del ghiaccio.
2024-05-19 13:40:00,861 - INFO - joeynmt.training - Example #2
2024-05-19 13:40:00,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:40:00,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:40:00,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 't@@', 't@@', 't@@', 'ica', 'ca@@', 'p', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'ap@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:40:00,862 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:40:00,863 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:40:00,863 - INFO - joeynmt.training - 	Hypothesis: La tttica cap è, in un certo senso, il cuore apore del sistema clima globale.
2024-05-19 13:40:00,863 - INFO - joeynmt.training - Example #3
2024-05-19 13:40:00,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:40:00,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:40:00,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'cont@@', 'est@@', 'ate', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:40:00,864 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:40:00,865 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:40:00,865 - INFO - joeynmt.training - 	Hypothesis: Si espande in contestate e contratti in estate.
2024-05-19 13:40:00,865 - INFO - joeynmt.training - Example #4
2024-05-19 13:40:00,865 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:40:00,865 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:40:00,866 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'mostr@@', 'arvi', 'che', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:40:00,866 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:40:00,867 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:40:00,867 - INFO - joeynmt.training - 	Hypothesis: La prossima slide mostrarvi che vi mostrerò un rapido rapido di quello che è successo negli ultimi 25 anni.
2024-05-19 13:40:05,489 - INFO - joeynmt.training - Epoch   8, Step:    32600, Batch Loss:     1.464058, Batch Acc: 0.632977, Tokens per Sec:    15648, Lr: 0.000300
2024-05-19 13:40:09,036 - INFO - joeynmt.training - Epoch   8, Step:    32700, Batch Loss:     1.263196, Batch Acc: 0.630297, Tokens per Sec:    19980, Lr: 0.000300
2024-05-19 13:40:12,633 - INFO - joeynmt.training - Epoch   8, Step:    32800, Batch Loss:     1.393952, Batch Acc: 0.631782, Tokens per Sec:    19839, Lr: 0.000300
2024-05-19 13:40:16,715 - INFO - joeynmt.training - Epoch   8, Step:    32900, Batch Loss:     1.266129, Batch Acc: 0.627327, Tokens per Sec:    17890, Lr: 0.000300
2024-05-19 13:40:20,967 - INFO - joeynmt.training - Epoch   8, Step:    33000, Batch Loss:     1.333801, Batch Acc: 0.634089, Tokens per Sec:    16901, Lr: 0.000300
2024-05-19 13:40:20,967 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:40:20,968 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:40:31,843 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.61, acc:   0.58, generation: 10.6760[sec], evaluation: 0.0000[sec]
2024-05-19 13:40:32,168 - INFO - joeynmt.helpers - delete bpe_model_4000/32000.ckpt
2024-05-19 13:40:32,179 - INFO - joeynmt.helpers - delete /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/32000.ckpt
2024-05-19 13:40:32,179 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/32000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/32000.ckpt')
2024-05-19 13:40:32,183 - INFO - joeynmt.training - Example #0
2024-05-19 13:40:32,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:40:32,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:40:32,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'la', 'ca@@', 'dut@@', 'a', 'ar@@', 'c@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'dot@@', 'ta', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:40:32,185 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:40:32,185 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:40:32,186 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che dimostrò la caduta arcica, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione di 48 stati, si è ridotta dal 40%.
2024-05-19 13:40:32,186 - INFO - joeynmt.training - Example #1
2024-05-19 13:40:32,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:40:32,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:40:32,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'problema', ',', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:40:32,187 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:40:32,188 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:40:32,188 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo problema, perché non mostra la spessità del ghiaccio.
2024-05-19 13:40:32,188 - INFO - joeynmt.training - Example #2
2024-05-19 13:40:32,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:40:32,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:40:32,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'po', 'della', 'ghi@@', 'accio', 'ar@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'ap@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:40:32,190 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:40:32,190 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:40:32,190 - INFO - joeynmt.training - 	Hypothesis: La capo della ghiaccio artico è, in un certo senso, il cuore apore del sistema globale.
2024-05-19 13:40:32,190 - INFO - joeynmt.training - Example #3
2024-05-19 13:40:32,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:40:32,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:40:32,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'est@@', 'i@@', 'va', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:40:32,192 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:40:32,192 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:40:32,193 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e si è estiva in estate.
2024-05-19 13:40:32,193 - INFO - joeynmt.training - Example #4
2024-05-19 13:40:32,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:40:32,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:40:32,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:40:32,194 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:40:32,195 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:40:32,195 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un rapido rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:40:36,219 - INFO - joeynmt.training - Epoch   8, Step:    33100, Batch Loss:     1.280590, Batch Acc: 0.630742, Tokens per Sec:    16306, Lr: 0.000300
2024-05-19 13:40:39,825 - INFO - joeynmt.training - Epoch   8, Step:    33200, Batch Loss:     1.170523, Batch Acc: 0.626816, Tokens per Sec:    19725, Lr: 0.000300
2024-05-19 13:40:43,377 - INFO - joeynmt.training - Epoch   8, Step:    33300, Batch Loss:     1.220306, Batch Acc: 0.631470, Tokens per Sec:    19316, Lr: 0.000300
2024-05-19 13:40:47,859 - INFO - joeynmt.training - Epoch   8, Step:    33400, Batch Loss:     1.220069, Batch Acc: 0.626306, Tokens per Sec:    15337, Lr: 0.000300
2024-05-19 13:40:51,508 - INFO - joeynmt.training - Epoch   8, Step:    33500, Batch Loss:     1.309115, Batch Acc: 0.623545, Tokens per Sec:    19495, Lr: 0.000300
2024-05-19 13:40:51,508 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:40:51,509 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:41:01,838 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.57, acc:   0.59, generation: 10.1585[sec], evaluation: 0.0000[sec]
2024-05-19 13:41:01,839 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:41:02,325 - INFO - joeynmt.helpers - delete bpe_model_4000/31000.ckpt
2024-05-19 13:41:02,336 - INFO - joeynmt.training - Example #0
2024-05-19 13:41:02,337 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:41:02,337 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:41:02,337 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'la', 'ca@@', 'po', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'le', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'lev@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:41:02,338 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:41:02,339 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:41:02,339 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che dimostrò la capo, che per la maggior parte degli ultimi tre milioni di anni sono state le dimensioni di più basso 48 stati, ha rilevato dal 40%.
2024-05-19 13:41:02,339 - INFO - joeynmt.training - Example #1
2024-05-19 13:41:02,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:41:02,340 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:41:02,340 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 't@@', 'el@@', 'ev@@', 'ata', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:41:02,340 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:41:02,341 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:41:02,341 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serietà di questo particolare problema perché non ha mostrato la televata del ghiaccio.
2024-05-19 13:41:02,341 - INFO - joeynmt.training - Example #2
2024-05-19 13:41:02,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:41:02,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:41:02,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'a', 'di', 'ghi@@', 'accio', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:41:02,342 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:41:02,342 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:41:02,343 - INFO - joeynmt.training - 	Hypothesis: La capa di ghiaccio è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:41:02,343 - INFO - joeynmt.training - Example #3
2024-05-19 13:41:02,343 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:41:02,343 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:41:02,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', '&@@', 'a@@', 'pos@@', ';', 'es@@', 'p@@', 'and@@', 'e', 'si', 'cont@@', 'ra@@', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:41:02,344 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:41:02,344 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:41:02,345 - INFO - joeynmt.training - 	Hypothesis: E 'espande si contrad'estate.
2024-05-19 13:41:02,345 - INFO - joeynmt.training - Example #4
2024-05-19 13:41:02,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:41:02,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:41:02,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'o', 'che', 'vi', 'sarà', 'un', 'rapi@@', 'do', 'avanti', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:41:02,346 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:41:02,346 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:41:02,346 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostro che vi sarà un rapido avanti di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:41:05,984 - INFO - joeynmt.training - Epoch   8, Step:    33600, Batch Loss:     1.421858, Batch Acc: 0.631522, Tokens per Sec:    17259, Lr: 0.000300
2024-05-19 13:41:09,598 - INFO - joeynmt.training - Epoch   8, Step:    33700, Batch Loss:     1.306631, Batch Acc: 0.628087, Tokens per Sec:    19490, Lr: 0.000300
2024-05-19 13:41:13,522 - INFO - joeynmt.training - Epoch   8, Step:    33800, Batch Loss:     1.491759, Batch Acc: 0.625394, Tokens per Sec:    17627, Lr: 0.000300
2024-05-19 13:41:17,658 - INFO - joeynmt.training - Epoch   8, Step:    33900, Batch Loss:     1.368383, Batch Acc: 0.626824, Tokens per Sec:    17373, Lr: 0.000300
2024-05-19 13:41:21,284 - INFO - joeynmt.training - Epoch   8, Step:    34000, Batch Loss:     1.226946, Batch Acc: 0.632220, Tokens per Sec:    19894, Lr: 0.000300
2024-05-19 13:41:21,285 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:41:21,285 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:41:32,906 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.56, acc:   0.59, generation: 11.5169[sec], evaluation: 0.0000[sec]
2024-05-19 13:41:32,907 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:41:33,163 - INFO - joeynmt.helpers - delete bpe_model_4000/29500.ckpt
2024-05-19 13:41:33,174 - INFO - joeynmt.training - Example #0
2024-05-19 13:41:33,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:41:33,175 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:41:33,176 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mostr@@', 'ano', 'che', 'la', 'maggior', 'parte', 'delle', 'ul@@', 'time', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'il', '40', '%', 'di', 'più', 'bas@@', 'so', 'del', '40', '%', '.', '</s>']
2024-05-19 13:41:33,176 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:41:33,177 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:41:33,177 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che dimostrano che la maggior parte delle ultime tre milioni di anni è stata la dimensione delle dimensioni di 48 stati, il 40% di più basso del 40%.
2024-05-19 13:41:33,177 - INFO - joeynmt.training - Example #1
2024-05-19 13:41:33,178 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:41:33,178 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:41:33,178 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'si', 'mostr@@', 'ano', 'la', 'z@@', 'ona', 'dell@@', '&@@', 'a@@', 'pos@@', ';', 'e@@', 'po@@', 'ca', '.', '</s>']
2024-05-19 13:41:33,178 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:41:33,179 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:41:33,179 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serie di questo particolare problema perché non si mostrano la zona dell'epoca.
2024-05-19 13:41:33,179 - INFO - joeynmt.training - Example #2
2024-05-19 13:41:33,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:41:33,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:41:33,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'elle', 'arti@@', 'fici@@', 'ale', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'ap@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:41:33,181 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:41:33,181 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:41:33,181 - INFO - joeynmt.training - 	Hypothesis: La capelle artificiale è, in un certo senso, il cuore apore del sistema globale.
2024-05-19 13:41:33,181 - INFO - joeynmt.training - Example #3
2024-05-19 13:41:33,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:41:33,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:41:33,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'ono', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:41:33,183 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:41:33,183 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:41:33,183 - INFO - joeynmt.training - 	Hypothesis: Spandono in inverno e si è estate.
2024-05-19 13:41:33,183 - INFO - joeynmt.training - Example #4
2024-05-19 13:41:33,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:41:33,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:41:33,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:41:33,185 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:41:33,185 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:41:33,185 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un rapido rapido di quello che è successo negli ultimi 25 anni.
2024-05-19 13:41:36,795 - INFO - joeynmt.training - Epoch   8, Step:    34100, Batch Loss:     1.436807, Batch Acc: 0.629715, Tokens per Sec:    18807, Lr: 0.000300
2024-05-19 13:41:40,438 - INFO - joeynmt.training - Epoch   8, Step:    34200, Batch Loss:     1.343385, Batch Acc: 0.628271, Tokens per Sec:    19607, Lr: 0.000300
2024-05-19 13:41:44,964 - INFO - joeynmt.training - Epoch   8, Step:    34300, Batch Loss:     1.180026, Batch Acc: 0.629959, Tokens per Sec:    15587, Lr: 0.000300
2024-05-19 13:41:48,541 - INFO - joeynmt.training - Epoch   8, Step:    34400, Batch Loss:     1.380918, Batch Acc: 0.626355, Tokens per Sec:    19883, Lr: 0.000300
2024-05-19 13:41:52,156 - INFO - joeynmt.training - Epoch   8, Step:    34500, Batch Loss:     1.221047, Batch Acc: 0.626233, Tokens per Sec:    19467, Lr: 0.000300
2024-05-19 13:41:52,156 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:41:52,157 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:42:02,802 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.55, acc:   0.58, generation: 10.5098[sec], evaluation: 0.0000[sec]
2024-05-19 13:42:02,803 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:42:03,064 - INFO - joeynmt.helpers - delete bpe_model_4000/33000.ckpt
2024-05-19 13:42:03,068 - INFO - joeynmt.training - Example #0
2024-05-19 13:42:03,069 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:42:03,069 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:42:03,070 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'la', 'ca@@', 'ff@@', 'a', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'ha', 's@@', 'ca@@', 'ff@@', 'o', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:42:03,070 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:42:03,071 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:42:03,071 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diapositive così che dimostrò la caffa, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di più basso 48 stati, ha scaffo dal 40%.
2024-05-19 13:42:03,071 - INFO - joeynmt.training - Example #1
2024-05-19 13:42:03,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:42:03,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:42:03,072 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'com@@', 'pre@@', 'se', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'int@@', 'a', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:42:03,072 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:42:03,073 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:42:03,073 - INFO - joeynmt.training - 	Hypothesis: Ma questo comprese la serie di questo particolare problema perché non mostra la spinta del ghiaccio.
2024-05-19 13:42:03,073 - INFO - joeynmt.training - Example #2
2024-05-19 13:42:03,073 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:42:03,074 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:42:03,074 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'macchina', 'arti@@', 'fici@@', 'ale', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'ap@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:42:03,074 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:42:03,075 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:42:03,075 - INFO - joeynmt.training - 	Hypothesis: La macchina artificiale, in un certo senso, il cuore apore del sistema clima globale.
2024-05-19 13:42:03,075 - INFO - joeynmt.training - Example #3
2024-05-19 13:42:03,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:42:03,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:42:03,076 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['E', 'si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'si', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:42:03,076 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:42:03,076 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:42:03,077 - INFO - joeynmt.training - 	Hypothesis: E si espande in estate e si contratti in estate.
2024-05-19 13:42:03,077 - INFO - joeynmt.training - Example #4
2024-05-19 13:42:03,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:42:03,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:42:03,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:42:03,078 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:42:03,078 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:42:03,078 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un rapido rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:42:06,644 - INFO - joeynmt.training - Epoch   8, Step:    34600, Batch Loss:     1.330893, Batch Acc: 0.620106, Tokens per Sec:    17860, Lr: 0.000300
2024-05-19 13:42:10,749 - INFO - joeynmt.training - Epoch   8, Step:    34700, Batch Loss:     1.448308, Batch Acc: 0.628209, Tokens per Sec:    17537, Lr: 0.000300
2024-05-19 13:42:14,155 - INFO - joeynmt.training - Epoch   8: total training loss 5731.67
2024-05-19 13:42:14,156 - INFO - joeynmt.training - EPOCH 9
2024-05-19 13:42:14,819 - INFO - joeynmt.training - Epoch   9, Step:    34800, Batch Loss:     1.218822, Batch Acc: 0.658618, Tokens per Sec:    19518, Lr: 0.000300
2024-05-19 13:42:18,448 - INFO - joeynmt.training - Epoch   9, Step:    34900, Batch Loss:     1.201779, Batch Acc: 0.652408, Tokens per Sec:    19343, Lr: 0.000300
2024-05-19 13:42:22,112 - INFO - joeynmt.training - Epoch   9, Step:    35000, Batch Loss:     1.284812, Batch Acc: 0.654028, Tokens per Sec:    19444, Lr: 0.000300
2024-05-19 13:42:22,113 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:42:22,113 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:42:34,065 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.57, acc:   0.59, generation: 11.8387[sec], evaluation: 0.0000[sec]
2024-05-19 13:42:34,302 - INFO - joeynmt.helpers - delete bpe_model_4000/30500.ckpt
2024-05-19 13:42:34,312 - INFO - joeynmt.training - Example #0
2024-05-19 13:42:34,313 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:42:34,314 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:42:34,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'la', 'ca@@', 'ff@@', 'a', 'di', 'f@@', 'ase', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'ha', 'di@@', 'mostr@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:42:34,315 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:42:34,315 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:42:34,315 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che la caffa di fase, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di basso 48 stati, ha dimostrato dal 40%.
2024-05-19 13:42:34,316 - INFO - joeynmt.training - Example #1
2024-05-19 13:42:34,316 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:42:34,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:42:34,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'com@@', 'preso', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'è', 'mostr@@', 'are', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:42:34,317 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:42:34,318 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:42:34,318 - INFO - joeynmt.training - 	Hypothesis: Ma questo compreso la serie di questo particolare problema perché non è mostrare la spessità del ghiaccio.
2024-05-19 13:42:34,318 - INFO - joeynmt.training - Example #2
2024-05-19 13:42:34,318 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:42:34,318 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:42:34,319 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'ot@@', 'a', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:42:34,319 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:42:34,319 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:42:34,320 - INFO - joeynmt.training - 	Hypothesis: La caota artica è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:42:34,320 - INFO - joeynmt.training - Example #3
2024-05-19 13:42:34,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:42:34,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:42:34,320 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'ono', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:42:34,321 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:42:34,321 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:42:34,321 - INFO - joeynmt.training - 	Hypothesis: Si espandono in inverno e si è contratti in estate.
2024-05-19 13:42:34,322 - INFO - joeynmt.training - Example #4
2024-05-19 13:42:34,322 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:42:34,322 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:42:34,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'o', 'che', 'sarà', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:42:34,323 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:42:34,324 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:42:34,324 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostro che sarà un rapido rapido di quello che è successo negli ultimi 25 anni.
2024-05-19 13:42:38,267 - INFO - joeynmt.training - Epoch   9, Step:    35100, Batch Loss:     1.320282, Batch Acc: 0.652160, Tokens per Sec:    16883, Lr: 0.000300
2024-05-19 13:42:42,679 - INFO - joeynmt.training - Epoch   9, Step:    35200, Batch Loss:     1.148444, Batch Acc: 0.650859, Tokens per Sec:    15959, Lr: 0.000300
2024-05-19 13:42:46,230 - INFO - joeynmt.training - Epoch   9, Step:    35300, Batch Loss:     1.178474, Batch Acc: 0.648635, Tokens per Sec:    20699, Lr: 0.000300
2024-05-19 13:42:49,930 - INFO - joeynmt.training - Epoch   9, Step:    35400, Batch Loss:     1.189583, Batch Acc: 0.646497, Tokens per Sec:    18928, Lr: 0.000300
2024-05-19 13:42:54,203 - INFO - joeynmt.training - Epoch   9, Step:    35500, Batch Loss:     1.271404, Batch Acc: 0.643720, Tokens per Sec:    16995, Lr: 0.000300
2024-05-19 13:42:54,204 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:42:54,204 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:43:04,695 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.61, acc:   0.59, generation: 10.3834[sec], evaluation: 0.0000[sec]
2024-05-19 13:43:04,953 - INFO - joeynmt.helpers - delete bpe_model_4000/30000.ckpt
2024-05-19 13:43:04,963 - INFO - joeynmt.training - Example #0
2024-05-19 13:43:04,964 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:43:04,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:43:04,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'ca@@', 'ff@@', 'a', 'del', 'ghi@@', 'accio', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'stati', ',', 'sono', 'state', 'le', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'ha', 's@@', 'ca@@', 'di@@', 'mento', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:43:04,966 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:43:04,966 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:43:04,966 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che la caffa del ghiaccio, che per la maggior parte degli ultimi tre milioni di anni sono state le dimensioni dei 48 stati, sono state le dimensioni di più basso 48 stati, ha scadimento dal 40%.
2024-05-19 13:43:04,967 - INFO - joeynmt.training - Example #1
2024-05-19 13:43:04,967 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:43:04,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:43:04,967 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'è', 'la', 'sp@@', 'av@@', 'ent@@', 'a', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:43:04,968 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:43:04,968 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:43:04,968 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo particolare problema perché non è la spaventa del ghiaccio.
2024-05-19 13:43:04,969 - INFO - joeynmt.training - Example #2
2024-05-19 13:43:04,969 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:43:04,969 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:43:04,969 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'macchina', 'di', 'un', 'ag@@', 'g@@', 'esso', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:43:04,970 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:43:04,970 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:43:04,970 - INFO - joeynmt.training - 	Hypothesis: La macchina di un aggesso è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:43:04,970 - INFO - joeynmt.training - Example #3
2024-05-19 13:43:04,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:43:04,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:43:04,971 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'ono', 'in', 'est@@', 'ate', 'e', 'contr@@', 'i', 'in', 'est@@', 'i@@', 'ere', '.', '</s>']
2024-05-19 13:43:04,972 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:43:04,972 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:43:04,972 - INFO - joeynmt.training - 	Hypothesis: Spandono in estate e contri in estiere.
2024-05-19 13:43:04,972 - INFO - joeynmt.training - Example #4
2024-05-19 13:43:04,973 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:43:04,973 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:43:04,973 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'di', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:43:04,974 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:43:04,974 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:43:04,974 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò un rapido di più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:43:09,575 - INFO - joeynmt.training - Epoch   9, Step:    35600, Batch Loss:     1.147753, Batch Acc: 0.648770, Tokens per Sec:    14462, Lr: 0.000300
2024-05-19 13:43:13,168 - INFO - joeynmt.training - Epoch   9, Step:    35700, Batch Loss:     1.226592, Batch Acc: 0.639021, Tokens per Sec:    19138, Lr: 0.000300
2024-05-19 13:43:16,848 - INFO - joeynmt.training - Epoch   9, Step:    35800, Batch Loss:     1.391609, Batch Acc: 0.637625, Tokens per Sec:    19256, Lr: 0.000300
2024-05-19 13:43:20,937 - INFO - joeynmt.training - Epoch   9, Step:    35900, Batch Loss:     1.057167, Batch Acc: 0.643093, Tokens per Sec:    17633, Lr: 0.000300
2024-05-19 13:43:25,116 - INFO - joeynmt.training - Epoch   9, Step:    36000, Batch Loss:     1.283333, Batch Acc: 0.644391, Tokens per Sec:    17661, Lr: 0.000300
2024-05-19 13:43:25,116 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:43:25,117 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:43:35,225 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.60, acc:   0.59, generation: 9.9125[sec], evaluation: 0.0000[sec]
2024-05-19 13:43:35,520 - INFO - joeynmt.helpers - delete bpe_model_4000/35500.ckpt
2024-05-19 13:43:35,532 - INFO - joeynmt.helpers - delete /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/35500.ckpt
2024-05-19 13:43:35,533 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/35500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/35500.ckpt')
2024-05-19 13:43:35,537 - INFO - joeynmt.training - Example #0
2024-05-19 13:43:35,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:43:35,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:43:35,538 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'ca@@', 'po', 'della', 'g@@', 'on@@', 'c@@', 'ina', 'del', '4@@', '8', 'stati', 'le', 'dimen@@', 'sioni', 'dell@@', '&@@', 'a@@', 'pos@@', ';', 'ulti@@', 'ma', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', 'più', 'bas@@', 'so', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'chiesto', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:43:35,538 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:43:35,539 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:43:35,539 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive che la capo della goncina del 48 stati le dimensioni dell'ultima tre milioni di anni è stata la dimensione delle dimensioni di più basso 48 stati, ha richiesto dal 40%.
2024-05-19 13:43:35,539 - INFO - joeynmt.training - Example #1
2024-05-19 13:43:35,539 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:43:35,540 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:43:35,540 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'si', 'ved@@', 'e', 'la', 'sp@@', 'ess@@', 'enza', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:43:35,540 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:43:35,541 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:43:35,541 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serie di questo particolare problema perché non si vede la spessenza del ghiaccio.
2024-05-19 13:43:35,541 - INFO - joeynmt.training - Example #2
2024-05-19 13:43:35,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:43:35,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:43:35,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'a', 'di', 'ar@@', 'te', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:43:35,542 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:43:35,543 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:43:35,543 - INFO - joeynmt.training - 	Hypothesis: La capa di arte è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:43:35,543 - INFO - joeynmt.training - Example #3
2024-05-19 13:43:35,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:43:35,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:43:35,544 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', ',', 'si', 'è', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:43:35,544 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:43:35,544 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:43:35,545 - INFO - joeynmt.training - 	Hypothesis: Si espande in estate, si è in estate.
2024-05-19 13:43:35,545 - INFO - joeynmt.training - Example #4
2024-05-19 13:43:35,545 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:43:35,545 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:43:35,545 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:43:35,546 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:43:35,546 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:43:35,546 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:43:39,689 - INFO - joeynmt.training - Epoch   9, Step:    36100, Batch Loss:     1.300921, Batch Acc: 0.645219, Tokens per Sec:    16378, Lr: 0.000300
2024-05-19 13:43:43,342 - INFO - joeynmt.training - Epoch   9, Step:    36200, Batch Loss:     1.186430, Batch Acc: 0.638010, Tokens per Sec:    19579, Lr: 0.000300
2024-05-19 13:43:46,867 - INFO - joeynmt.training - Epoch   9, Step:    36300, Batch Loss:     1.385810, Batch Acc: 0.639121, Tokens per Sec:    20254, Lr: 0.000300
2024-05-19 13:43:51,316 - INFO - joeynmt.training - Epoch   9, Step:    36400, Batch Loss:     1.234476, Batch Acc: 0.637227, Tokens per Sec:    15837, Lr: 0.000300
2024-05-19 13:43:55,078 - INFO - joeynmt.training - Epoch   9, Step:    36500, Batch Loss:     1.283237, Batch Acc: 0.642307, Tokens per Sec:    18689, Lr: 0.000300
2024-05-19 13:43:55,078 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:43:55,079 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:44:04,937 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.56, acc:   0.59, generation: 9.6667[sec], evaluation: 0.0000[sec]
2024-05-19 13:44:05,263 - INFO - joeynmt.helpers - delete bpe_model_4000/36000.ckpt
2024-05-19 13:44:05,275 - INFO - joeynmt.helpers - delete /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/36000.ckpt
2024-05-19 13:44:05,275 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/36000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/36000.ckpt')
2024-05-19 13:44:05,279 - INFO - joeynmt.training - Example #0
2024-05-19 13:44:05,280 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:44:05,280 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:44:05,280 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'str@@', 'ano', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', 'più', 'bas@@', 'so', 'di', '4@@', '8', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'bas@@', 'so', ',', 'ha', 'sh@@', 'at@@', 'tu@@', 'ato', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:44:05,281 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:44:05,281 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:44:05,282 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diastrano, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione di più basso di 48 stati le dimensioni di basso, ha shattuato dal 40%.
2024-05-19 13:44:05,282 - INFO - joeynmt.training - Example #1
2024-05-19 13:44:05,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:44:05,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:44:05,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'capi@@', 'sce', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:44:05,283 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:44:05,283 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:44:05,284 - INFO - joeynmt.training - 	Hypothesis: Ma questo capisce la serietà di questo particolare problema perché non ha mostrato la spessità del ghiaccio.
2024-05-19 13:44:05,284 - INFO - joeynmt.training - Example #2
2024-05-19 13:44:05,284 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:44:05,284 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:44:05,284 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 't@@', 'ica', 'ca@@', 'p', 'fis@@', 's@@', 'ino', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:44:05,285 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:44:05,285 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:44:05,286 - INFO - joeynmt.training - 	Hypothesis: La tica cap fissino è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:44:05,286 - INFO - joeynmt.training - Example #3
2024-05-19 13:44:05,286 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:44:05,286 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:44:05,286 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'ate', 'e', 'si', 'è', 'est@@', 'i@@', 'ere', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:44:05,287 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:44:05,287 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:44:05,288 - INFO - joeynmt.training - 	Hypothesis: Spande in estate e si è estiere in estate.
2024-05-19 13:44:05,288 - INFO - joeynmt.training - Example #4
2024-05-19 13:44:05,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:44:05,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:44:05,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', '&@@', 'qu@@', 'ot@@', ';', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:44:05,289 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:44:05,289 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:44:05,290 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro "di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:44:09,077 - INFO - joeynmt.training - Epoch   9, Step:    36600, Batch Loss:     1.220840, Batch Acc: 0.639001, Tokens per Sec:    16980, Lr: 0.000300
2024-05-19 13:44:12,679 - INFO - joeynmt.training - Epoch   9, Step:    36700, Batch Loss:     1.285255, Batch Acc: 0.640374, Tokens per Sec:    19814, Lr: 0.000300
2024-05-19 13:44:16,471 - INFO - joeynmt.training - Epoch   9, Step:    36800, Batch Loss:     1.076612, Batch Acc: 0.641495, Tokens per Sec:    18958, Lr: 0.000300
2024-05-19 13:44:20,929 - INFO - joeynmt.training - Epoch   9, Step:    36900, Batch Loss:     1.303295, Batch Acc: 0.644049, Tokens per Sec:    16451, Lr: 0.000300
2024-05-19 13:44:24,557 - INFO - joeynmt.training - Epoch   9, Step:    37000, Batch Loss:     1.236910, Batch Acc: 0.641804, Tokens per Sec:    20359, Lr: 0.000300
2024-05-19 13:44:24,558 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:44:24,558 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:44:35,852 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.57, acc:   0.59, generation: 11.1779[sec], evaluation: 0.0000[sec]
2024-05-19 13:44:36,113 - INFO - joeynmt.helpers - delete bpe_model_4000/35000.ckpt
2024-05-19 13:44:36,125 - INFO - joeynmt.training - Example #0
2024-05-19 13:44:36,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:44:36,125 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:44:36,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'ca@@', 'ff@@', 'a', 'di', 'più', 'di', '4@@', '8', 'stati', 'le', 'dimen@@', 'sioni', 'di', 'circa', 'circa', 'circa', 'il', '40', '%', 'di', 'stati', 'le', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'sci@@', 'ri@@', 'di', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:44:36,127 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:44:36,127 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:44:36,127 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che la caffa di più di 48 stati le dimensioni di circa circa circa il 40% di stati le dimensioni di 48 stati, sono stati le dimensioni di 48 stati, ha risciridi dal 40%.
2024-05-19 13:44:36,128 - INFO - joeynmt.training - Example #1
2024-05-19 13:44:36,128 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:44:36,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:44:36,128 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:44:36,129 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:44:36,129 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:44:36,129 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serietà di questo particolare problema perché non mostra la spessità del ghiaccio.
2024-05-19 13:44:36,130 - INFO - joeynmt.training - Example #2
2024-05-19 13:44:36,130 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:44:36,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:44:36,130 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p', 'arti@@', 'fici@@', 'ale', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'ap@@', 'pun@@', 't@@', 'ale', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:44:36,131 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:44:36,131 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:44:36,131 - INFO - joeynmt.training - 	Hypothesis: La cap artificiale è, in un certo senso, il cuore appuntale del sistema globale.
2024-05-19 13:44:36,132 - INFO - joeynmt.training - Example #3
2024-05-19 13:44:36,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:44:36,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:44:36,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'ono', 'in', 'est@@', 'ate', 'e', 'si', 'ra@@', 'ff@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:44:36,133 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:44:36,133 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:44:36,133 - INFO - joeynmt.training - 	Hypothesis: Spandono in estate e si raffatti in estate.
2024-05-19 13:44:36,133 - INFO - joeynmt.training - Example #4
2024-05-19 13:44:36,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:44:36,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:44:36,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:44:36,135 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:44:36,135 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:44:36,135 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro un rapido rapido di quello che è successo negli ultimi 25 anni.
2024-05-19 13:44:39,726 - INFO - joeynmt.training - Epoch   9, Step:    37100, Batch Loss:     1.300260, Batch Acc: 0.646814, Tokens per Sec:    18760, Lr: 0.000300
2024-05-19 13:44:43,296 - INFO - joeynmt.training - Epoch   9, Step:    37200, Batch Loss:     1.344864, Batch Acc: 0.639729, Tokens per Sec:    19912, Lr: 0.000300
2024-05-19 13:44:47,477 - INFO - joeynmt.training - Epoch   9, Step:    37300, Batch Loss:     1.156269, Batch Acc: 0.644072, Tokens per Sec:    17188, Lr: 0.000300
2024-05-19 13:44:51,441 - INFO - joeynmt.training - Epoch   9, Step:    37400, Batch Loss:     1.490915, Batch Acc: 0.632977, Tokens per Sec:    17932, Lr: 0.000300
2024-05-19 13:44:54,988 - INFO - joeynmt.training - Epoch   9, Step:    37500, Batch Loss:     1.432937, Batch Acc: 0.634877, Tokens per Sec:    20233, Lr: 0.000300
2024-05-19 13:44:54,988 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:44:54,989 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:45:06,313 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.55, acc:   0.59, generation: 11.2122[sec], evaluation: 0.0000[sec]
2024-05-19 13:45:06,564 - INFO - joeynmt.helpers - delete bpe_model_4000/33500.ckpt
2024-05-19 13:45:06,568 - INFO - joeynmt.training - Example #0
2024-05-19 13:45:06,569 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:45:06,570 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:45:06,570 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'str@@', 'ate', 'che', 'la', 'ca@@', 'p', 'ar@@', 'c@@', 'ica', ',', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'è', 'stata', 'la', 'dimen@@', 'sione', 'del', '40', '%', '.', '</s>']
2024-05-19 13:45:06,571 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:45:06,571 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:45:06,571 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso, ho mostrato queste due diastrate che la cap arcica, per la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di 48 stati, è stata la dimensione del 40%.
2024-05-19 13:45:06,571 - INFO - joeynmt.training - Example #1
2024-05-19 13:45:06,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:45:06,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:45:06,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'il', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:45:06,573 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:45:06,573 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:45:06,573 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serietà di questo particolare problema perché non ha mostrato il ghiaccio.
2024-05-19 13:45:06,573 - INFO - joeynmt.training - Example #2
2024-05-19 13:45:06,574 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:45:06,574 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:45:06,574 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 't@@', 'ica', 'ca@@', 'p', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'col@@', 'tiv@@', 'are', 'il', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:45:06,575 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:45:06,575 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:45:06,575 - INFO - joeynmt.training - 	Hypothesis: La tica cap è, in un certo senso, il cuore di coltivare il sistema clima globale.
2024-05-19 13:45:06,575 - INFO - joeynmt.training - Example #3
2024-05-19 13:45:06,576 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:45:06,576 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:45:06,576 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'i@@', 'ere', 'e', 'si', 'è', 'est@@', 'i@@', 'ere', '.', '</s>']
2024-05-19 13:45:06,576 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:45:06,577 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:45:06,577 - INFO - joeynmt.training - 	Hypothesis: Spande in estiere e si è estiere.
2024-05-19 13:45:06,577 - INFO - joeynmt.training - Example #4
2024-05-19 13:45:06,577 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:45:06,578 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:45:06,578 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'vi', 'mostr@@', 'o', 'in', 'fre@@', 't@@', 'ta', 'di', 'cosa', 'è', 'acca@@', 'du@@', 'to', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:45:06,578 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:45:06,579 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:45:06,579 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva vi mostro in fretta di cosa è accaduto negli ultimi 25 anni.
2024-05-19 13:45:10,150 - INFO - joeynmt.training - Epoch   9, Step:    37600, Batch Loss:     1.397533, Batch Acc: 0.636234, Tokens per Sec:    18619, Lr: 0.000300
2024-05-19 13:45:14,090 - INFO - joeynmt.training - Epoch   9, Step:    37700, Batch Loss:     1.281648, Batch Acc: 0.634076, Tokens per Sec:    18267, Lr: 0.000300
2024-05-19 13:45:18,302 - INFO - joeynmt.training - Epoch   9, Step:    37800, Batch Loss:     1.313751, Batch Acc: 0.633549, Tokens per Sec:    16913, Lr: 0.000300
2024-05-19 13:45:21,912 - INFO - joeynmt.training - Epoch   9, Step:    37900, Batch Loss:     1.322800, Batch Acc: 0.633692, Tokens per Sec:    19822, Lr: 0.000300
2024-05-19 13:45:25,489 - INFO - joeynmt.training - Epoch   9, Step:    38000, Batch Loss:     1.306474, Batch Acc: 0.634682, Tokens per Sec:    19470, Lr: 0.000300
2024-05-19 13:45:25,490 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:45:25,490 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:45:37,252 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.57, acc:   0.59, generation: 11.6571[sec], evaluation: 0.0000[sec]
2024-05-19 13:45:37,257 - INFO - joeynmt.training - Example #0
2024-05-19 13:45:37,258 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:45:37,258 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:45:37,258 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', ',', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'che', 'la', 'ca@@', 'po', 'di', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'è', 'stata', 'la', 'dimen@@', 'sione', 'del', '40', 'per', 'c@@', 'ento', '.', '</s>']
2024-05-19 13:45:37,259 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:45:37,260 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:45:37,260 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso, ho mostrato queste due diapositive che la capo di artica, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di 48 stati, è stata la dimensione del 40 per cento.
2024-05-19 13:45:37,260 - INFO - joeynmt.training - Example #1
2024-05-19 13:45:37,261 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:45:37,261 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:45:37,261 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostra', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:45:37,262 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:45:37,262 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:45:37,262 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serietà di questo particolare problema perché non mostra la spessità del ghiaccio.
2024-05-19 13:45:37,262 - INFO - joeynmt.training - Example #2
2024-05-19 13:45:37,263 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:45:37,263 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:45:37,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 't@@', 'ica', 'ca@@', 'p', '&@@', 'qu@@', 'ot@@', ';', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'che', 'il', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:45:37,264 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:45:37,264 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:45:37,264 - INFO - joeynmt.training - 	Hypothesis: La tica cap "è, in un certo senso, il cuore che il sistema clima globale del sistema clima globale.
2024-05-19 13:45:37,264 - INFO - joeynmt.training - Example #3
2024-05-19 13:45:37,265 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:45:37,265 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:45:37,265 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:45:37,265 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:45:37,266 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:45:37,266 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e contratti in estate.
2024-05-19 13:45:37,266 - INFO - joeynmt.training - Example #4
2024-05-19 13:45:37,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:45:37,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:45:37,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'vi', 'mostr@@', 'o', 'rapi@@', 'da', 'in', 'fre@@', 't@@', 'ta', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:45:37,267 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:45:37,268 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:45:37,268 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi vi mostro rapida in fretta di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:45:40,846 - INFO - joeynmt.training - Epoch   9, Step:    38100, Batch Loss:     1.214619, Batch Acc: 0.635147, Tokens per Sec:    19657, Lr: 0.000300
2024-05-19 13:45:45,383 - INFO - joeynmt.training - Epoch   9, Step:    38200, Batch Loss:     1.345700, Batch Acc: 0.639334, Tokens per Sec:    15797, Lr: 0.000300
2024-05-19 13:45:48,994 - INFO - joeynmt.training - Epoch   9, Step:    38300, Batch Loss:     1.447483, Batch Acc: 0.633739, Tokens per Sec:    19664, Lr: 0.000300
2024-05-19 13:45:52,659 - INFO - joeynmt.training - Epoch   9, Step:    38400, Batch Loss:     1.398160, Batch Acc: 0.637701, Tokens per Sec:    19711, Lr: 0.000300
2024-05-19 13:45:56,543 - INFO - joeynmt.training - Epoch   9, Step:    38500, Batch Loss:     1.120949, Batch Acc: 0.637122, Tokens per Sec:    18990, Lr: 0.000300
2024-05-19 13:45:56,544 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:45:56,544 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:46:07,427 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.49, acc:   0.59, generation: 10.7711[sec], evaluation: 0.0000[sec]
2024-05-19 13:46:07,428 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:46:07,693 - INFO - joeynmt.helpers - delete bpe_model_4000/37000.ckpt
2024-05-19 13:46:07,698 - INFO - joeynmt.training - Example #0
2024-05-19 13:46:07,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:46:07,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:46:07,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mostr@@', 'o', 'la', 'ca@@', 'po', 'di', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'ma@@', 'st@@', 'e', 'di', 'un', '40', '%', '.', '</s>']
2024-05-19 13:46:07,701 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:46:07,701 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:46:07,701 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che dimostro la capo di artica, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione delle dimensioni di 48 stati, ha rimaste di un 40%.
2024-05-19 13:46:07,701 - INFO - joeynmt.training - Example #1
2024-05-19 13:46:07,702 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:46:07,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:46:07,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:46:07,703 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:46:07,703 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:46:07,703 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo particolare problema perché non mostra la spessità del ghiaccio.
2024-05-19 13:46:07,704 - INFO - joeynmt.training - Example #2
2024-05-19 13:46:07,704 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:46:07,704 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:46:07,704 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 't@@', 'ica', 'ca@@', 'p', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'un', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:46:07,705 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:46:07,705 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:46:07,705 - INFO - joeynmt.training - 	Hypothesis: La tica cap è, in un certo senso, il cuore di un sistema climatico globale.
2024-05-19 13:46:07,705 - INFO - joeynmt.training - Example #3
2024-05-19 13:46:07,706 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:46:07,706 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:46:07,706 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'op@@', 'i', 'in', 'in@@', 'ver@@', 'no', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:46:07,707 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:46:07,707 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:46:07,707 - INFO - joeynmt.training - 	Hypothesis: Sopi in inverno e contratti in estate.
2024-05-19 13:46:07,707 - INFO - joeynmt.training - Example #4
2024-05-19 13:46:07,708 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:46:07,708 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:46:07,708 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'o', 'un', 'rapi@@', 'do', 'rapi@@', 'da', 'di', 'più', 'velo@@', 'ce', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:46:07,708 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:46:07,709 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:46:07,709 - INFO - joeynmt.training - 	Hypothesis: La prossima slide mostro che vi mostro un rapido rapida di più veloce di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:46:11,956 - INFO - joeynmt.training - Epoch   9, Step:    38600, Batch Loss:     1.334329, Batch Acc: 0.632247, Tokens per Sec:    15488, Lr: 0.000300
2024-05-19 13:46:15,962 - INFO - joeynmt.training - Epoch   9, Step:    38700, Batch Loss:     1.300357, Batch Acc: 0.627950, Tokens per Sec:    17610, Lr: 0.000300
2024-05-19 13:46:19,624 - INFO - joeynmt.training - Epoch   9, Step:    38800, Batch Loss:     1.195349, Batch Acc: 0.635930, Tokens per Sec:    20375, Lr: 0.000300
2024-05-19 13:46:23,254 - INFO - joeynmt.training - Epoch   9, Step:    38900, Batch Loss:     1.444987, Batch Acc: 0.634031, Tokens per Sec:    19381, Lr: 0.000300
2024-05-19 13:46:27,732 - INFO - joeynmt.training - Epoch   9, Step:    39000, Batch Loss:     1.348716, Batch Acc: 0.630163, Tokens per Sec:    16177, Lr: 0.000300
2024-05-19 13:46:27,732 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:46:27,733 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:46:36,872 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.47, acc:   0.59, generation: 9.0345[sec], evaluation: 0.0000[sec]
2024-05-19 13:46:36,873 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-19 13:46:37,126 - INFO - joeynmt.helpers - delete bpe_model_4000/34000.ckpt
2024-05-19 13:46:37,131 - INFO - joeynmt.training - Example #0
2024-05-19 13:46:37,132 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:46:37,132 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:46:37,132 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'che', 'la', 'ca@@', 'p@@', 'ell@@', 'etta', 'ar@@', 't@@', 'ica', ',', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', ',', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'è', 'stata', 'la', 'dimen@@', 'sione', 'di', '4@@', '8', 'stati', ',', 'è', 'ri@@', 'ma@@', 'st@@', 'i', 'da', '40', '%', '.', '</s>']
2024-05-19 13:46:37,133 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:46:37,133 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:46:37,134 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che dimostrò che la capelletta artica, per la maggior parte degli ultimi tre milioni di anni, sono stati le dimensioni di 48 stati, è stata la dimensione di 48 stati, è rimasti da 40%.
2024-05-19 13:46:37,134 - INFO - joeynmt.training - Example #1
2024-05-19 13:46:37,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:46:37,135 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:46:37,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:46:37,135 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:46:37,136 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:46:37,136 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serietà di questo particolare problema perché non mostra la spessità del ghiaccio.
2024-05-19 13:46:37,136 - INFO - joeynmt.training - Example #2
2024-05-19 13:46:37,136 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:46:37,136 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:46:37,137 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p', 'ar@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:46:37,137 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:46:37,137 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:46:37,138 - INFO - joeynmt.training - 	Hypothesis: La cap artico è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:46:37,138 - INFO - joeynmt.training - Example #3
2024-05-19 13:46:37,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:46:37,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:46:37,139 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:46:37,139 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:46:37,139 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:46:37,140 - INFO - joeynmt.training - 	Hypothesis: Si espande in inverno e si è in estate.
2024-05-19 13:46:37,140 - INFO - joeynmt.training - Example #4
2024-05-19 13:46:37,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:46:37,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:46:37,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'che', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'rapi@@', 'da', 'di', 'più', 'velo@@', 'ci', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:46:37,141 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:46:37,141 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:46:37,142 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostrerò un rapido rapida di più veloci di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:46:41,726 - INFO - joeynmt.training - Epoch   9, Step:    39100, Batch Loss:     1.217087, Batch Acc: 0.639527, Tokens per Sec:    15021, Lr: 0.000300
2024-05-19 13:46:43,044 - INFO - joeynmt.training - Epoch   9: total training loss 5586.09
2024-05-19 13:46:43,045 - INFO - joeynmt.training - EPOCH 10
2024-05-19 13:46:45,296 - INFO - joeynmt.training - Epoch  10, Step:    39200, Batch Loss:     1.150711, Batch Acc: 0.662784, Tokens per Sec:    19451, Lr: 0.000300
2024-05-19 13:46:48,983 - INFO - joeynmt.training - Epoch  10, Step:    39300, Batch Loss:     1.143449, Batch Acc: 0.656658, Tokens per Sec:    19827, Lr: 0.000300
2024-05-19 13:46:52,800 - INFO - joeynmt.training - Epoch  10, Step:    39400, Batch Loss:     1.358335, Batch Acc: 0.664719, Tokens per Sec:    19100, Lr: 0.000300
2024-05-19 13:46:57,133 - INFO - joeynmt.training - Epoch  10, Step:    39500, Batch Loss:     1.327649, Batch Acc: 0.659038, Tokens per Sec:    16268, Lr: 0.000300
2024-05-19 13:46:57,134 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:46:57,134 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:47:06,779 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.54, acc:   0.59, generation: 9.4253[sec], evaluation: 0.0000[sec]
2024-05-19 13:47:07,071 - INFO - joeynmt.helpers - delete bpe_model_4000/36500.ckpt
2024-05-19 13:47:07,076 - INFO - joeynmt.training - Example #0
2024-05-19 13:47:07,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:47:07,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:47:07,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'str@@', 'ano', 'che', 'la', 'ca@@', 'po', 'di', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'state', 'le', 'dimen@@', 'sioni', 'delle', 'dimen@@', 'sioni', 'delle', 'dimen@@', 'sioni', 'delle', 'bas@@', 'se', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'ma@@', 'st@@', 'e', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:47:07,080 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:47:07,080 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:47:07,080 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diastrano che la capo di artica, che per la maggior parte degli ultimi tre milioni di anni sono state le dimensioni delle dimensioni delle dimensioni delle basse 48 stati, ha rimaste dal 40%.
2024-05-19 13:47:07,082 - INFO - joeynmt.training - Example #1
2024-05-19 13:47:07,083 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:47:07,083 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:47:07,083 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'problema', 'in', 'cui', 'questa', 'particol@@', 'are', 'problema', 'in', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:47:07,084 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:47:07,084 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:47:07,084 - INFO - joeynmt.training - 	Hypothesis: Ma questo problema in cui questa particolare problema in questo particolare problema perché non ha mostrato la spessità del ghiaccio.
2024-05-19 13:47:07,085 - INFO - joeynmt.training - Example #2
2024-05-19 13:47:07,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:47:07,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:47:07,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'elle', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'ap@@', 're', 'il', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:47:07,086 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:47:07,086 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:47:07,087 - INFO - joeynmt.training - 	Hypothesis: La capelle artica è, in un certo senso, il cuore di apre il sistema clima globale.
2024-05-19 13:47:07,087 - INFO - joeynmt.training - Example #3
2024-05-19 13:47:07,087 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:47:07,087 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:47:07,087 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'n@@', 'ali', 'e', 'cont@@', 'ra@@', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:47:07,088 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:47:07,088 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:47:07,089 - INFO - joeynmt.training - 	Hypothesis: Spande in invernali e contrad'estate.
2024-05-19 13:47:07,089 - INFO - joeynmt.training - Example #4
2024-05-19 13:47:07,089 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:47:07,089 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:47:07,090 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'mostr@@', 'o', 'che', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'su', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:47:07,090 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:47:07,090 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:47:07,091 - INFO - joeynmt.training - 	Hypothesis: La prossima slide mostro che vi mostrerò un rapido rapido di su quello che è successo negli ultimi 25 anni.
2024-05-19 13:47:11,368 - INFO - joeynmt.training - Epoch  10, Step:    39600, Batch Loss:     1.249175, Batch Acc: 0.652145, Tokens per Sec:    15523, Lr: 0.000300
2024-05-19 13:47:14,927 - INFO - joeynmt.training - Epoch  10, Step:    39700, Batch Loss:     1.281363, Batch Acc: 0.656095, Tokens per Sec:    20374, Lr: 0.000300
2024-05-19 13:47:18,574 - INFO - joeynmt.training - Epoch  10, Step:    39800, Batch Loss:     1.262929, Batch Acc: 0.658849, Tokens per Sec:    19911, Lr: 0.000300
2024-05-19 13:47:22,908 - INFO - joeynmt.training - Epoch  10, Step:    39900, Batch Loss:     1.309287, Batch Acc: 0.654839, Tokens per Sec:    17028, Lr: 0.000300
2024-05-19 13:47:26,792 - INFO - joeynmt.training - Epoch  10, Step:    40000, Batch Loss:     1.267608, Batch Acc: 0.647842, Tokens per Sec:    19174, Lr: 0.000300
2024-05-19 13:47:26,793 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:47:26,793 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:47:37,289 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.52, acc:   0.59, generation: 10.3051[sec], evaluation: 0.0000[sec]
2024-05-19 13:47:37,638 - INFO - joeynmt.helpers - delete bpe_model_4000/37500.ckpt
2024-05-19 13:47:37,652 - INFO - joeynmt.training - Example #0
2024-05-19 13:47:37,653 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:47:37,654 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:47:37,654 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'di@@', 'mostr@@', 'o', 'che', 'la', 'ca@@', 'p@@', 'elle', 'ar@@', 't@@', 'ica', ',', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'dei', '4@@', '8', 'stati', ',', 'è', 'stata', 'la', 'dimen@@', 'sione', 'del', '40', '%', '.', '</s>']
2024-05-19 13:47:37,655 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:47:37,656 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:47:37,656 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diapositive così che dimostro che la capelle artica, per la maggior parte degli ultimi tre milioni di anni è stata la dimensione dei 48 stati, è stata la dimensione del 40%.
2024-05-19 13:47:37,656 - INFO - joeynmt.training - Example #1
2024-05-19 13:47:37,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:47:37,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:47:37,658 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'particol@@', 'are', 'problema', ',', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'a', 'la', 'sp@@', 'int@@', 'a', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:47:37,659 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:47:37,659 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:47:37,660 - INFO - joeynmt.training - 	Hypothesis: Ma questo particolare problema, perché non ha mostrato la serietà di questo particolare problema perché non mostra la spinta del ghiaccio.
2024-05-19 13:47:37,669 - INFO - joeynmt.training - Example #2
2024-05-19 13:47:37,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:47:37,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:47:37,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 't@@', 'ica', 'ca@@', 'p', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:47:37,670 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:47:37,671 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:47:37,671 - INFO - joeynmt.training - 	Hypothesis: La tica cap è, in un certo senso, il cuore del sistema globale.
2024-05-19 13:47:37,672 - INFO - joeynmt.training - Example #3
2024-05-19 13:47:37,672 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:47:37,673 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:47:37,673 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'ono', 'in', 'in@@', 'ver@@', 'no', 'e', 'si', 'è', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:47:37,673 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:47:37,674 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:47:37,674 - INFO - joeynmt.training - 	Hypothesis: Spandono in inverno e si è in estate.
2024-05-19 13:47:37,675 - INFO - joeynmt.training - Example #4
2024-05-19 13:47:37,675 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:47:37,676 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:47:37,676 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'o', 'che', 'sarà', 'rapi@@', 'da', 'velo@@', 'ci', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:47:37,677 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:47:37,677 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:47:37,678 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostro che sarà rapida veloci di quello che è successo negli ultimi 25 anni.
2024-05-19 13:47:41,384 - INFO - joeynmt.training - Epoch  10, Step:    40100, Batch Loss:     1.119314, Batch Acc: 0.650784, Tokens per Sec:    17262, Lr: 0.000300
2024-05-19 13:47:45,121 - INFO - joeynmt.training - Epoch  10, Step:    40200, Batch Loss:     1.071923, Batch Acc: 0.653490, Tokens per Sec:    19493, Lr: 0.000300
2024-05-19 13:47:48,986 - INFO - joeynmt.training - Epoch  10, Step:    40300, Batch Loss:     1.114411, Batch Acc: 0.650514, Tokens per Sec:    18600, Lr: 0.000300
2024-05-19 13:47:53,396 - INFO - joeynmt.training - Epoch  10, Step:    40400, Batch Loss:     1.260976, Batch Acc: 0.650479, Tokens per Sec:    16331, Lr: 0.000300
2024-05-19 13:47:56,975 - INFO - joeynmt.training - Epoch  10, Step:    40500, Batch Loss:     1.083210, Batch Acc: 0.652431, Tokens per Sec:    20002, Lr: 0.000300
2024-05-19 13:47:56,976 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:47:56,976 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:48:07,783 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.56, acc:   0.59, generation: 10.6808[sec], evaluation: 0.0000[sec]
2024-05-19 13:48:07,787 - INFO - joeynmt.training - Example #0
2024-05-19 13:48:07,788 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:48:07,788 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:48:07,789 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'str@@', 'ate', 'che', 'di@@', 'mostr@@', 'ò', 'la', 'ca@@', 'po', 'di', 'ar@@', 'c@@', 'ico', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'del', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'ma@@', 'st@@', 'i', 'di', '4@@', '8', 'stati', ',', 'ha', 'ri@@', 'ma@@', 'st@@', 'i', 'al', '40', '%', '.', '</s>']
2024-05-19 13:48:07,790 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:48:07,790 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:48:07,790 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diastrate che dimostrò la capo di arcico, che per la maggior parte degli ultimi tre milioni di anni è stata la dimensione del 48 stati, ha rimasti di 48 stati, ha rimasti al 40%.
2024-05-19 13:48:07,791 - INFO - joeynmt.training - Example #1
2024-05-19 13:48:07,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:48:07,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:48:07,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:48:07,792 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:48:07,793 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:48:07,793 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo particolare problema perché non ha mostrato la spessità del ghiaccio.
2024-05-19 13:48:07,793 - INFO - joeynmt.training - Example #2
2024-05-19 13:48:07,793 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:48:07,794 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:48:07,794 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'a', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'ap@@', 'ri@@', 'g@@', 'no', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:48:07,794 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:48:07,795 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:48:07,795 - INFO - joeynmt.training - 	Hypothesis: La capa artica è, in un certo senso, il cuore di aprigno globale.
2024-05-19 13:48:07,795 - INFO - joeynmt.training - Example #3
2024-05-19 13:48:07,795 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:48:07,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:48:07,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'ere', 'e', 'al', 'contr@@', 'ario', '.', '</s>']
2024-05-19 13:48:07,796 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:48:07,797 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:48:07,797 - INFO - joeynmt.training - 	Hypothesis: Si espandere e al contrario.
2024-05-19 13:48:07,797 - INFO - joeynmt.training - Example #4
2024-05-19 13:48:07,797 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:48:07,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:48:07,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'erò', 'una', 'rapi@@', 'da', 'velo@@', 'ce', 'di', 'cosa', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:48:07,798 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:48:07,799 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:48:07,799 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostrerò una rapida veloce di cosa è successo negli ultimi 25 anni.
2024-05-19 13:48:11,418 - INFO - joeynmt.training - Epoch  10, Step:    40600, Batch Loss:     1.128294, Batch Acc: 0.652790, Tokens per Sec:    19842, Lr: 0.000300
2024-05-19 13:48:14,981 - INFO - joeynmt.training - Epoch  10, Step:    40700, Batch Loss:     1.354042, Batch Acc: 0.647060, Tokens per Sec:    20454, Lr: 0.000300
2024-05-19 13:48:19,233 - INFO - joeynmt.training - Epoch  10, Step:    40800, Batch Loss:     1.286103, Batch Acc: 0.650610, Tokens per Sec:    17305, Lr: 0.000300
2024-05-19 13:48:23,112 - INFO - joeynmt.training - Epoch  10, Step:    40900, Batch Loss:     1.297947, Batch Acc: 0.651560, Tokens per Sec:    18698, Lr: 0.000300
2024-05-19 13:48:26,739 - INFO - joeynmt.training - Epoch  10, Step:    41000, Batch Loss:     1.288457, Batch Acc: 0.644942, Tokens per Sec:    19830, Lr: 0.000300
2024-05-19 13:48:26,740 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:48:26,740 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:48:36,920 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.54, acc:   0.59, generation: 10.0763[sec], evaluation: 0.0000[sec]
2024-05-19 13:48:37,161 - INFO - joeynmt.helpers - delete bpe_model_4000/34500.ckpt
2024-05-19 13:48:37,166 - INFO - joeynmt.training - Example #0
2024-05-19 13:48:37,167 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:48:37,167 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:48:37,167 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'ca@@', 'ff@@', 'a', 'di', 'una', 'ca@@', 'zz@@', 'ina', ',', 'che', 'per', 'la', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stati', 'le', 'dimen@@', 'sioni', 'delle', 'dimen@@', 'sioni', 'di', '4@@', '8', 'stati', ',', 'ha', 's@@', 'ca@@', 'ff@@', 'o', 'del', '40', '%', '.', '</s>']
2024-05-19 13:48:37,168 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:48:37,169 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:48:37,169 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso queste due diapositive così che la caffa di una cazzina, che per la maggior parte degli ultimi tre milioni di anni sono stati le dimensioni delle dimensioni di 48 stati, ha scaffo del 40%.
2024-05-19 13:48:37,169 - INFO - joeynmt.training - Example #1
2024-05-19 13:48:37,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:48:37,170 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:48:37,170 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'serie', 'di', 'questo', 'problema', ',', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 't@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:48:37,170 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:48:37,171 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:48:37,171 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serie di questo problema, perché non ha mostrato la tessità del ghiaccio.
2024-05-19 13:48:37,171 - INFO - joeynmt.training - Example #2
2024-05-19 13:48:37,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:48:37,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:48:37,172 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p@@', 'elle', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'tutto', 'il', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:48:37,172 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:48:37,173 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:48:37,173 - INFO - joeynmt.training - 	Hypothesis: La capelle artica è, in un senso, il cuore di tutto il sistema clima globale.
2024-05-19 13:48:37,173 - INFO - joeynmt.training - Example #3
2024-05-19 13:48:37,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:48:37,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:48:37,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'ono', 'in', 'in@@', 'ver@@', 'no', 'e', 'contr@@', 'ari', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:48:37,174 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:48:37,174 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:48:37,175 - INFO - joeynmt.training - 	Hypothesis: Spandono in inverno e contrari in estate.
2024-05-19 13:48:37,175 - INFO - joeynmt.training - Example #4
2024-05-19 13:48:37,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:48:37,175 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:48:37,176 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'rapi@@', 'da', 'più', 'velo@@', 'ce', 'di', 'cosa', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:48:37,176 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:48:37,176 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:48:37,177 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro rapida più veloce di cosa è successo negli ultimi 25 anni.
2024-05-19 13:48:40,756 - INFO - joeynmt.training - Epoch  10, Step:    41100, Batch Loss:     1.158650, Batch Acc: 0.647624, Tokens per Sec:    18854, Lr: 0.000300
2024-05-19 13:48:44,359 - INFO - joeynmt.training - Epoch  10, Step:    41200, Batch Loss:     1.300789, Batch Acc: 0.646256, Tokens per Sec:    19741, Lr: 0.000300
2024-05-19 13:48:48,868 - INFO - joeynmt.training - Epoch  10, Step:    41300, Batch Loss:     1.313124, Batch Acc: 0.642661, Tokens per Sec:    15739, Lr: 0.000300
2024-05-19 13:48:52,538 - INFO - joeynmt.training - Epoch  10, Step:    41400, Batch Loss:     1.403457, Batch Acc: 0.645611, Tokens per Sec:    18997, Lr: 0.000300
2024-05-19 13:48:56,198 - INFO - joeynmt.training - Epoch  10, Step:    41500, Batch Loss:     1.285961, Batch Acc: 0.644509, Tokens per Sec:    20501, Lr: 0.000300
2024-05-19 13:48:56,199 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:48:56,199 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:49:06,930 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.51, acc:   0.59, generation: 10.6128[sec], evaluation: 0.0000[sec]
2024-05-19 13:49:07,179 - INFO - joeynmt.helpers - delete bpe_model_4000/41000.ckpt
2024-05-19 13:49:07,181 - INFO - joeynmt.helpers - delete /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/41000.ckpt
2024-05-19 13:49:07,182 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/41000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/41000.ckpt')
2024-05-19 13:49:07,185 - INFO - joeynmt.training - Example #0
2024-05-19 13:49:07,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:49:07,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:49:07,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'che', 'la', 'ca@@', 'p', 'ar@@', 't@@', 'ica', 'delle', 'ul@@', 'time', 'tre', 'milioni', 'di', 'anni', 'sono', 'stato', 'le', 'dimen@@', 'sioni', 'delle', 'dimen@@', 'sioni', 'delle', 'bas@@', 'se', '4@@', '8', 'stati', ',', 'si', 'è', 's@@', 'ca@@', 'ff@@', 'o', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:49:07,187 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:49:07,187 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:49:07,188 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due slide così che dimostrò che la cap artica delle ultime tre milioni di anni sono stato le dimensioni delle dimensioni delle basse 48 stati, si è scaffo dal 40%.
2024-05-19 13:49:07,188 - INFO - joeynmt.training - Example #1
2024-05-19 13:49:07,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:49:07,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:49:07,189 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'ha', 'capi@@', 'to', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'mostr@@', 'ano', 'il', 't@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:49:07,190 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:49:07,190 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:49:07,190 - INFO - joeynmt.training - 	Hypothesis: Ma questo ha capito la serietà di questo particolare problema perché non mostrano il tessore del ghiaccio.
2024-05-19 13:49:07,190 - INFO - joeynmt.training - Example #2
2024-05-19 13:49:07,191 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:49:07,191 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:49:07,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p', 'or@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'ap@@', 'pun@@', 't@@', 'amento', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:49:07,192 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:49:07,192 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:49:07,192 - INFO - joeynmt.training - 	Hypothesis: La cap ortico è, in un certo senso, il cuore di appuntamento globale.
2024-05-19 13:49:07,192 - INFO - joeynmt.training - Example #3
2024-05-19 13:49:07,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:49:07,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:49:07,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'i@@', 'ame', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:49:07,194 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:49:07,194 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:49:07,194 - INFO - joeynmt.training - 	Hypothesis: Spande in estiame in estate.
2024-05-19 13:49:07,194 - INFO - joeynmt.training - Example #4
2024-05-19 13:49:07,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:49:07,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:49:07,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'vi', 'mostr@@', 'erò', 'sarà', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'ciò', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:49:07,196 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:49:07,196 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:49:07,196 - INFO - joeynmt.training - 	Hypothesis: La prossima slide vi mostrerò sarà un rapido rapido di ciò che è successo negli ultimi 25 anni.
2024-05-19 13:49:10,791 - INFO - joeynmt.training - Epoch  10, Step:    41600, Batch Loss:     1.265337, Batch Acc: 0.645579, Tokens per Sec:    18606, Lr: 0.000300
2024-05-19 13:49:14,847 - INFO - joeynmt.training - Epoch  10, Step:    41700, Batch Loss:     1.194767, Batch Acc: 0.646791, Tokens per Sec:    17574, Lr: 0.000300
2024-05-19 13:49:18,987 - INFO - joeynmt.training - Epoch  10, Step:    41800, Batch Loss:     1.176187, Batch Acc: 0.645622, Tokens per Sec:    17225, Lr: 0.000300
2024-05-19 13:49:22,656 - INFO - joeynmt.training - Epoch  10, Step:    41900, Batch Loss:     1.087842, Batch Acc: 0.639176, Tokens per Sec:    19605, Lr: 0.000300
2024-05-19 13:49:26,304 - INFO - joeynmt.training - Epoch  10, Step:    42000, Batch Loss:     1.220871, Batch Acc: 0.653045, Tokens per Sec:    19700, Lr: 0.000300
2024-05-19 13:49:26,305 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:49:26,305 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:49:36,551 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.52, acc:   0.59, generation: 10.1470[sec], evaluation: 0.0000[sec]
2024-05-19 13:49:36,817 - INFO - joeynmt.helpers - delete bpe_model_4000/39500.ckpt
2024-05-19 13:49:36,822 - INFO - joeynmt.training - Example #0
2024-05-19 13:49:36,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:49:36,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:49:36,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Lo', 'scor@@', 'so', 'anno', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'sli@@', 'de', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'che', 'la', 'ca@@', 'ff@@', 'a', 'ar@@', 't@@', 'ica', 'della', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'sono', 'stata', 'la', 'dimen@@', 'sione', 'delle', 'dimen@@', 'sioni', 'della', 'dimen@@', 'sione', 'del', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'st@@', 'i', 'di', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'dal', '40', '%', '.', '</s>']
2024-05-19 13:49:36,825 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:49:36,825 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:49:36,825 - INFO - joeynmt.training - 	Hypothesis: Lo scorso anno ho mostrato queste due slide così che dimostrò che la caffa artica della maggior parte degli ultimi tre milioni di anni sono stata la dimensione delle dimensioni della dimensione del 48 stati, si è rimasti di 48 stati, si è rimasta dal 40%.
2024-05-19 13:49:36,826 - INFO - joeynmt.training - Example #1
2024-05-19 13:49:36,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:49:36,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:49:36,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'com@@', 'preso', 'la', 'seri@@', 'età', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'l@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ick@@', 'ness', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:49:36,827 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:49:36,827 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:49:36,827 - INFO - joeynmt.training - 	Hypothesis: Ma questo compreso la serietà di questo particolare problema perché non ha mostrato l'inickness del ghiaccio.
2024-05-19 13:49:36,828 - INFO - joeynmt.training - Example #2
2024-05-19 13:49:36,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:49:36,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:49:36,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:49:36,829 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:49:36,829 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:49:36,830 - INFO - joeynmt.training - 	Hypothesis: La cap artica è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:49:36,830 - INFO - joeynmt.training - Example #3
2024-05-19 13:49:36,830 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:49:36,830 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:49:36,830 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'vol@@', 'ge', 'in', 'in@@', 'ver@@', 'no', 'e', 'cont@@', 'at@@', 'ti', 'in', 'est@@', 'i@@', 'vo', '.', '</s>']
2024-05-19 13:49:36,831 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:49:36,831 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:49:36,831 - INFO - joeynmt.training - 	Hypothesis: Svolge in inverno e contatti in estivo.
2024-05-19 13:49:36,832 - INFO - joeynmt.training - Example #4
2024-05-19 13:49:36,832 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:49:36,832 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:49:36,832 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'sli@@', 'de', 'che', 'vi', 'mostr@@', 'o', 'sarà', 'un', 'rapi@@', 'do', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:49:36,833 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:49:36,833 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:49:36,833 - INFO - joeynmt.training - 	Hypothesis: La prossima slide che vi mostro sarà un rapido rapido di quello che è successo negli ultimi 25 anni.
2024-05-19 13:49:40,476 - INFO - joeynmt.training - Epoch  10, Step:    42100, Batch Loss:     1.297058, Batch Acc: 0.645548, Tokens per Sec:    18842, Lr: 0.000300
2024-05-19 13:49:44,880 - INFO - joeynmt.training - Epoch  10, Step:    42200, Batch Loss:     1.174160, Batch Acc: 0.643365, Tokens per Sec:    16423, Lr: 0.000300
2024-05-19 13:49:48,673 - INFO - joeynmt.training - Epoch  10, Step:    42300, Batch Loss:     1.424037, Batch Acc: 0.642430, Tokens per Sec:    19397, Lr: 0.000300
2024-05-19 13:49:52,314 - INFO - joeynmt.training - Epoch  10, Step:    42400, Batch Loss:     1.275315, Batch Acc: 0.643964, Tokens per Sec:    19907, Lr: 0.000300
2024-05-19 13:49:56,020 - INFO - joeynmt.training - Epoch  10, Step:    42500, Batch Loss:     1.339025, Batch Acc: 0.640217, Tokens per Sec:    18870, Lr: 0.000300
2024-05-19 13:49:56,021 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:49:56,021 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:50:07,241 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.54, acc:   0.59, generation: 11.1120[sec], evaluation: 0.0000[sec]
2024-05-19 13:50:07,245 - INFO - joeynmt.training - Example #0
2024-05-19 13:50:07,246 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:50:07,247 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:50:07,247 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'la', 'ca@@', 'p', 'ar@@', 'c@@', 'ica', 'della', 'maggior', 'parte', 'degli', 'ultimi', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', '4@@', '8', 'stati', ',', 'si', 'è', 'ri@@', 'ma@@', 'sta', 'del', '40', '%', '.', '</s>']
2024-05-19 13:50:07,248 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:50:07,248 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:50:07,249 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che la cap arcica della maggior parte degli ultimi tre milioni di anni è stata la dimensione delle 48 stati, si è rimasta del 40%.
2024-05-19 13:50:07,249 - INFO - joeynmt.training - Example #1
2024-05-19 13:50:07,249 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:50:07,250 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:50:07,250 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'particol@@', 'are', 'la', 'serie', 'di', 'questo', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:50:07,251 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:50:07,251 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:50:07,251 - INFO - joeynmt.training - 	Hypothesis: Ma questo particolare la serie di questo problema perché non ha mostrato la spessità del ghiaccio.
2024-05-19 13:50:07,252 - INFO - joeynmt.training - Example #2
2024-05-19 13:50:07,252 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:50:07,252 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:50:07,252 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'ca@@', 'p', 'arti@@', 'sta', 'della', 'car@@', 'ta', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'del', 'sistema', 'cli@@', 'ma', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:50:07,253 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:50:07,253 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:50:07,253 - INFO - joeynmt.training - 	Hypothesis: La cap artista della carta è, in un certo senso, il cuore del sistema clima globale.
2024-05-19 13:50:07,254 - INFO - joeynmt.training - Example #3
2024-05-19 13:50:07,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:50:07,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:50:07,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Si', 'es@@', 'p@@', 'and@@', 'e', 'in', 'est@@', 'i@@', 'ere', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'i@@', 'era', '.', '</s>']
2024-05-19 13:50:07,255 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:50:07,255 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:50:07,255 - INFO - joeynmt.training - 	Hypothesis: Si espande in estiere e contratti in estiera.
2024-05-19 13:50:07,256 - INFO - joeynmt.training - Example #4
2024-05-19 13:50:07,256 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:50:07,256 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:50:07,256 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'vi', 'mostr@@', 'erò', 'un', 'rapi@@', 'do', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:50:07,257 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:50:07,257 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:50:07,257 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi vi mostrerò un rapido di quello che è successo negli ultimi 25 anni.
2024-05-19 13:50:11,202 - INFO - joeynmt.training - Epoch  10, Step:    42600, Batch Loss:     1.386237, Batch Acc: 0.642453, Tokens per Sec:    17875, Lr: 0.000300
2024-05-19 13:50:15,516 - INFO - joeynmt.training - Epoch  10, Step:    42700, Batch Loss:     1.201979, Batch Acc: 0.641069, Tokens per Sec:    16535, Lr: 0.000300
2024-05-19 13:50:19,087 - INFO - joeynmt.training - Epoch  10, Step:    42800, Batch Loss:     1.136253, Batch Acc: 0.638297, Tokens per Sec:    20184, Lr: 0.000300
2024-05-19 13:50:22,668 - INFO - joeynmt.training - Epoch  10, Step:    42900, Batch Loss:     1.297724, Batch Acc: 0.641787, Tokens per Sec:    19562, Lr: 0.000300
2024-05-19 13:50:26,955 - INFO - joeynmt.training - Epoch  10, Step:    43000, Batch Loss:     1.315060, Batch Acc: 0.637956, Tokens per Sec:    16665, Lr: 0.000300
2024-05-19 13:50:26,955 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:50:26,956 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:50:37,713 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.50, acc:   0.59, generation: 10.6519[sec], evaluation: 0.0000[sec]
2024-05-19 13:50:37,961 - INFO - joeynmt.helpers - delete bpe_model_4000/40000.ckpt
2024-05-19 13:50:37,971 - INFO - joeynmt.training - Example #0
2024-05-19 13:50:37,972 - DEBUG - joeynmt.training - 	Tokenized source:     ['L@@', 'ast', 'year', 'I', 'show@@', 'ed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'low@@', 'er', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-19 13:50:37,972 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'a@@', 'positi@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'Stati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'stre@@', 't@@', 'ta', 'del', '40', '%', '.']
2024-05-19 13:50:37,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', '&@@', 'a@@', 'pos@@', ';', 'anno', 'scor@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'due', 'di@@', 'a@@', 'positi@@', 've', 'così', 'che', 'di@@', 'mostr@@', 'ò', 'che', 'la', 'ca@@', 'p@@', 'elle', 'ar@@', 't@@', 'ica', 'del', '4@@', '8', 'stati', 'le', 'dimen@@', 'sioni', 'delle', 'dimen@@', 'sioni', 'dell@@', '&@@', 'a@@', 'pos@@', ';', 'ultimo', 'tre', 'milioni', 'di', 'anni', 'è', 'stata', 'la', 'dimen@@', 'sione', 'delle', '4@@', '8', 'stati', ',', 'si', 'è', 's@@', 'ca@@', 'ff@@', 'a', 'di', '40', '%', '.', '</s>']
2024-05-19 13:50:37,973 - INFO - joeynmt.training - 	Source:     Last year I showed these two slides so that demonstrate that the arctic ice cap, which for most of the last three million years has been the size of the lower 48 states, has shrunk by 40 percent.
2024-05-19 13:50:37,973 - INFO - joeynmt.training - 	Reference:  L'anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica, che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali, si è ristretta del 40%.
2024-05-19 13:50:37,974 - INFO - joeynmt.training - 	Hypothesis: L'anno scorso ho mostrato queste due diapositive così che dimostrò che la capelle artica del 48 stati le dimensioni delle dimensioni dell'ultimo tre milioni di anni è stata la dimensione delle 48 stati, si è scaffa di 40%.
2024-05-19 13:50:37,974 - INFO - joeynmt.training - Example #1
2024-05-19 13:50:37,974 - DEBUG - joeynmt.training - 	Tokenized source:     ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'does@@', 'n', '&@@', 'a@@', 'pos@@', ';@@', 't', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-19 13:50:37,975 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Tut@@', 'tav@@', 'ia', 'questo', 'sot@@', 'to@@', 'val@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghi@@', 'accio', '.']
2024-05-19 13:50:37,975 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Ma', 'questo', 'com@@', 'preso', 'la', 'serie', 'di', 'questo', 'particol@@', 'are', 'problema', 'perché', 'non', 'ha', 'mostr@@', 'ato', 'la', 'sp@@', 'ess@@', 'ità', 'del', 'ghi@@', 'accio', '.', '</s>']
2024-05-19 13:50:37,975 - INFO - joeynmt.training - 	Source:     But this understates the seriousness of this particular problem because it doesn't show the thickness of the ice.
2024-05-19 13:50:37,976 - INFO - joeynmt.training - 	Reference:  Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio.
2024-05-19 13:50:37,976 - INFO - joeynmt.training - 	Hypothesis: Ma questo compreso la serie di questo particolare problema perché non ha mostrato la spessità del ghiaccio.
2024-05-19 13:50:37,976 - INFO - joeynmt.training - Example #2
2024-05-19 13:50:37,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'clim@@', 'ate', 'system', '.']
2024-05-19 13:50:37,976 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'cal@@', 'ot@@', 'ta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-19 13:50:37,977 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 't@@', 'ica', 'ca@@', 'p', 'ar@@', 't@@', 'ico', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'di', 'ap@@', 'pun@@', 't@@', 'amento', 'glob@@', 'ale', '.', '</s>']
2024-05-19 13:50:37,977 - INFO - joeynmt.training - 	Source:     The arctic ice cap is, in a sense, the beating heart of the global climate system.
2024-05-19 13:50:37,977 - INFO - joeynmt.training - 	Reference:  La calotta glaciale artica è, in un certo senso, il cuore pulsante del sistema climatico globale.
2024-05-19 13:50:37,978 - INFO - joeynmt.training - 	Hypothesis: La tica cap artico è, in un certo senso, il cuore di appuntamento globale.
2024-05-19 13:50:37,978 - INFO - joeynmt.training - Example #3
2024-05-19 13:50:37,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'int@@', 'er', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-19 13:50:37,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Si', 'es@@', 'p@@', 'and@@', 'e', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'in@@', 'ver@@', 'no', 'e', 'si', 'rit@@', 'i@@', 'ra', 'd@@', '&@@', 'a@@', 'pos@@', ';', 'est@@', 'ate', '.']
2024-05-19 13:50:37,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['S@@', 'p@@', 'and@@', 'e', 'in', 'in@@', 'ver@@', 'no', 'e', 'contr@@', 'at@@', 'ti', 'in', 'est@@', 'ate', '.', '</s>']
2024-05-19 13:50:37,979 - INFO - joeynmt.training - 	Source:     It expands in winter and contracts in summer.
2024-05-19 13:50:37,979 - INFO - joeynmt.training - 	Reference:  Si espande d'inverno e si ritira d'estate.
2024-05-19 13:50:37,979 - INFO - joeynmt.training - 	Hypothesis: Spande in inverno e contratti in estate.
2024-05-19 13:50:37,980 - INFO - joeynmt.training - Example #4
2024-05-19 13:50:37,980 - DEBUG - joeynmt.training - 	Tokenized source:     ['The', 'next', 'sli@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rapi@@', 'd', 'fast@@', '-@@', 'for@@', 'ward', 'of', 'what', '&@@', 'a@@', 'pos@@', ';@@', 's', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-19 13:50:37,980 - DEBUG - joeynmt.training - 	Tokenized reference:  ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'sarà', 'una', 'rapi@@', 'da', 'car@@', 're@@', 'll@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-19 13:50:37,980 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['La', 'prossi@@', 'ma', 'di@@', 'a@@', 'positi@@', 'va', 'che', 'vi', 'mostr@@', 'o', 'una', 'rapi@@', 'da', 'velo@@', 'ce', 'di', 'quello', 'che', 'è', 'successo', 'negli', 'ultimi', '25', 'anni', '.', '</s>']
2024-05-19 13:50:37,981 - INFO - joeynmt.training - 	Source:     The next slide I show you will be a rapid fast-forward of what's happened over the last 25 years.
2024-05-19 13:50:37,981 - INFO - joeynmt.training - 	Reference:  La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni.
2024-05-19 13:50:37,981 - INFO - joeynmt.training - 	Hypothesis: La prossima diapositiva che vi mostro una rapida veloce di quello che è successo negli ultimi 25 anni.
2024-05-19 13:50:42,496 - INFO - joeynmt.training - Epoch  10, Step:    43100, Batch Loss:     1.344064, Batch Acc: 0.638619, Tokens per Sec:    14762, Lr: 0.000300
2024-05-19 13:50:46,138 - INFO - joeynmt.training - Epoch  10, Step:    43200, Batch Loss:     1.357083, Batch Acc: 0.641958, Tokens per Sec:    19738, Lr: 0.000300
2024-05-19 13:50:49,715 - INFO - joeynmt.training - Epoch  10, Step:    43300, Batch Loss:     1.415980, Batch Acc: 0.639672, Tokens per Sec:    19664, Lr: 0.000300
2024-05-19 13:50:53,700 - INFO - joeynmt.training - Epoch  10, Step:    43400, Batch Loss:     1.360574, Batch Acc: 0.640434, Tokens per Sec:    17746, Lr: 0.000300
2024-05-19 13:50:56,953 - INFO - joeynmt.training - Epoch  10: total training loss 5437.82
2024-05-19 13:50:56,953 - INFO - joeynmt.training - Training ended after  10 epochs.
2024-05-19 13:50:56,954 - INFO - joeynmt.training - Best validation result (greedy) at step    39000:   4.47 ppl.
2024-05-19 13:50:56,976 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-19 13:50:57,064 - INFO - joeynmt.model - Enc-dec model built.
2024-05-19 13:50:57,225 - INFO - joeynmt.helpers - Load model from /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/39000.ckpt.
2024-05-19 13:50:57,254 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=3316),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=3720),
	loss_function=None)
2024-05-19 13:50:57,255 - INFO - joeynmt.prediction - Decoding on dev set...
2024-05-19 13:50:57,255 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:50:57,256 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:51:15,748 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 18.3950[sec], evaluation: 0.0000[sec]
2024-05-19 13:51:15,755 - INFO - joeynmt.prediction - Translations saved to: /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/00039000.hyps.dev.
2024-05-19 13:51:15,755 - INFO - joeynmt.prediction - Decoding on test set...
2024-05-19 13:51:15,756 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-19 13:51:15,756 - INFO - joeynmt.prediction - Predicting 1566 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-19 13:51:43,537 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 27.6250[sec], evaluation: 0.0000[sec]
2024-05-19 13:51:43,545 - INFO - joeynmt.prediction - Translations saved to: /content/drive/MyDrive/mt5/mt-exercise-5/bpe_model_4000/00039000.hyps.test.
